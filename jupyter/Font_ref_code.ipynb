{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ê°€ìƒ í™”ì¥í’ˆ ì „ë©´ì— ë“¤ì–´ê°ˆ í°íŠ¸ ì´ë¯¸ì§€ ìƒì„±í•˜ê¸°",
   "id": "5483d0aa502841bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# FONTS_DIR  = Path(r\"C:\\Users\\nam\\Desktop\\tst\\ref_fonts_ttf\")\n",
    "# OUT_ROOT   = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\front_bw\")"
   ],
   "id": "9b1e1d39c471293e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T12:24:16.916873200Z",
     "start_time": "2025-12-20T12:05:13.126580400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "import sys\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageChops\n",
    "from fontTools.ttLib import TTFont\n",
    "\n",
    "# =========================\n",
    "# âœ… 1. ì„¤ì • ë° ê²½ë¡œ\n",
    "# =========================\n",
    "FONTS_DIR  = Path(r\"C:\\Users\\nam\\Desktop\\tst\\ref_fonts_ttf\")\n",
    "OUT_ROOT   = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\front_bw\")\n",
    "\n",
    "# ë Œë”ë§ ì˜µì…˜\n",
    "RENDER_FONT_SIZE = 160          # ë©”ì¸ í…ìŠ¤íŠ¸ í¬ê¸°\n",
    "SMALL_FONT_RATIO = 0.6          # ìš©ëŸ‰ í‘œê¸° í°íŠ¸ ë¹„ìœ¨\n",
    "LINE_GAP = 20                   # ì¤„ ê°„ê²© (ë¹ˆ ì¤„ì´ ë“¤ì–´ê°€ë¯€ë¡œ ê°„ê²©ì€ ì¢í˜€ë„ ë¨)\n",
    "PAD      = 20\n",
    "PIXEL_CROP = True\n",
    "SKIP_MISSING_GLYPHS = True\n",
    "OUTPUT_SIZE = 1024\n",
    "SLASH_POLICY = \"split\"\n",
    "\n",
    "# â­ [ì„¤ì •] ë¬¸ë‹¨ ì‚¬ì´ì— ë¹ˆ ì¤„ ì¶”ê°€ ì—¬ë¶€\n",
    "ADD_EMPTY_LINE = True\n",
    "\n",
    "# ìš©ëŸ‰/ë‹¨ìœ„ ê°ì§€ ì •ê·œì‹\n",
    "VOLUME_PATTERN = re.compile(r\"^(.*?)\\s*(\\d+(?:\\.\\d+)?\\s*(?:ml|mL|g|kg|oz|pads|sheets|ea))\\s*$\", re.IGNORECASE)\n",
    "\n",
    "# =========================\n",
    "# âœ… 2. ë°ì´í„° (200ê°œ ë ˆì½”ë“œ)\n",
    "# =========================\n",
    "RECORDS_JSONL = \"\"\"\n",
    "{\"lines\": [\"blurrish calm\", \"ë°”ë”” ë¡œì…˜ 355ml\"]}\n",
    "{\"lines\": [\"blurrish calm\", \"í•¸ë“œí¬ë¦¼ 30ml\"]}\n",
    "{\"lines\": [\"auralis dew\", \"ë°”ë””ì›Œì‹œ 300ml\"]}\n",
    "{\"lines\": [\"auralis dew\", \"ë°”ë”” ë¡œì…˜ 355ml\"]}\n",
    "{\"lines\": [\"daylight pure\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"daylight pure\", \"ì„¸ëŸ¼ 50ml\"]}\n",
    "{\"lines\": [\"velveton soft\", \"í´ë Œì§• ì˜¤ì¼ 200ml\"]}\n",
    "{\"lines\": [\"velveton soft\", \"í´ë Œì§• í¼ 120ml\"]}\n",
    "{\"lines\": [\"novafirm zero\", \"í´ë Œì§• ì›Œí„° 300ml\"]}\n",
    "{\"lines\": [\"novafirm zero\", \"í´ë Œì§• ì ¤ 200ml\"]}\n",
    "{\"lines\": [\"moonleaf lift\", \"ì„ í¬ë¦¼ 60ml\"]}\n",
    "{\"lines\": [\"moonleaf lift\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"amberra hydra\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"amberra hydra\", \"ë¡œì…˜ 250ml\"]}\n",
    "{\"lines\": [\"prismia cica\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"prismia cica\", \"ì•„ì´ í¬ë¦¼ 20g\"]}\n",
    "{\"lines\": [\"petaluna bright\", \"ë¯¸ìŠ¤íŠ¸ 80ml\"]}\n",
    "{\"lines\": [\"petaluna bright\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"silkroot fresh\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"silkroot fresh\", \"ìˆ˜ë”©ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"mellowlab matte\", \"ìƒ´í‘¸ 300ml\"]}\n",
    "{\"lines\": [\"mellowlab matte\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 400ml\"]}\n",
    "{\"lines\": [\"lunavia glow\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"lunavia glow\", \"ë©€í‹°ë°¤ 15g\"]}\n",
    "{\"lines\": [\"seaseed satin\", \"ë¦½ë°¤ 4g\"]}\n",
    "{\"lines\": [\"seaseed satin\", \"ë¦½í‹´íŠ¸ 3.5g\"]}\n",
    "{\"lines\": [\"skylin herb\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"skylin herb\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"berrynote airy\", \"ì•½ì‚°ì„± í¼ 150ml\"]}\n",
    "{\"lines\": [\"berrynote airy\", \"í† ë„ˆ 250ml\"]}\n",
    "{\"lines\": [\"hushskin daily\", \"ë°”ë”” ë¡œì…˜ 400ml\"]}\n",
    "{\"lines\": [\"hushskin daily\", \"í•¸ë“œí¬ë¦¼ 75ml\"]}\n",
    "{\"lines\": [\"cloudrin night\", \"ë°”ë””ì›Œì‹œ 355ml\"]}\n",
    "{\"lines\": [\"cloudrin night\", \"ë°”ë”” ë¡œì…˜ 250ml\"]}\n",
    "{\"lines\": [\"oasisle clean\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"oasisle clean\", \"ì„¸ëŸ¼ 30ml\"]}\n",
    "{\"lines\": [\"glowmint tint\", \"í´ë Œì§• ì˜¤ì¼ 150ml\"]}\n",
    "{\"lines\": [\"glowmint tint\", \"í´ë Œì§• í¼ 100ml\"]}\n",
    "{\"lines\": [\"serenique soothe\", \"í´ë Œì§• ì›Œí„° 500ml\"]}\n",
    "{\"lines\": [\"serenique soothe\", \"í´ë Œì§• ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"purekind vita\", \"ì„ í¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"purekind vita\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"novaferm aqua\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"novaferm aqua\", \"ë¡œì…˜ 200ml\"]}\n",
    "{\"lines\": [\"warmhug velvet\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"warmhug velvet\", \"ì•„ì´ í¬ë¦¼ 15g\"]}\n",
    "{\"lines\": [\"aromad mild\", \"ë¯¸ìŠ¤íŠ¸ 50ml\"]}\n",
    "{\"lines\": [\"aromad mild\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"cleanwave smooth\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"cleanwave smooth\", \"ìˆ˜ë”©ì ¤ 200ml\"]}\n",
    "{\"lines\": [\"radiantia bloom\", \"ìƒ´í‘¸ 500ml\"]}\n",
    "{\"lines\": [\"radiantia bloom\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 300ml\"]}\n",
    "{\"lines\": [\"serenbay cloud\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 50g\"]}\n",
    "{\"lines\": [\"serenbay cloud\", \"ë©€í‹°ë°¤ 20g\"]}\n",
    "{\"lines\": [\"ivorylane warm\", \"ë¦½ë°¤ 5g\"]}\n",
    "{\"lines\": [\"ivorylane warm\", \"ë¦½í‹´íŠ¸ 4g\"]}\n",
    "{\"lines\": [\"mintbloom zen\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"mintbloom zen\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"coralroom calm\", \"ì•½ì‚°ì„± í¼ 120ml\"]}\n",
    "{\"lines\": [\"coralroom calm\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"pearlhush dew\", \"ë°”ë”” ë¡œì…˜ 250ml\"]}\n",
    "{\"lines\": [\"pearlhush dew\", \"í•¸ë“œí¬ë¦¼ 100ml\"]}\n",
    "{\"lines\": [\"teatree pure\", \"ë°”ë””ì›Œì‹œ 500ml\"]}\n",
    "{\"lines\": [\"teatree pure\", \"ë°”ë”” ë¡œì…˜ 473ml\"]}\n",
    "{\"lines\": [\"sandmuse soft\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"sandmuse soft\", \"ì„¸ëŸ¼ 15ml\"]}\n",
    "{\"lines\": [\"lumenry zero\", \"í´ë Œì§• ì˜¤ì¼ 170ml\"]}\n",
    "{\"lines\": [\"lumenry zero\", \"í´ë Œì§• í¼ 150ml\"]}\n",
    "{\"lines\": [\"dewfound lift\", \"í´ë Œì§• ì›Œí„° 200ml\"]}\n",
    "{\"lines\": [\"dewfound lift\", \"í´ë Œì§• ì ¤ 180ml\"]}\n",
    "{\"lines\": [\"floraquill hydra\", \"ì„ í¬ë¦¼ 40ml\"]}\n",
    "{\"lines\": [\"floraquill hydra\", \"í† ë„ˆ 250ml\"]}\n",
    "{\"lines\": [\"stoneleaf cica\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"stoneleaf cica\", \"ë¡œì…˜ 150ml\"]}\n",
    "{\"lines\": [\"citruskin bright\", \"í˜ì´ìŠ¤ í¬ë¦¼ 30g\"]}\n",
    "{\"lines\": [\"citruskin bright\", \"ì•„ì´ í¬ë¦¼ 20g\"]}\n",
    "{\"lines\": [\"cloudharbor fresh\", \"ë¯¸ìŠ¤íŠ¸ 100ml\"]}\n",
    "{\"lines\": [\"cloudharbor fresh\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"freshmuse matte\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"freshmuse matte\", \"ìˆ˜ë”©ì ¤ 100ml\"]}\n",
    "{\"lines\": [\"barelythere glow\", \"ìƒ´í‘¸ 400ml\"]}\n",
    "{\"lines\": [\"barelythere glow\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 200ml\"]}\n",
    "{\"lines\": [\"softcove satin\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"softcove satin\", \"ë©€í‹°ë°¤ 15g\"]}\n",
    "{\"lines\": [\"neobare herb\", \"ë¦½ë°¤ 4g\"]}\n",
    "{\"lines\": [\"neobare herb\", \"ë¦½í‹´íŠ¸ 3.5g\"]}\n",
    "{\"lines\": [\"bloomix airy\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"bloomix airy\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"ambrleaf daily\", \"ì•½ì‚°ì„± í¼ 150ml\"]}\n",
    "{\"lines\": [\"ambrleaf daily\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"oceandawn night\", \"ë°”ë”” ë¡œì…˜ 150ml\"]}\n",
    "{\"lines\": [\"oceandawn night\", \"í•¸ë“œí¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"nudemist clean\", \"ë°”ë””ì›Œì‹œ 300ml\"]}\n",
    "{\"lines\": [\"nudemist clean\", \"ë°”ë”” ë¡œì…˜ 500ml\"]}\n",
    "{\"lines\": [\"pinkharbor tint\", \"í† ë„ˆ 230ml\"]}\n",
    "{\"lines\": [\"pinkharbor tint\", \"ì„¸ëŸ¼ 30ml\"]}\n",
    "{\"lines\": [\"quietlily soothe\", \"í´ë Œì§• ì˜¤ì¼ 200ml\"]}\n",
    "{\"lines\": [\"quietlily soothe\", \"í´ë Œì§• í¼ 120ml\"]}\n",
    "{\"lines\": [\"lucidseed vita\", \"í´ë Œì§• ì›Œí„° 400ml\"]}\n",
    "{\"lines\": [\"lucidseed vita\", \"í´ë Œì§• ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"miraflow aqua\", \"ì„ í¬ë¦¼ 60ml\"]}\n",
    "{\"lines\": [\"miraflow aqua\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"solun velvet\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"solun velvet\", \"ë¡œì…˜ 300ml\"]}\n",
    "{\"lines\": [\"aurevia mild\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"aurevia mild\", \"ì•„ì´ í¬ë¦¼ 15g\"]}\n",
    "{\"lines\": [\"glaciera smooth\", \"ë¯¸ìŠ¤íŠ¸ 50ml\"]}\n",
    "{\"lines\": [\"glaciera smooth\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"fawnroot bloom\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"fawnroot bloom\", \"ìˆ˜ë”©ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"rosenest cloud\", \"ìƒ´í‘¸ 500ml\"]}\n",
    "{\"lines\": [\"rosenest cloud\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 400ml\"]}\n",
    "{\"lines\": [\"opaline warm\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 50g\"]}\n",
    "{\"lines\": [\"opaline warm\", \"ë©€í‹°ë°¤ 20g\"]}\n",
    "{\"lines\": [\"candlea zen\", \"ë¦½ë°¤ 5g\"]}\n",
    "{\"lines\": [\"candlea zen\", \"ë¦½í‹´íŠ¸ 4g\"]}\n",
    "{\"lines\": [\"nortex calm\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"nortex calm\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"silvaris dew\", \"ì•½ì‚°ì„± í¼ 120ml\"]}\n",
    "{\"lines\": [\"silvaris dew\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"cedarvein pure\", \"ë°”ë”” ë¡œì…˜ 473ml\"]}\n",
    "{\"lines\": [\"cedarvein pure\", \"í•¸ë“œí¬ë¦¼ 30ml\"]}\n",
    "{\"lines\": [\"mistralyn soft\", \"ë°”ë””ì›Œì‹œ 400ml\"]}\n",
    "{\"lines\": [\"mistralyn soft\", \"ë°”ë”” ë¡œì…˜ 200ml\"]}\n",
    "{\"lines\": [\"duskelle zero\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"duskelle zero\", \"ì„¸ëŸ¼ 40ml\"]}\n",
    "{\"lines\": [\"purenova lift\", \"í´ë Œì§• ì˜¤ì¼ 170ml\"]}\n",
    "{\"lines\": [\"purenova lift\", \"í´ë Œì§• í¼ 100ml\"]}\n",
    "{\"lines\": [\"bluecove hydra\", \"í´ë Œì§• ì›Œí„° 200ml\"]}\n",
    "{\"lines\": [\"bluecove hydra\", \"í´ë Œì§• ì ¤ 180ml\"]}\n",
    "{\"lines\": [\"honeyra cica\", \"ì„ í¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"honeyra cica\", \"í† ë„ˆ 250ml\"]}\n",
    "{\"lines\": [\"laventh bright\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"laventh bright\", \"ë¡œì…˜ 150ml\"]}\n",
    "{\"lines\": [\"springleaf fresh\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"springleaf fresh\", \"ì•„ì´ í¬ë¦¼ 15g\"]}\n",
    "{\"lines\": [\"cocomist matte\", \"ë¯¸ìŠ¤íŠ¸ 80ml\"]}\n",
    "{\"lines\": [\"cocomist matte\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"sagehaven glow\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"sagehaven glow\", \"ìˆ˜ë”©ì ¤ 200ml\"]}\n",
    "{\"lines\": [\"breezara satin\", \"ìƒ´í‘¸ 300ml\"]}\n",
    "{\"lines\": [\"breezara satin\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 300ml\"]}\n",
    "{\"lines\": [\"ivorydew herb\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 50g\"]}\n",
    "{\"lines\": [\"ivorydew herb\", \"ë©€í‹°ë°¤ 20g\"]}\n",
    "{\"lines\": [\"monarchia airy\", \"ë¦½ë°¤ 4g\"]}\n",
    "{\"lines\": [\"monarchia airy\", \"ë¦½í‹´íŠ¸ 3.5g\"]}\n",
    "{\"lines\": [\"pebblebay daily\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"pebblebay daily\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"tenderoot night\", \"ì•½ì‚°ì„± í¼ 150ml\"]}\n",
    "{\"lines\": [\"tenderoot night\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"sunwisp clean\", \"ë°”ë”” ë¡œì…˜ 200ml\"]}\n",
    "{\"lines\": [\"sunwisp clean\", \"í•¸ë“œí¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"rainora tint\", \"ë°”ë””ì›Œì‹œ 500ml\"]}\n",
    "{\"lines\": [\"rainora tint\", \"ë°”ë”” ë¡œì…˜ 355ml\"]}\n",
    "{\"lines\": [\"citravale soothe\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"citravale soothe\", \"ì„¸ëŸ¼ 15ml\"]}\n",
    "{\"lines\": [\"veloria vita\", \"í´ë Œì§• ì˜¤ì¼ 150ml\"]}\n",
    "{\"lines\": [\"veloria vita\", \"í´ë Œì§• í¼ 150ml\"]}\n",
    "{\"lines\": [\"coralyn aqua\", \"í´ë Œì§• ì›Œí„° 400ml\"]}\n",
    "{\"lines\": [\"coralyn aqua\", \"í´ë Œì§• ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"mossmint velvet\", \"ì„ í¬ë¦¼ 60ml\"]}\n",
    "{\"lines\": [\"mossmint velvet\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"lilacove mild\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"lilacove mild\", \"ë¡œì…˜ 200ml\"]}\n",
    "{\"lines\": [\"plumaria smooth\", \"í˜ì´ìŠ¤ í¬ë¦¼ 30g\"]}\n",
    "{\"lines\": [\"plumaria smooth\", \"ì•„ì´ í¬ë¦¼ 20g\"]}\n",
    "{\"lines\": [\"starling bloom\", \"ë¯¸ìŠ¤íŠ¸ 50ml\"]}\n",
    "{\"lines\": [\"starling bloom\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"mistoria cloud\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"mistoria cloud\", \"ìˆ˜ë”©ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"seaquill warm\", \"ìƒ´í‘¸ 400ml\"]}\n",
    "{\"lines\": [\"seaquill warm\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 200ml\"]}\n",
    "{\"lines\": [\"dawnmuse zen\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"dawnmuse zen\", \"ë©€í‹°ë°¤ 15g\"]}\n",
    "{\"lines\": [\"aurorite calm\", \"ë¦½ë°¤ 5g\"]}\n",
    "{\"lines\": [\"aurorite calm\", \"ë¦½í‹´íŠ¸ 4g\"]}\n",
    "{\"lines\": [\"glowridge dew\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"glowridge dew\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"silkbay pure\", \"ì•½ì‚°ì„± í¼ 120ml\"]}\n",
    "{\"lines\": [\"silkbay pure\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"cloudmori soft\", \"ë°”ë”” ë¡œì…˜ 300ml\"]}\n",
    "{\"lines\": [\"cloudmori soft\", \"í•¸ë“œí¬ë¦¼ 100ml\"]}\n",
    "{\"lines\": [\"petalfog zero\", \"ë°”ë””ì›Œì‹œ 355ml\"]}\n",
    "{\"lines\": [\"petalfog zero\", \"ë°”ë”” ë¡œì…˜ 473ml\"]}\n",
    "{\"lines\": [\"nectarune lift\", \"í† ë„ˆ 230ml\"]}\n",
    "{\"lines\": [\"nectarune lift\", \"ì„¸ëŸ¼ 40ml\"]}\n",
    "{\"lines\": [\"halcyon hydra\", \"í´ë Œì§• ì˜¤ì¼ 200ml\"]}\n",
    "{\"lines\": [\"halcyon hydra\", \"í´ë Œì§• í¼ 100ml\"]}\n",
    "{\"lines\": [\"mellowine cica\", \"í´ë Œì§• ì›Œí„° 300ml\"]}\n",
    "{\"lines\": [\"mellowine cica\", \"í´ë Œì§• ì ¤ 180ml\"]}\n",
    "{\"lines\": [\"satinelle lift\", \"ì„ í¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"satinelle lift\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"moodleaf hydra\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"moodleaf hydra\", \"ë¡œì…˜ 150ml\"]}\n",
    "{\"lines\": [\"clearhaven cica\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"clearhaven cica\", \"ì•„ì´ í¬ë¦¼ 20g\"]}\n",
    "{\"lines\": [\"sproutia bright\", \"ë¯¸ìŠ¤íŠ¸ 100ml\"]}\n",
    "{\"lines\": [\"sproutia bright\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"luminote fresh\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"luminote fresh\", \"ìˆ˜ë”©ì ¤ 200ml\"]}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "raw_records = [json.loads(line) for line in RECORDS_JSONL.splitlines() if line.strip()]\n",
    "\n",
    "# ID ì¬í• ë‹¹\n",
    "records = []\n",
    "for i, rec in enumerate(raw_records):\n",
    "    rec['id'] = f\"{i+1:05d}\"\n",
    "    records.append(rec)\n",
    "\n",
    "# Pillow ë¦¬ìƒ˜í”Œë§ í˜¸í™˜ì„±\n",
    "try: RESAMPLE_LANCZOS = Image.Resampling.LANCZOS\n",
    "except AttributeError: RESAMPLE_LANCZOS = Image.LANCZOS\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def get_clean_font_name(font_path: Path) -> str:\n",
    "    stem = font_path.stem\n",
    "    clean_name = re.sub(r\"[^a-zA-Z0-9ê°€-í£]\", \"\", stem)\n",
    "    return clean_name\n",
    "\n",
    "def normalize_lines(lines):\n",
    "    \"\"\"\n",
    "    1. ìŠ¬ë˜ì‹œ(/) ë¶„ë¦¬\n",
    "    2. ìš©ëŸ‰ í‘œê¸° ë¶„ë¦¬\n",
    "    3. [NEW] ë¬¸ë‹¨ ì‚¬ì´ ë¹ˆ ì¤„(' ') ì‚½ì…\n",
    "    \"\"\"\n",
    "    temp_lines = []\n",
    "\n",
    "    # 1ì°¨: ê¸°ì¡´ ì •ì±… ë¶„ë¦¬\n",
    "    for line in lines:\n",
    "        s = str(line).strip()\n",
    "        if not s: continue\n",
    "        if SLASH_POLICY == \"split\" and \"/\" in s:\n",
    "            parts = [p.strip() for p in re.split(r\"\\s*/\\s*\", s) if p.strip()]\n",
    "            temp_lines.extend(parts)\n",
    "        elif SLASH_POLICY == \"remove\":\n",
    "            temp_lines.append(re.sub(r\"\\s*/\\s*\", \" \", s).strip())\n",
    "        else:\n",
    "            temp_lines.append(s)\n",
    "\n",
    "    # 2ì°¨: ìš©ëŸ‰ íŒ¨í„´ ë¶„ë¦¬\n",
    "    parsed_lines = []\n",
    "    for line in temp_lines:\n",
    "        match = VOLUME_PATTERN.match(line)\n",
    "        if match:\n",
    "            main_part = match.group(1).strip()\n",
    "            vol_part = match.group(2).strip()\n",
    "            if main_part: parsed_lines.append(main_part)\n",
    "            parsed_lines.append(vol_part)\n",
    "        else:\n",
    "            parsed_lines.append(line)\n",
    "\n",
    "    # 3ì°¨: ë¹ˆ ì¤„ ì‚½ì… (Double Spacing)\n",
    "    if ADD_EMPTY_LINE and len(parsed_lines) > 0:\n",
    "        spaced_lines = []\n",
    "        for i, item in enumerate(parsed_lines):\n",
    "            spaced_lines.append(item)\n",
    "            # ë§ˆì§€ë§‰ ì•„ì´í…œì´ ì•„ë‹ˆë©´ ê³µë°±(\" \") ì¶”ê°€ -> ì´ê²Œ ë¹ˆ ì¤„ ì—­í• \n",
    "            if i < len(parsed_lines) - 1:\n",
    "                spaced_lines.append(\" \")\n",
    "        return spaced_lines\n",
    "\n",
    "    return parsed_lines\n",
    "\n",
    "def best_cmap(font_path: Path) -> dict:\n",
    "    try:\n",
    "        tt = TTFont(str(font_path), lazy=True)\n",
    "        cmap = tt[\"cmap\"].getBestCmap() or {}\n",
    "        try: tt.close()\n",
    "        except: pass\n",
    "        return cmap\n",
    "    except: return {}\n",
    "\n",
    "def missing_chars(cmap: dict, text: str):\n",
    "    miss = []\n",
    "    for ch in set(text):\n",
    "        if ch.isspace(): continue\n",
    "        if ord(ch) not in cmap: miss.append(ch)\n",
    "    return sorted(miss)\n",
    "\n",
    "def tight_crop_white(img: Image.Image) -> Image.Image:\n",
    "    if not PIXEL_CROP: return img\n",
    "    bg = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "    diff = ImageChops.difference(img, bg)\n",
    "    bbox = diff.getbbox()\n",
    "    return img.crop(bbox) if bbox else img\n",
    "\n",
    "def fit_into_square(img: Image.Image, size: int) -> tuple[Image.Image, float, tuple[int,int]]:\n",
    "    w, h = img.size\n",
    "    scale = min(size / w, size / h, 1.0)\n",
    "    if scale < 1.0:\n",
    "        nw = max(1, int(round(w * scale)))\n",
    "        nh = max(1, int(round(h * scale)))\n",
    "        img = img.resize((nw, nh), resample=RESAMPLE_LANCZOS)\n",
    "        w, h = img.size\n",
    "    canvas = Image.new(\"RGB\", (size, size), (255, 255, 255))\n",
    "    ox = (size - w) // 2\n",
    "    oy = (size - h) // 2\n",
    "    canvas.paste(img, (ox, oy))\n",
    "    return canvas, float(scale), (int(ox), int(oy))\n",
    "\n",
    "def get_text_dimensions(text_string, font):\n",
    "    dummy = Image.new(\"RGB\", (1, 1))\n",
    "    draw = ImageDraw.Draw(dummy)\n",
    "    if hasattr(draw, \"textbbox\"):\n",
    "        l, t, r, b = draw.textbbox((0, 0), text_string, font=font)\n",
    "        return r - l, b - t\n",
    "    else:\n",
    "        return draw.textsize(text_string, font)\n",
    "\n",
    "# =========================\n",
    "# ë Œë”ë§ í•¨ìˆ˜\n",
    "# =========================\n",
    "def render_multi_size_block(lines, font_path: Path) -> Image.Image:\n",
    "    font_main = ImageFont.truetype(str(font_path), RENDER_FONT_SIZE)\n",
    "    font_small = ImageFont.truetype(str(font_path), int(RENDER_FONT_SIZE * SMALL_FONT_RATIO))\n",
    "\n",
    "    parsed_lines = []\n",
    "    total_h = 0\n",
    "    max_w = 0\n",
    "\n",
    "    for line in lines:\n",
    "        # ê³µë°± ë¼ì¸(\" \")ì€ ì •ê·œì‹ ë§¤ì¹˜ X -> font_main ì‚¬ìš© -> ë¹ˆ ì¤„ ë†’ì´ í™•ë³´\n",
    "        is_vol = bool(VOLUME_PATTERN.match(line))\n",
    "        font = font_small if is_vol else font_main\n",
    "\n",
    "        w, h = get_text_dimensions(line, font)\n",
    "\n",
    "        # ë§Œì•½ \" \" ê³µë°± ì¤„ì´ë¼ë©´ ë†’ì´ëŠ” í°íŠ¸ í¬ê¸°ë§Œí¼ ë³´ì¥, ë„ˆë¹„ëŠ” 0ì— ê°€ê¹Œì›€\n",
    "        if not line.strip():\n",
    "            h = RENDER_FONT_SIZE # ê°•ì œ ë†’ì´ ì§€ì •\n",
    "\n",
    "        parsed_lines.append({\"text\": line, \"font\": font, \"w\": w, \"h\": h})\n",
    "        max_w = max(max_w, w)\n",
    "        total_h += h\n",
    "\n",
    "    # ì¤„ ê°„ê²© ì¶”ê°€\n",
    "    total_h += (len(lines) - 1) * LINE_GAP if len(lines) > 0 else 0\n",
    "\n",
    "    img_w = max_w + 2 * PAD\n",
    "    img_h = total_h + 2 * PAD\n",
    "    img = Image.new(\"RGB\", (img_w, img_h), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    current_y = PAD\n",
    "    for item in parsed_lines:\n",
    "        text = item[\"text\"]\n",
    "        font = item[\"font\"]\n",
    "        line_w = item[\"w\"]\n",
    "        line_h = item[\"h\"]\n",
    "\n",
    "        x = (img_w - line_w) // 2\n",
    "\n",
    "        # ê³µë°±ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì‹¤ì œ ê·¸ë¦¬ê¸°\n",
    "        if text.strip():\n",
    "            draw.text((x, current_y), text, font=font, fill=(0, 0, 0))\n",
    "\n",
    "        current_y += line_h + LINE_GAP\n",
    "\n",
    "    return img\n",
    "\n",
    "# =========================\n",
    "# ë©”ì¸ í”„ë¡œì„¸ìŠ¤\n",
    "# =========================\n",
    "def process_single_font_safe(font_path, record_list):\n",
    "    clean_font_name = get_clean_font_name(font_path) or \"UnknownFont\"\n",
    "    out_dir = OUT_ROOT / clean_font_name\n",
    "\n",
    "    ann_path  = out_dir / \"annotations.jsonl\"\n",
    "    if ann_path.exists():\n",
    "        print(f\"â© Skipping {clean_font_name}\", flush=True)\n",
    "        return\n",
    "\n",
    "    cmap = best_cmap(font_path)\n",
    "    if not cmap:\n",
    "        print(f\"âš ï¸ Bad font: {clean_font_name}\", flush=True)\n",
    "        return\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    miss_path = out_dir / \"missing_glyphs.jsonl\"\n",
    "    saved, skipped = 0, 0\n",
    "\n",
    "    with ann_path.open(\"w\", encoding=\"utf-8\") as ann_f, miss_path.open(\"w\", encoding=\"utf-8\") as miss_f:\n",
    "        for rec in record_list:\n",
    "            rid = rec.get(\"id\")\n",
    "            raw_lines = rec.get(\"lines\", [])\n",
    "            lines = normalize_lines(raw_lines)\n",
    "            text = \"\\n\".join(lines)\n",
    "\n",
    "            miss = missing_chars(cmap, text)\n",
    "            if miss:\n",
    "                miss_f.write(json.dumps({\"id\": rid, \"font\": str(font_path), \"missing_chars\": miss}, ensure_ascii=False) + \"\\n\")\n",
    "                if SKIP_MISSING_GLYPHS:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                img = render_multi_size_block(lines, font_path)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            img = tight_crop_white(img)\n",
    "            inner_w, inner_h = img.size\n",
    "            final_img, scale, (ox, oy) = fit_into_square(img, OUTPUT_SIZE)\n",
    "\n",
    "            filename = f\"{clean_font_name}_{rid}.png\"\n",
    "            final_img.save(out_dir / filename, \"PNG\")\n",
    "\n",
    "            meta = {\n",
    "                \"id\": rid,\n",
    "                \"file_name\": filename,\n",
    "                \"image_path\": f\"{clean_font_name}/{filename}\",\n",
    "                \"font_name\": clean_font_name,\n",
    "                \"output_size\": OUTPUT_SIZE,\n",
    "                \"render_font_size\": RENDER_FONT_SIZE,\n",
    "                \"small_font_ratio\": SMALL_FONT_RATIO,\n",
    "                \"fit_scale\": float(scale),\n",
    "                \"paste_offset\": [ox, oy],\n",
    "                \"lines\": lines\n",
    "            }\n",
    "            ann_f.write(json.dumps(meta, ensure_ascii=False) + \"\\n\")\n",
    "            saved += 1\n",
    "\n",
    "    print(f\"[{clean_font_name}] Saved: {saved}, Skipped: {skipped}\", flush=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "    ttf_paths = sorted([p for p in FONTS_DIR.rglob(\"*.ttf\") if p.is_file()])\n",
    "\n",
    "    print(f\"Records: {len(records)}, Fonts: {len(ttf_paths)}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    for i, font_path in enumerate(ttf_paths):\n",
    "        print(f\"ğŸ‘‰ [{i+1}/{len(ttf_paths)}] {font_path.name} ... \", end=\"\", flush=True)\n",
    "        try: process_single_font_safe(font_path, records)\n",
    "        except KeyboardInterrupt: break\n",
    "        except Exception as e: print(f\"\\nâŒ Error: {e}\", flush=True)\n",
    "\n",
    "    print(\"\\nâœ… All Done.\")"
   ],
   "id": "fa14c862354fb88d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records: 200, Fonts: 150\n",
      "--------------------------------------------------\n",
      "ğŸ‘‰ [1/150] AritaBuriKR-Medium.ttf ... [AritaBuriKRMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [2/150] AstaSans-Regular.ttf ... [AstaSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [3/150] Binggrae.ttf ... [Binggrae] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [4/150] BinggraeII.ttf ... [BinggraeII] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [5/150] BinggraeMelona.ttf ... [BinggraeMelona] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [6/150] BinggraeSamanco.ttf ... [BinggraeSamanco] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [7/150] BinggraeTaom.ttf ... [BinggraeTaom] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [8/150] BMHANNA_11yrs_ttf.ttf ... [BMHANNA11yrsttf] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [9/150] BookkGothic_Light.ttf ... [BookkGothicLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [10/150] BookkMyungjo_Light.ttf ... [BookkMyungjoLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [11/150] Cafe24Simplehae-v2.0.ttf ... [Cafe24Simplehaev20] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [12/150] Cafe24SsurroundAir-v1.1.ttf ... [Cafe24SsurroundAirv11] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [13/150] Cafe24Syongsyong-v2.0.ttf ... [Cafe24Syongsyongv20] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [14/150] ChosunGs.TTF ... [ChosunGs] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [15/150] ChosunGu.TTF ... [ChosunGu] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [16/150] ChosunKg.TTF ... [ChosunKg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [17/150] ChosunKm.TTF ... [ChosunKm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [18/150] ChosunNm.ttf ... [ChosunNm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [19/150] ChosunSg.TTF ... [ChosunSg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [20/150] ChosunSm.TTF ... [ChosunSm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [21/150] D2Coding-Ver1.3.2-20180524.ttf ... [D2CodingVer13220180524] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [22/150] Dongle-Light.ttf ... [DongleLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [23/150] EliceDigitalBaeum_Regular.ttf ... [EliceDigitalBaeumRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [24/150] EliceDigitalCodingverH_Bold.ttf ... [EliceDigitalCodingverHBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [25/150] EliceDXNeolli-Medium.ttf ... [EliceDXNeolliMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [26/150] esamanru Medium.ttf ... [esamanruMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [27/150] Eulyoo1945-Regular.ttf ... [Eulyoo1945Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [28/150] Freesentation-4Regular.ttf ... [Freesentation4Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [29/150] FreesentationVF.ttf ... [FreesentationVF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [30/150] GapyeongHanseokbongR.ttf ... [GapyeongHanseokbongR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [31/150] GmarketSansTTFMedium.ttf ... [GmarketSansTTFMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [32/150] goorm-sans-regular.ttf ... [goormsansregular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [33/150] goorm_Sans_Code_400.ttf ... [goormSansCode400] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [34/150] GowunDodum-Regular.ttf ... [GowunDodumRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [35/150] Gumi Dotum.ttf ... [GumiDotum] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [36/150] Hahmlet-Black.ttf ... [HahmletBlack] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [37/150] Hahmlet-Thin.ttf ... [HahmletThin] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [38/150] Hakgyoansim Allimjang TTF R.ttf ... [HakgyoansimAllimjangTTFR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [39/150] Hakgyoansim Badasseugi TTF L.ttf ... [HakgyoansimBadasseugiTTFL] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [40/150] Hakgyoansim Geurimilgi TTF R.ttf ... [HakgyoansimGeurimilgiTTFR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [41/150] Hakgyoansim Nadeuri TTF B.ttf ... [HakgyoansimNadeuriTTFB] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [42/150] Hakgyoansim_BoardmarkerR.ttf ... [HakgyoansimBoardmarkerR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [43/150] Hakgyoansim_JayusiganR.ttf ... [HakgyoansimJayusiganR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [44/150] Hakgyoansim_OcarinaR.ttf ... [HakgyoansimOcarinaR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [45/150] Hakgyoansim_SangjangR.ttf ... [HakgyoansimSangjangR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [46/150] Hakgyoansim_SiganpyoR.ttf ... [HakgyoansimSiganpyoR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [47/150] HakgyoansimBareonbatangR.ttf ... [HakgyoansimBareonbatangR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [48/150] HakgyoansimBareondotumR.ttf ... [HakgyoansimBareondotumR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [49/150] HakgyoansimSantteutdotumM.ttf ... [HakgyoansimSantteutdotumM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [50/150] HakgyoansimTtwimteulR.ttf ... [HakgyoansimTtwimteulR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [51/150] HakgyoansimUndongjangL.ttf ... [HakgyoansimUndongjangL] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [52/150] HancomSans-SemiBold_0.ttf ... [HancomSansSemiBold0] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [53/150] HSJandari-Regular.ttf ... [HSJandariRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [54/150] HSê²¨ìš¸ëˆˆê½ƒì²´.ttf ... [HSê²¨ìš¸ëˆˆê½ƒì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [55/150] Interop-Regular.ttf ... [InteropRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [56/150] JejuGothic.ttf ... [JejuGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [57/150] JejuHallasan.ttf ... [JejuHallasan] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [58/150] JejuMyeongjo.ttf ... [JejuMyeongjo] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [59/150] KakaoBigSans-Regular.ttf ... [KakaoBigSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [60/150] KakaoSmallSans-Regular.ttf ... [KakaoSmallSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [61/150] KBO Dia Gothic_medium.ttf ... [KBODiaGothicmedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [62/150] KCCChassam.ttf ... [KCCChassam] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [63/150] KCCImkwontaek.ttf ... [KCCImkwontaek] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [64/150] KCCì€ì˜ì²´.ttf ... [KCCì€ì˜ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [65/150] KimjungchulGothic-Regular.ttf ... [KimjungchulGothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [66/150] KimjungchulMyungjo-Regular.ttf ... [KimjungchulMyungjoRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [67/150] KimjungchulScript-Bold.ttf ... [KimjungchulScriptBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [68/150] KOHINanum_Light.ttf ... [KOHINanumLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [69/150] KoPubWorld Batang Medium.ttf ... [KoPubWorldBatangMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [70/150] KoPubWorld Dotum Medium.ttf ... [KoPubWorldDotumMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [71/150] KOTRA_GOTHIC.ttf ... [KOTRAGOTHIC] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [72/150] KOTRA_SONGEULSSI.ttf ... [KOTRASONGEULSSI] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [73/150] KyoboHandwriting2024psw.ttf ... [KyoboHandwriting2024psw] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [74/150] LINESeedKR-Rg.ttf ... [LINESeedKRRg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [75/150] MapoHongdaeFreedom.ttf ... [MapoHongdaeFreedom] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [76/150] MBC 1961êµ´ë¦¼ M.ttf ... [MBC1961êµ´ë¦¼M] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [77/150] MinSans-Light.ttf ... [MinSansLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [78/150] MinSans-Regular.ttf ... [MinSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [79/150] MinSansVF.ttf ... [MinSansVF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [80/150] MiraeroNormal.ttf ... [MiraeroNormal] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [81/150] Moneygraphy-Rounded.ttf ... [MoneygraphyRounded] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [82/150] Mungyeong-Gamhong-Apple.ttf ... [MungyeongGamhongApple] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [83/150] NanumBarunGothic-YetHangul.ttf ... [NanumBarunGothicYetHangul] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [84/150] NanumBarunGothic.ttf ... [NanumBarunGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [85/150] NanumBarunpenR.ttf ... [NanumBarunpenR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [86/150] NanumGothic.ttf ... [NanumGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [87/150] NanumHumanRegular.ttf ... [NanumHumanRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [88/150] NanumMyeongjo-YetHangul.ttf ... [NanumMyeongjoYetHangul] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [89/150] NanumMyeongjo.ttf ... [NanumMyeongjo] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [90/150] NanumSquareR.ttf ... [NanumSquareR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [91/150] netmarbleM.ttf ... [netmarbleM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [92/150] NEXON Kart Gothic Kor Medium.ttf ... [NEXONKartGothicKorMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [93/150] NEXONLv1GothicRegular.ttf ... [NEXONLv1GothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [94/150] NotoSansKR-Regular.ttf ... [NotoSansKRRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [95/150] NotoSerifKR-Regular.ttf ... [NotoSerifKRRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [96/150] ONE Mobile Regular.ttf ... [ONEMobileRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [97/150] Paperlogy-4Regular.ttf ... [Paperlogy4Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [98/150] PyeojinGothic-Light.ttf ... [PyeojinGothicLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [99/150] PyeojinGothic-Regular.ttf ... [PyeojinGothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [100/150] PyeongChang-Regular.ttf ... [PyeongChangRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [101/150] RiaSans-Regular.ttf ... [RiaSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [102/150] SB ì–´ê·¸ë¡œ M.ttf ... [SBì–´ê·¸ë¡œM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [103/150] SejongGeulggot.ttf ... [SejongGeulggot] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [104/150] SeoulAlrimTTF-Medium.ttf ... [SeoulAlrimTTFMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [105/150] SeoulNamsanB.ttf ... [SeoulNamsanB] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [106/150] Spoqa Han Sans Regular.ttf ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103736 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SpoqaHanSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [107/150] SpoqaHanSansNeo-Regular.ttf ... [SpoqaHanSansNeoRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [108/150] STUNNING.ttf ... [STUNNING] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [109/150] SUIT-Variable.ttf ... [SUITVariable] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [110/150] The Jamsil 3 Regular.ttf ... [TheJamsil3Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [111/150] THEFACESHOP+INKLIPQUID(ìœˆë„ìš°ìš©).ttf ... [THEFACESHOPINKLIPQUIDìœˆë„ìš°ìš©] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [112/150] Tlabì‹ ì˜ë³µì²´.ttf ... [Tlabì‹ ì˜ë³µì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [113/150] UhBee Se_hyun.ttf ... [UhBeeSehyun] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [114/150] WantedSans-Regular.ttf ... [WantedSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [115/150] WantedSansVariable.ttf ... [WantedSansVariable] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [116/150] YES24GothicR.ttf ... [YES24GothicR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [117/150] YES24MyoungjoR.ttf ... [YES24MyoungjoR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [118/150] YoonChildfundkoreaMinGuk.ttf ... [YoonChildfundkoreaMinGuk] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [119/150] ê°•ì›êµìœ¡ëª¨ë‘ Light.ttf ... [ê°•ì›êµìœ¡ëª¨ë‘Light] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [120/150] ê°•ì›êµìœ¡ìƒˆìŒ.ttf ... [ê°•ì›êµìœ¡ìƒˆìŒ] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [121/150] ê°•ì›êµìœ¡í˜„ì˜¥ìƒ˜.ttf ... [ê°•ì›êµìœ¡í˜„ì˜¥ìƒ˜] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [122/150] ê²½ê¸°ì²œë…„ë°”íƒ•_Regular.ttf ... [ê²½ê¸°ì²œë…„ë°”íƒ•Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [123/150] ê²½ê¸°ì²œë…„ì œëª©V_Bold.ttf ... [ê²½ê¸°ì²œë…„ì œëª©VBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [124/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ê³°ì‹ ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ê³°ì‹ ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [125/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ë§›ìˆëŠ”ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ë§›ìˆëŠ”ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [126/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ìƒí•´ì°¬ë¯¸ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ìƒí•´ì°¬ë¯¸ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [127/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì„±ì‹¤ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì„±ì‹¤ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [128/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì†Œë°©ê´€ì˜ ê¸°ë„.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì†Œë°©ê´€ì˜ê¸°ë„] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [129/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì•„ì¸ë§˜ ì†ê¸€ì”¨.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì•„ì¸ë§˜ì†ê¸€ì”¨] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [130/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì—„ë§ˆì‚¬ë‘.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì—„ë§ˆì‚¬ë‘] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [131/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ˆìœ ë¯¼ê²½ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ˆìœë¯¼ê²½ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [132/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ë¯¸ìˆëŠ” í•œê¸€.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ë¯¸ìˆëŠ”í•œê¸€] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [133/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì² í•„ê¸€ì”¨.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì² í•„ê¸€ì”¨] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [134/150] ëŒ€êµ¬ë¶ì„±ë¡œ Light.ttf ... [ëŒ€êµ¬ë¶ì„±ë¡œLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [135/150] ë•…ìŠ¤ë¶€ëŒ€ì°Œê°œ Light.ttf ... [ë•…ìŠ¤ë¶€ëŒ€ì°Œê°œLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [136/150] ì‚¼ìœ¡ëŒ€ì²´ Regular.ttf ... [ì‚¼ìœ¡ëŒ€ì²´Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [137/150] ì„œìš¸í•œê°• ì¥ì²´B.ttf ... [ì„œìš¸í•œê°•ì¥ì²´B] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [138/150] ì„œìš¸í•œê°• ì¥ì²´M.ttf ... [ì„œìš¸í•œê°•ì¥ì²´M] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [139/150] ì˜¨ê¸€ì ê³µë¶€ì˜í•˜ìë‚˜.ttf ... [ì˜¨ê¸€ìê³µë¶€ì˜í•˜ìë‚˜] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [140/150] ì˜¨ê¸€ì ê¹€ì½©í•´.ttf ... [ì˜¨ê¸€ìê¹€ì½©í•´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [141/150] ì˜¨ê¸€ì ë°”ë‹·ë°”ëŒ.ttf ... [ì˜¨ê¸€ìë°”ë‹·ë°”ëŒ] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [142/150] ì˜¨ê¸€ì ìœ„ì”¨ë¦¬ìŠ¤íŠ¸.ttf ... [ì˜¨ê¸€ììœ„ì”¨ë¦¬ìŠ¤íŠ¸] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [143/150] ì˜¨ê¸€ì ì½˜ì½˜ì²´.ttf ... [ì˜¨ê¸€ìì½˜ì½˜ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [144/150] ìœ ì•¤í”¼í”Œ ê³ ë”• KS.ttf ... [ìœ ì•¤í”¼í”Œê³ ë”•KS] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [145/150] ìœ ì•¤í”¼í”Œ ê³ ë”• UNI.ttf ... [ìœ ì•¤í”¼í”Œê³ ë”•UNI] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [146/150] ì´ì„œìœ¤ì²´.ttf ... [ì´ì„œìœ¤ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [147/150] ì •ì„ ë™ê°•ì²´(Regular)TTF.ttf ... [ì •ì„ ë™ê°•ì²´RegularTTF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [148/150] ì •ì„ ì•„ë¦¬ë‘ë¿Œë¦¬ì²´TTF.ttf ... [ì •ì„ ì•„ë¦¬ë‘ë¿Œë¦¬ì²´TTF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [149/150] ì¤‘ë‚˜ì¢‹ì²´ Medium.ttf ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12292 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¤‘ë‚˜ì¢‹ì²´Medium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [150/150] í´ë¦½ì•„íŠ¸ì½”ë¦¬ì•„_Regular.ttf ... [í´ë¦½ì•„íŠ¸ì½”ë¦¬ì•„Regular] Saved: 200, Skipped: 0\n",
      "\n",
      "âœ… All Done.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ìƒ‰ìƒì„ ë‹¤ì–‘í•˜ê²Œ ìƒì„±",
   "id": "66cebc97607d1592"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:23:12.033234500Z",
     "start_time": "2025-12-20T13:03:42.679311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import re\n",
    "import sys\n",
    "import random  # âœ… ì¶”ê°€ë¨\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageChops\n",
    "from fontTools.ttLib import TTFont\n",
    "\n",
    "# =========================\n",
    "# âœ… 1. ì„¤ì • ë° ê²½ë¡œ\n",
    "# =========================\n",
    "FONTS_DIR  = Path(r\"C:\\Users\\nam\\Desktop\\tst\\ref_fonts_ttf\")\n",
    "OUT_ROOT   = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\front_color_aug\")\n",
    "\n",
    "# ë Œë”ë§ ì˜µì…˜\n",
    "RENDER_FONT_SIZE = 160          # ë©”ì¸ í…ìŠ¤íŠ¸ í¬ê¸°\n",
    "SMALL_FONT_RATIO = 0.6          # ìš©ëŸ‰ í‘œê¸° í°íŠ¸ ë¹„ìœ¨\n",
    "LINE_GAP = 20                   # ì¤„ ê°„ê²©\n",
    "PAD      = 20\n",
    "PIXEL_CROP = True\n",
    "SKIP_MISSING_GLYPHS = True\n",
    "OUTPUT_SIZE = 1024\n",
    "SLASH_POLICY = \"split\"\n",
    "\n",
    "# â­ [ì„¤ì •] ë¬¸ë‹¨ ì‚¬ì´ì— ë¹ˆ ì¤„ ì¶”ê°€ ì—¬ë¶€\n",
    "ADD_EMPTY_LINE = True\n",
    "\n",
    "# ìš©ëŸ‰/ë‹¨ìœ„ ê°ì§€ ì •ê·œì‹\n",
    "VOLUME_PATTERN = re.compile(r\"^(.*?)\\s*(\\d+(?:\\.\\d+)?\\s*(?:ml|mL|g|kg|oz|pads|sheets|ea))\\s*$\", re.IGNORECASE)\n",
    "\n",
    "# =========================\n",
    "# âœ… 2. ë°ì´í„° (200ê°œ ë ˆì½”ë“œ)\n",
    "# =========================\n",
    "RECORDS_JSONL = \"\"\"\n",
    "{\"lines\": [\"blurrish calm\", \"ë°”ë”” ë¡œì…˜ 355ml\"]}\n",
    "{\"lines\": [\"blurrish calm\", \"í•¸ë“œí¬ë¦¼ 30ml\"]}\n",
    "{\"lines\": [\"auralis dew\", \"ë°”ë””ì›Œì‹œ 300ml\"]}\n",
    "{\"lines\": [\"auralis dew\", \"ë°”ë”” ë¡œì…˜ 355ml\"]}\n",
    "{\"lines\": [\"daylight pure\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"daylight pure\", \"ì„¸ëŸ¼ 50ml\"]}\n",
    "{\"lines\": [\"velveton soft\", \"í´ë Œì§• ì˜¤ì¼ 200ml\"]}\n",
    "{\"lines\": [\"velveton soft\", \"í´ë Œì§• í¼ 120ml\"]}\n",
    "{\"lines\": [\"novafirm zero\", \"í´ë Œì§• ì›Œí„° 300ml\"]}\n",
    "{\"lines\": [\"novafirm zero\", \"í´ë Œì§• ì ¤ 200ml\"]}\n",
    "{\"lines\": [\"moonleaf lift\", \"ì„ í¬ë¦¼ 60ml\"]}\n",
    "{\"lines\": [\"moonleaf lift\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"amberra hydra\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"amberra hydra\", \"ë¡œì…˜ 250ml\"]}\n",
    "{\"lines\": [\"prismia cica\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"prismia cica\", \"ì•„ì´ í¬ë¦¼ 20g\"]}\n",
    "{\"lines\": [\"petaluna bright\", \"ë¯¸ìŠ¤íŠ¸ 80ml\"]}\n",
    "{\"lines\": [\"petaluna bright\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"silkroot fresh\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"silkroot fresh\", \"ìˆ˜ë”©ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"mellowlab matte\", \"ìƒ´í‘¸ 300ml\"]}\n",
    "{\"lines\": [\"mellowlab matte\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 400ml\"]}\n",
    "{\"lines\": [\"lunavia glow\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"lunavia glow\", \"ë©€í‹°ë°¤ 15g\"]}\n",
    "{\"lines\": [\"seaseed satin\", \"ë¦½ë°¤ 4g\"]}\n",
    "{\"lines\": [\"seaseed satin\", \"ë¦½í‹´íŠ¸ 3.5g\"]}\n",
    "{\"lines\": [\"skylin herb\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"skylin herb\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"berrynote airy\", \"ì•½ì‚°ì„± í¼ 150ml\"]}\n",
    "{\"lines\": [\"berrynote airy\", \"í† ë„ˆ 250ml\"]}\n",
    "{\"lines\": [\"hushskin daily\", \"ë°”ë”” ë¡œì…˜ 400ml\"]}\n",
    "{\"lines\": [\"hushskin daily\", \"í•¸ë“œí¬ë¦¼ 75ml\"]}\n",
    "{\"lines\": [\"cloudrin night\", \"ë°”ë””ì›Œì‹œ 355ml\"]}\n",
    "{\"lines\": [\"cloudrin night\", \"ë°”ë”” ë¡œì…˜ 250ml\"]}\n",
    "{\"lines\": [\"oasisle clean\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"oasisle clean\", \"ì„¸ëŸ¼ 30ml\"]}\n",
    "{\"lines\": [\"glowmint tint\", \"í´ë Œì§• ì˜¤ì¼ 150ml\"]}\n",
    "{\"lines\": [\"glowmint tint\", \"í´ë Œì§• í¼ 100ml\"]}\n",
    "{\"lines\": [\"serenique soothe\", \"í´ë Œì§• ì›Œí„° 500ml\"]}\n",
    "{\"lines\": [\"serenique soothe\", \"í´ë Œì§• ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"purekind vita\", \"ì„ í¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"purekind vita\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"novaferm aqua\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"novaferm aqua\", \"ë¡œì…˜ 200ml\"]}\n",
    "{\"lines\": [\"warmhug velvet\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"warmhug velvet\", \"ì•„ì´ í¬ë¦¼ 15g\"]}\n",
    "{\"lines\": [\"aromad mild\", \"ë¯¸ìŠ¤íŠ¸ 50ml\"]}\n",
    "{\"lines\": [\"aromad mild\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"cleanwave smooth\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"cleanwave smooth\", \"ìˆ˜ë”©ì ¤ 200ml\"]}\n",
    "{\"lines\": [\"radiantia bloom\", \"ìƒ´í‘¸ 500ml\"]}\n",
    "{\"lines\": [\"radiantia bloom\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 300ml\"]}\n",
    "{\"lines\": [\"serenbay cloud\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 50g\"]}\n",
    "{\"lines\": [\"serenbay cloud\", \"ë©€í‹°ë°¤ 20g\"]}\n",
    "{\"lines\": [\"ivorylane warm\", \"ë¦½ë°¤ 5g\"]}\n",
    "{\"lines\": [\"ivorylane warm\", \"ë¦½í‹´íŠ¸ 4g\"]}\n",
    "{\"lines\": [\"mintbloom zen\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"mintbloom zen\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"coralroom calm\", \"ì•½ì‚°ì„± í¼ 120ml\"]}\n",
    "{\"lines\": [\"coralroom calm\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"pearlhush dew\", \"ë°”ë”” ë¡œì…˜ 250ml\"]}\n",
    "{\"lines\": [\"pearlhush dew\", \"í•¸ë“œí¬ë¦¼ 100ml\"]}\n",
    "{\"lines\": [\"teatree pure\", \"ë°”ë””ì›Œì‹œ 500ml\"]}\n",
    "{\"lines\": [\"teatree pure\", \"ë°”ë”” ë¡œì…˜ 473ml\"]}\n",
    "{\"lines\": [\"sandmuse soft\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"sandmuse soft\", \"ì„¸ëŸ¼ 15ml\"]}\n",
    "{\"lines\": [\"lumenry zero\", \"í´ë Œì§• ì˜¤ì¼ 170ml\"]}\n",
    "{\"lines\": [\"lumenry zero\", \"í´ë Œì§• í¼ 150ml\"]}\n",
    "{\"lines\": [\"dewfound lift\", \"í´ë Œì§• ì›Œí„° 200ml\"]}\n",
    "{\"lines\": [\"dewfound lift\", \"í´ë Œì§• ì ¤ 180ml\"]}\n",
    "{\"lines\": [\"floraquill hydra\", \"ì„ í¬ë¦¼ 40ml\"]}\n",
    "{\"lines\": [\"floraquill hydra\", \"í† ë„ˆ 250ml\"]}\n",
    "{\"lines\": [\"stoneleaf cica\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"stoneleaf cica\", \"ë¡œì…˜ 150ml\"]}\n",
    "{\"lines\": [\"citruskin bright\", \"í˜ì´ìŠ¤ í¬ë¦¼ 30g\"]}\n",
    "{\"lines\": [\"citruskin bright\", \"ì•„ì´ í¬ë¦¼ 20g\"]}\n",
    "{\"lines\": [\"cloudharbor fresh\", \"ë¯¸ìŠ¤íŠ¸ 100ml\"]}\n",
    "{\"lines\": [\"cloudharbor fresh\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"freshmuse matte\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"freshmuse matte\", \"ìˆ˜ë”©ì ¤ 100ml\"]}\n",
    "{\"lines\": [\"barelythere glow\", \"ìƒ´í‘¸ 400ml\"]}\n",
    "{\"lines\": [\"barelythere glow\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 200ml\"]}\n",
    "{\"lines\": [\"softcove satin\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"softcove satin\", \"ë©€í‹°ë°¤ 15g\"]}\n",
    "{\"lines\": [\"neobare herb\", \"ë¦½ë°¤ 4g\"]}\n",
    "{\"lines\": [\"neobare herb\", \"ë¦½í‹´íŠ¸ 3.5g\"]}\n",
    "{\"lines\": [\"bloomix airy\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"bloomix airy\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"ambrleaf daily\", \"ì•½ì‚°ì„± í¼ 150ml\"]}\n",
    "{\"lines\": [\"ambrleaf daily\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"oceandawn night\", \"ë°”ë”” ë¡œì…˜ 150ml\"]}\n",
    "{\"lines\": [\"oceandawn night\", \"í•¸ë“œí¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"nudemist clean\", \"ë°”ë””ì›Œì‹œ 300ml\"]}\n",
    "{\"lines\": [\"nudemist clean\", \"ë°”ë”” ë¡œì…˜ 500ml\"]}\n",
    "{\"lines\": [\"pinkharbor tint\", \"í† ë„ˆ 230ml\"]}\n",
    "{\"lines\": [\"pinkharbor tint\", \"ì„¸ëŸ¼ 30ml\"]}\n",
    "{\"lines\": [\"quietlily soothe\", \"í´ë Œì§• ì˜¤ì¼ 200ml\"]}\n",
    "{\"lines\": [\"quietlily soothe\", \"í´ë Œì§• í¼ 120ml\"]}\n",
    "{\"lines\": [\"lucidseed vita\", \"í´ë Œì§• ì›Œí„° 400ml\"]}\n",
    "{\"lines\": [\"lucidseed vita\", \"í´ë Œì§• ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"miraflow aqua\", \"ì„ í¬ë¦¼ 60ml\"]}\n",
    "{\"lines\": [\"miraflow aqua\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"solun velvet\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"solun velvet\", \"ë¡œì…˜ 300ml\"]}\n",
    "{\"lines\": [\"aurevia mild\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"aurevia mild\", \"ì•„ì´ í¬ë¦¼ 15g\"]}\n",
    "{\"lines\": [\"glaciera smooth\", \"ë¯¸ìŠ¤íŠ¸ 50ml\"]}\n",
    "{\"lines\": [\"glaciera smooth\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"fawnroot bloom\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"fawnroot bloom\", \"ìˆ˜ë”©ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"rosenest cloud\", \"ìƒ´í‘¸ 500ml\"]}\n",
    "{\"lines\": [\"rosenest cloud\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 400ml\"]}\n",
    "{\"lines\": [\"opaline warm\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 50g\"]}\n",
    "{\"lines\": [\"opaline warm\", \"ë©€í‹°ë°¤ 20g\"]}\n",
    "{\"lines\": [\"candlea zen\", \"ë¦½ë°¤ 5g\"]}\n",
    "{\"lines\": [\"candlea zen\", \"ë¦½í‹´íŠ¸ 4g\"]}\n",
    "{\"lines\": [\"nortex calm\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"nortex calm\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"silvaris dew\", \"ì•½ì‚°ì„± í¼ 120ml\"]}\n",
    "{\"lines\": [\"silvaris dew\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"cedarvein pure\", \"ë°”ë”” ë¡œì…˜ 473ml\"]}\n",
    "{\"lines\": [\"cedarvein pure\", \"í•¸ë“œí¬ë¦¼ 30ml\"]}\n",
    "{\"lines\": [\"mistralyn soft\", \"ë°”ë””ì›Œì‹œ 400ml\"]}\n",
    "{\"lines\": [\"mistralyn soft\", \"ë°”ë”” ë¡œì…˜ 200ml\"]}\n",
    "{\"lines\": [\"duskelle zero\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"duskelle zero\", \"ì„¸ëŸ¼ 40ml\"]}\n",
    "{\"lines\": [\"purenova lift\", \"í´ë Œì§• ì˜¤ì¼ 170ml\"]}\n",
    "{\"lines\": [\"purenova lift\", \"í´ë Œì§• í¼ 100ml\"]}\n",
    "{\"lines\": [\"bluecove hydra\", \"í´ë Œì§• ì›Œí„° 200ml\"]}\n",
    "{\"lines\": [\"bluecove hydra\", \"í´ë Œì§• ì ¤ 180ml\"]}\n",
    "{\"lines\": [\"honeyra cica\", \"ì„ í¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"honeyra cica\", \"í† ë„ˆ 250ml\"]}\n",
    "{\"lines\": [\"laventh bright\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"laventh bright\", \"ë¡œì…˜ 150ml\"]}\n",
    "{\"lines\": [\"springleaf fresh\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"springleaf fresh\", \"ì•„ì´ í¬ë¦¼ 15g\"]}\n",
    "{\"lines\": [\"cocomist matte\", \"ë¯¸ìŠ¤íŠ¸ 80ml\"]}\n",
    "{\"lines\": [\"cocomist matte\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"sagehaven glow\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"sagehaven glow\", \"ìˆ˜ë”©ì ¤ 200ml\"]}\n",
    "{\"lines\": [\"breezara satin\", \"ìƒ´í‘¸ 300ml\"]}\n",
    "{\"lines\": [\"breezara satin\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 300ml\"]}\n",
    "{\"lines\": [\"ivorydew herb\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 50g\"]}\n",
    "{\"lines\": [\"ivorydew herb\", \"ë©€í‹°ë°¤ 20g\"]}\n",
    "{\"lines\": [\"monarchia airy\", \"ë¦½ë°¤ 4g\"]}\n",
    "{\"lines\": [\"monarchia airy\", \"ë¦½í‹´íŠ¸ 3.5g\"]}\n",
    "{\"lines\": [\"pebblebay daily\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"pebblebay daily\", \"í˜ì´ìŠ¤ í¬ë¦¼ 70g\"]}\n",
    "{\"lines\": [\"tenderoot night\", \"ì•½ì‚°ì„± í¼ 150ml\"]}\n",
    "{\"lines\": [\"tenderoot night\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"sunwisp clean\", \"ë°”ë”” ë¡œì…˜ 200ml\"]}\n",
    "{\"lines\": [\"sunwisp clean\", \"í•¸ë“œí¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"rainora tint\", \"ë°”ë””ì›Œì‹œ 500ml\"]}\n",
    "{\"lines\": [\"rainora tint\", \"ë°”ë”” ë¡œì…˜ 355ml\"]}\n",
    "{\"lines\": [\"citravale soothe\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"citravale soothe\", \"ì„¸ëŸ¼ 15ml\"]}\n",
    "{\"lines\": [\"veloria vita\", \"í´ë Œì§• ì˜¤ì¼ 150ml\"]}\n",
    "{\"lines\": [\"veloria vita\", \"í´ë Œì§• í¼ 150ml\"]}\n",
    "{\"lines\": [\"coralyn aqua\", \"í´ë Œì§• ì›Œí„° 400ml\"]}\n",
    "{\"lines\": [\"coralyn aqua\", \"í´ë Œì§• ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"mossmint velvet\", \"ì„ í¬ë¦¼ 60ml\"]}\n",
    "{\"lines\": [\"mossmint velvet\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"lilacove mild\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"lilacove mild\", \"ë¡œì…˜ 200ml\"]}\n",
    "{\"lines\": [\"plumaria smooth\", \"í˜ì´ìŠ¤ í¬ë¦¼ 30g\"]}\n",
    "{\"lines\": [\"plumaria smooth\", \"ì•„ì´ í¬ë¦¼ 20g\"]}\n",
    "{\"lines\": [\"starling bloom\", \"ë¯¸ìŠ¤íŠ¸ 50ml\"]}\n",
    "{\"lines\": [\"starling bloom\", \"í† ë„ˆ 200ml\"]}\n",
    "{\"lines\": [\"mistoria cloud\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"mistoria cloud\", \"ìˆ˜ë”©ì ¤ 150ml\"]}\n",
    "{\"lines\": [\"seaquill warm\", \"ìƒ´í‘¸ 400ml\"]}\n",
    "{\"lines\": [\"seaquill warm\", \"íŠ¸ë¦¬íŠ¸ë¨¼íŠ¸ 200ml\"]}\n",
    "{\"lines\": [\"dawnmuse zen\", \"í´ë ˆì´ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"dawnmuse zen\", \"ë©€í‹°ë°¤ 15g\"]}\n",
    "{\"lines\": [\"aurorite calm\", \"ë¦½ë°¤ 5g\"]}\n",
    "{\"lines\": [\"aurorite calm\", \"ë¦½í‹´íŠ¸ 4g\"]}\n",
    "{\"lines\": [\"glowridge dew\", \"ìŠ¬ë¦¬í•‘ ë§ˆìŠ¤í¬ 100g\"]}\n",
    "{\"lines\": [\"glowridge dew\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"silkbay pure\", \"ì•½ì‚°ì„± í¼ 120ml\"]}\n",
    "{\"lines\": [\"silkbay pure\", \"í† ë„ˆ 150ml\"]}\n",
    "{\"lines\": [\"cloudmori soft\", \"ë°”ë”” ë¡œì…˜ 300ml\"]}\n",
    "{\"lines\": [\"cloudmori soft\", \"í•¸ë“œí¬ë¦¼ 100ml\"]}\n",
    "{\"lines\": [\"petalfog zero\", \"ë°”ë””ì›Œì‹œ 355ml\"]}\n",
    "{\"lines\": [\"petalfog zero\", \"ë°”ë”” ë¡œì…˜ 473ml\"]}\n",
    "{\"lines\": [\"nectarune lift\", \"í† ë„ˆ 230ml\"]}\n",
    "{\"lines\": [\"nectarune lift\", \"ì„¸ëŸ¼ 40ml\"]}\n",
    "{\"lines\": [\"halcyon hydra\", \"í´ë Œì§• ì˜¤ì¼ 200ml\"]}\n",
    "{\"lines\": [\"halcyon hydra\", \"í´ë Œì§• í¼ 100ml\"]}\n",
    "{\"lines\": [\"mellowine cica\", \"í´ë Œì§• ì›Œí„° 300ml\"]}\n",
    "{\"lines\": [\"mellowine cica\", \"í´ë Œì§• ì ¤ 180ml\"]}\n",
    "{\"lines\": [\"satinelle lift\", \"ì„ í¬ë¦¼ 50ml\"]}\n",
    "{\"lines\": [\"satinelle lift\", \"í† ë„ˆ 170ml\"]}\n",
    "{\"lines\": [\"moodleaf hydra\", \"ì„  ì—ì„¼ìŠ¤ 50ml\"]}\n",
    "{\"lines\": [\"moodleaf hydra\", \"ë¡œì…˜ 150ml\"]}\n",
    "{\"lines\": [\"clearhaven cica\", \"í˜ì´ìŠ¤ í¬ë¦¼ 50g\"]}\n",
    "{\"lines\": [\"clearhaven cica\", \"ì•„ì´ í¬ë¦¼ 20g\"]}\n",
    "{\"lines\": [\"sproutia bright\", \"ë¯¸ìŠ¤íŠ¸ 100ml\"]}\n",
    "{\"lines\": [\"sproutia bright\", \"í† ë„ˆ 180ml\"]}\n",
    "{\"lines\": [\"luminote fresh\", \"ì•°í”Œ 30ml\"]}\n",
    "{\"lines\": [\"luminote fresh\", \"ìˆ˜ë”©ì ¤ 200ml\"]}\n",
    "\"\"\".strip()\n",
    "\n",
    "# ë°ì´í„° ë¡œë“œ\n",
    "raw_records = [json.loads(line) for line in RECORDS_JSONL.splitlines() if line.strip()]\n",
    "\n",
    "# ID ì¬í• ë‹¹\n",
    "records = []\n",
    "for i, rec in enumerate(raw_records):\n",
    "    rec['id'] = f\"{i+1:05d}\"\n",
    "    records.append(rec)\n",
    "\n",
    "# Pillow ë¦¬ìƒ˜í”Œë§ í˜¸í™˜ì„±\n",
    "try: RESAMPLE_LANCZOS = Image.Resampling.LANCZOS\n",
    "except AttributeError: RESAMPLE_LANCZOS = Image.LANCZOS\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def get_clean_font_name(font_path: Path) -> str:\n",
    "    stem = font_path.stem\n",
    "    clean_name = re.sub(r\"[^a-zA-Z0-9ê°€-í£]\", \"\", stem)\n",
    "    return clean_name\n",
    "\n",
    "def get_random_dark_color():\n",
    "    \"\"\"\n",
    "    [í…ŒìŠ¤íŠ¸ìš©] ìƒ‰ìƒì´ ì ìš©ë˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´\n",
    "    ì¼ë¶€ëŸ¬ í‹°ê°€ ë§ì´ ë‚˜ëŠ” ìƒ‰ìƒ(íŒŒë‘, ë¹¨ê°•, ì´ˆë¡ ë“±)ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ë¬´ì¡°ê±´ ìœ ì±„ìƒ‰ ë°˜í™˜\n",
    "    base_r = random.randint(50, 150)\n",
    "    base_g = random.randint(50, 150)\n",
    "    base_b = random.randint(50, 150)\n",
    "\n",
    "    # ë„ˆë¬´ ë°ì•„ì„œ í°ìƒ‰ ë°°ê²½ì— ì•ˆ ë³´ì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ í•˜ë‚˜ëŠ” ì–´ë‘¡ê²Œ\n",
    "    darken = random.choice(['r', 'g', 'b'])\n",
    "    if darken == 'r': base_r = random.randint(0, 50)\n",
    "    elif darken == 'g': base_g = random.randint(0, 50)\n",
    "    else: base_b = random.randint(0, 50)\n",
    "\n",
    "    return (base_r, base_g, base_b)\n",
    "\n",
    "def normalize_lines(lines):\n",
    "    \"\"\"\n",
    "    1. ìŠ¬ë˜ì‹œ(/) ë¶„ë¦¬\n",
    "    2. ìš©ëŸ‰ í‘œê¸° ë¶„ë¦¬\n",
    "    3. [NEW] ë¬¸ë‹¨ ì‚¬ì´ ë¹ˆ ì¤„(' ') ì‚½ì…\n",
    "    \"\"\"\n",
    "    temp_lines = []\n",
    "\n",
    "    # 1ì°¨: ê¸°ì¡´ ì •ì±… ë¶„ë¦¬\n",
    "    for line in lines:\n",
    "        s = str(line).strip()\n",
    "        if not s: continue\n",
    "        if SLASH_POLICY == \"split\" and \"/\" in s:\n",
    "            parts = [p.strip() for p in re.split(r\"\\s*/\\s*\", s) if p.strip()]\n",
    "            temp_lines.extend(parts)\n",
    "        elif SLASH_POLICY == \"remove\":\n",
    "            temp_lines.append(re.sub(r\"\\s*/\\s*\", \" \", s).strip())\n",
    "        else:\n",
    "            temp_lines.append(s)\n",
    "\n",
    "    # 2ì°¨: ìš©ëŸ‰ íŒ¨í„´ ë¶„ë¦¬\n",
    "    parsed_lines = []\n",
    "    for line in temp_lines:\n",
    "        match = VOLUME_PATTERN.match(line)\n",
    "        if match:\n",
    "            main_part = match.group(1).strip()\n",
    "            vol_part = match.group(2).strip()\n",
    "            if main_part: parsed_lines.append(main_part)\n",
    "            parsed_lines.append(vol_part)\n",
    "        else:\n",
    "            parsed_lines.append(line)\n",
    "\n",
    "    # 3ì°¨: ë¹ˆ ì¤„ ì‚½ì… (Double Spacing)\n",
    "    if ADD_EMPTY_LINE and len(parsed_lines) > 0:\n",
    "        spaced_lines = []\n",
    "        for i, item in enumerate(parsed_lines):\n",
    "            spaced_lines.append(item)\n",
    "            # ë§ˆì§€ë§‰ ì•„ì´í…œì´ ì•„ë‹ˆë©´ ê³µë°±(\" \") ì¶”ê°€ -> ì´ê²Œ ë¹ˆ ì¤„ ì—­í• \n",
    "            if i < len(parsed_lines) - 1:\n",
    "                spaced_lines.append(\" \")\n",
    "        return spaced_lines\n",
    "\n",
    "    return parsed_lines\n",
    "\n",
    "def best_cmap(font_path: Path) -> dict:\n",
    "    try:\n",
    "        tt = TTFont(str(font_path), lazy=True)\n",
    "        cmap = tt[\"cmap\"].getBestCmap() or {}\n",
    "        try: tt.close()\n",
    "        except: pass\n",
    "        return cmap\n",
    "    except: return {}\n",
    "\n",
    "def missing_chars(cmap: dict, text: str):\n",
    "    miss = []\n",
    "    for ch in set(text):\n",
    "        if ch.isspace(): continue\n",
    "        if ord(ch) not in cmap: miss.append(ch)\n",
    "    return sorted(miss)\n",
    "\n",
    "def tight_crop_white(img: Image.Image) -> Image.Image:\n",
    "    if not PIXEL_CROP: return img\n",
    "    bg = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "    diff = ImageChops.difference(img, bg)\n",
    "    bbox = diff.getbbox()\n",
    "    return img.crop(bbox) if bbox else img\n",
    "\n",
    "def fit_into_square(img: Image.Image, size: int) -> tuple[Image.Image, float, tuple[int,int]]:\n",
    "    w, h = img.size\n",
    "    scale = min(size / w, size / h, 1.0)\n",
    "    if scale < 1.0:\n",
    "        nw = max(1, int(round(w * scale)))\n",
    "        nh = max(1, int(round(h * scale)))\n",
    "        img = img.resize((nw, nh), resample=RESAMPLE_LANCZOS)\n",
    "        w, h = img.size\n",
    "    canvas = Image.new(\"RGB\", (size, size), (255, 255, 255))\n",
    "    ox = (size - w) // 2\n",
    "    oy = (size - h) // 2\n",
    "    canvas.paste(img, (ox, oy))\n",
    "    return canvas, float(scale), (int(ox), int(oy))\n",
    "\n",
    "def get_text_dimensions(text_string, font):\n",
    "    dummy = Image.new(\"RGB\", (1, 1))\n",
    "    draw = ImageDraw.Draw(dummy)\n",
    "    if hasattr(draw, \"textbbox\"):\n",
    "        l, t, r, b = draw.textbbox((0, 0), text_string, font=font)\n",
    "        return r - l, b - t\n",
    "    else:\n",
    "        return draw.textsize(text_string, font)\n",
    "\n",
    "# =========================\n",
    "# ë Œë”ë§ í•¨ìˆ˜ (ëœë¤ ìƒ‰ìƒ ì ìš©)\n",
    "# =========================\n",
    "def render_multi_size_block(lines, font_path: Path): # -> tuple[Image.Image, tuple]\n",
    "    font_main = ImageFont.truetype(str(font_path), RENDER_FONT_SIZE)\n",
    "    font_small = ImageFont.truetype(str(font_path), int(RENDER_FONT_SIZE * SMALL_FONT_RATIO))\n",
    "\n",
    "    # â­ ëœë¤ ìƒ‰ìƒ ìƒì„±\n",
    "    text_color = get_random_dark_color()\n",
    "\n",
    "    parsed_lines = []\n",
    "    total_h = 0\n",
    "    max_w = 0\n",
    "\n",
    "    for line in lines:\n",
    "        # ê³µë°± ë¼ì¸(\" \")ì€ ì •ê·œì‹ ë§¤ì¹˜ X -> font_main ì‚¬ìš© -> ë¹ˆ ì¤„ ë†’ì´ í™•ë³´\n",
    "        is_vol = bool(VOLUME_PATTERN.match(line))\n",
    "        font = font_small if is_vol else font_main\n",
    "\n",
    "        w, h = get_text_dimensions(line, font)\n",
    "\n",
    "        # ë§Œì•½ \" \" ê³µë°± ì¤„ì´ë¼ë©´ ë†’ì´ëŠ” í°íŠ¸ í¬ê¸°ë§Œí¼ ë³´ì¥, ë„ˆë¹„ëŠ” 0ì— ê°€ê¹Œì›€\n",
    "        if not line.strip():\n",
    "            h = RENDER_FONT_SIZE # ê°•ì œ ë†’ì´ ì§€ì •\n",
    "\n",
    "        parsed_lines.append({\"text\": line, \"font\": font, \"w\": w, \"h\": h})\n",
    "        max_w = max(max_w, w)\n",
    "        total_h += h\n",
    "\n",
    "    # ì¤„ ê°„ê²© ì¶”ê°€\n",
    "    total_h += (len(lines) - 1) * LINE_GAP if len(lines) > 0 else 0\n",
    "\n",
    "    img_w = max_w + 2 * PAD\n",
    "    img_h = total_h + 2 * PAD\n",
    "    img = Image.new(\"RGB\", (img_w, img_h), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    current_y = PAD\n",
    "    for item in parsed_lines:\n",
    "        text = item[\"text\"]\n",
    "        font = item[\"font\"]\n",
    "        line_w = item[\"w\"]\n",
    "        line_h = item[\"h\"]\n",
    "\n",
    "        x = (img_w - line_w) // 2\n",
    "\n",
    "        # ê³µë°±ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì‹¤ì œ ê·¸ë¦¬ê¸°\n",
    "        if text.strip():\n",
    "            # â­ fill ì˜µì…˜ì— ëœë¤ ìƒ‰ìƒ ì ìš©\n",
    "            draw.text((x, current_y), text, font=font, fill=text_color)\n",
    "\n",
    "        current_y += line_h + LINE_GAP\n",
    "\n",
    "    # ì´ë¯¸ì§€ì™€ ì‚¬ìš©ëœ ìƒ‰ìƒ ë°˜í™˜\n",
    "    return img, text_color\n",
    "\n",
    "# =========================\n",
    "# ë©”ì¸ í”„ë¡œì„¸ìŠ¤\n",
    "# =========================\n",
    "def process_single_font_safe(font_path, record_list):\n",
    "    clean_font_name = get_clean_font_name(font_path) or \"UnknownFont\"\n",
    "    out_dir = OUT_ROOT / clean_font_name\n",
    "\n",
    "    ann_path  = out_dir / \"annotations.jsonl\"\n",
    "    if ann_path.exists():\n",
    "        print(f\"â© Skipping {clean_font_name}\", flush=True)\n",
    "        return\n",
    "\n",
    "    cmap = best_cmap(font_path)\n",
    "    if not cmap:\n",
    "        print(f\"âš ï¸ Bad font: {clean_font_name}\", flush=True)\n",
    "        return\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    miss_path = out_dir / \"missing_glyphs.jsonl\"\n",
    "    saved, skipped = 0, 0\n",
    "\n",
    "    with ann_path.open(\"w\", encoding=\"utf-8\") as ann_f, miss_path.open(\"w\", encoding=\"utf-8\") as miss_f:\n",
    "        for rec in record_list:\n",
    "            rid = rec.get(\"id\")\n",
    "            raw_lines = rec.get(\"lines\", [])\n",
    "            lines = normalize_lines(raw_lines)\n",
    "            text = \"\\n\".join(lines)\n",
    "\n",
    "            miss = missing_chars(cmap, text)\n",
    "            if miss:\n",
    "                miss_f.write(json.dumps({\"id\": rid, \"font\": str(font_path), \"missing_chars\": miss}, ensure_ascii=False) + \"\\n\")\n",
    "                if SKIP_MISSING_GLYPHS:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                # ë Œë”ë§ í˜¸ì¶œ (ì´ë¯¸ì§€ì™€ ìƒ‰ìƒ ì •ë³´ ë°›ìŒ)\n",
    "                img, used_text_color = render_multi_size_block(lines, font_path)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            img = tight_crop_white(img)\n",
    "            inner_w, inner_h = img.size\n",
    "            final_img, scale, (ox, oy) = fit_into_square(img, OUTPUT_SIZE)\n",
    "\n",
    "            filename = f\"{clean_font_name}_{rid}.png\"\n",
    "            final_img.save(out_dir / filename, \"PNG\")\n",
    "\n",
    "            meta = {\n",
    "                \"id\": rid,\n",
    "                \"file_name\": filename,\n",
    "                \"image_path\": f\"{clean_font_name}/{filename}\",\n",
    "                \"font_name\": clean_font_name,\n",
    "                \"output_size\": OUTPUT_SIZE,\n",
    "                \"render_font_size\": RENDER_FONT_SIZE,\n",
    "                \"small_font_ratio\": SMALL_FONT_RATIO,\n",
    "                \"fit_scale\": float(scale),\n",
    "                \"paste_offset\": [ox, oy],\n",
    "                \"text_color_rgb\": used_text_color, # âœ… ì‚¬ìš©ëœ ìƒ‰ìƒ ì •ë³´ ì €ì¥\n",
    "                \"lines\": lines\n",
    "            }\n",
    "            ann_f.write(json.dumps(meta, ensure_ascii=False) + \"\\n\")\n",
    "            saved += 1\n",
    "\n",
    "    print(f\"[{clean_font_name}] Saved: {saved}, Skipped: {skipped}\", flush=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "    ttf_paths = sorted([p for p in FONTS_DIR.rglob(\"*.ttf\") if p.is_file()])\n",
    "\n",
    "    print(f\"Records: {len(records)}, Fonts: {len(ttf_paths)}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"ğŸ¨ [Smart Color Mode] Generating Front Labels with Random Dark Colors...\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    for i, font_path in enumerate(ttf_paths):\n",
    "        print(f\"ğŸ‘‰ [{i+1}/{len(ttf_paths)}] {font_path.name} ... \", end=\"\", flush=True)\n",
    "        try: process_single_font_safe(font_path, records)\n",
    "        except KeyboardInterrupt: break\n",
    "        except Exception as e: print(f\"\\nâŒ Error: {e}\", flush=True)\n",
    "\n",
    "    print(\"\\nâœ… All Done.\")"
   ],
   "id": "8cb5a759f6c0cc26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records: 200, Fonts: 150\n",
      "--------------------------------------------------\n",
      "ğŸ¨ [Smart Color Mode] Generating Front Labels with Random Dark Colors...\n",
      "--------------------------------------------------\n",
      "ğŸ‘‰ [1/150] AritaBuriKR-Medium.ttf ... [AritaBuriKRMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [2/150] AstaSans-Regular.ttf ... [AstaSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [3/150] Binggrae.ttf ... [Binggrae] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [4/150] BinggraeII.ttf ... [BinggraeII] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [5/150] BinggraeMelona.ttf ... [BinggraeMelona] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [6/150] BinggraeSamanco.ttf ... [BinggraeSamanco] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [7/150] BinggraeTaom.ttf ... [BinggraeTaom] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [8/150] BMHANNA_11yrs_ttf.ttf ... [BMHANNA11yrsttf] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [9/150] BookkGothic_Light.ttf ... [BookkGothicLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [10/150] BookkMyungjo_Light.ttf ... [BookkMyungjoLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [11/150] Cafe24Simplehae-v2.0.ttf ... [Cafe24Simplehaev20] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [12/150] Cafe24SsurroundAir-v1.1.ttf ... [Cafe24SsurroundAirv11] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [13/150] Cafe24Syongsyong-v2.0.ttf ... [Cafe24Syongsyongv20] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [14/150] ChosunGs.TTF ... [ChosunGs] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [15/150] ChosunGu.TTF ... [ChosunGu] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [16/150] ChosunKg.TTF ... [ChosunKg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [17/150] ChosunKm.TTF ... [ChosunKm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [18/150] ChosunNm.ttf ... [ChosunNm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [19/150] ChosunSg.TTF ... [ChosunSg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [20/150] ChosunSm.TTF ... [ChosunSm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [21/150] D2Coding-Ver1.3.2-20180524.ttf ... [D2CodingVer13220180524] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [22/150] Dongle-Light.ttf ... [DongleLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [23/150] EliceDigitalBaeum_Regular.ttf ... [EliceDigitalBaeumRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [24/150] EliceDigitalCodingverH_Bold.ttf ... [EliceDigitalCodingverHBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [25/150] EliceDXNeolli-Medium.ttf ... [EliceDXNeolliMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [26/150] esamanru Medium.ttf ... [esamanruMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [27/150] Eulyoo1945-Regular.ttf ... [Eulyoo1945Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [28/150] Freesentation-4Regular.ttf ... [Freesentation4Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [29/150] FreesentationVF.ttf ... [FreesentationVF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [30/150] GapyeongHanseokbongR.ttf ... [GapyeongHanseokbongR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [31/150] GmarketSansTTFMedium.ttf ... [GmarketSansTTFMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [32/150] goorm-sans-regular.ttf ... [goormsansregular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [33/150] goorm_Sans_Code_400.ttf ... [goormSansCode400] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [34/150] GowunDodum-Regular.ttf ... [GowunDodumRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [35/150] Gumi Dotum.ttf ... [GumiDotum] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [36/150] Hahmlet-Black.ttf ... [HahmletBlack] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [37/150] Hahmlet-Thin.ttf ... [HahmletThin] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [38/150] Hakgyoansim Allimjang TTF R.ttf ... [HakgyoansimAllimjangTTFR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [39/150] Hakgyoansim Badasseugi TTF L.ttf ... [HakgyoansimBadasseugiTTFL] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [40/150] Hakgyoansim Geurimilgi TTF R.ttf ... [HakgyoansimGeurimilgiTTFR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [41/150] Hakgyoansim Nadeuri TTF B.ttf ... [HakgyoansimNadeuriTTFB] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [42/150] Hakgyoansim_BoardmarkerR.ttf ... [HakgyoansimBoardmarkerR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [43/150] Hakgyoansim_JayusiganR.ttf ... [HakgyoansimJayusiganR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [44/150] Hakgyoansim_OcarinaR.ttf ... [HakgyoansimOcarinaR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [45/150] Hakgyoansim_SangjangR.ttf ... [HakgyoansimSangjangR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [46/150] Hakgyoansim_SiganpyoR.ttf ... [HakgyoansimSiganpyoR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [47/150] HakgyoansimBareonbatangR.ttf ... [HakgyoansimBareonbatangR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [48/150] HakgyoansimBareondotumR.ttf ... [HakgyoansimBareondotumR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [49/150] HakgyoansimSantteutdotumM.ttf ... [HakgyoansimSantteutdotumM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [50/150] HakgyoansimTtwimteulR.ttf ... [HakgyoansimTtwimteulR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [51/150] HakgyoansimUndongjangL.ttf ... [HakgyoansimUndongjangL] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [52/150] HancomSans-SemiBold_0.ttf ... [HancomSansSemiBold0] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [53/150] HSJandari-Regular.ttf ... [HSJandariRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [54/150] HSê²¨ìš¸ëˆˆê½ƒì²´.ttf ... [HSê²¨ìš¸ëˆˆê½ƒì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [55/150] Interop-Regular.ttf ... [InteropRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [56/150] JejuGothic.ttf ... [JejuGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [57/150] JejuHallasan.ttf ... [JejuHallasan] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [58/150] JejuMyeongjo.ttf ... [JejuMyeongjo] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [59/150] KakaoBigSans-Regular.ttf ... [KakaoBigSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [60/150] KakaoSmallSans-Regular.ttf ... [KakaoSmallSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [61/150] KBO Dia Gothic_medium.ttf ... [KBODiaGothicmedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [62/150] KCCChassam.ttf ... [KCCChassam] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [63/150] KCCImkwontaek.ttf ... [KCCImkwontaek] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [64/150] KCCì€ì˜ì²´.ttf ... [KCCì€ì˜ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [65/150] KimjungchulGothic-Regular.ttf ... [KimjungchulGothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [66/150] KimjungchulMyungjo-Regular.ttf ... [KimjungchulMyungjoRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [67/150] KimjungchulScript-Bold.ttf ... [KimjungchulScriptBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [68/150] KOHINanum_Light.ttf ... [KOHINanumLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [69/150] KoPubWorld Batang Medium.ttf ... [KoPubWorldBatangMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [70/150] KoPubWorld Dotum Medium.ttf ... [KoPubWorldDotumMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [71/150] KOTRA_GOTHIC.ttf ... [KOTRAGOTHIC] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [72/150] KOTRA_SONGEULSSI.ttf ... [KOTRASONGEULSSI] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [73/150] KyoboHandwriting2024psw.ttf ... [KyoboHandwriting2024psw] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [74/150] LINESeedKR-Rg.ttf ... [LINESeedKRRg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [75/150] MapoHongdaeFreedom.ttf ... [MapoHongdaeFreedom] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [76/150] MBC 1961êµ´ë¦¼ M.ttf ... [MBC1961êµ´ë¦¼M] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [77/150] MinSans-Light.ttf ... [MinSansLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [78/150] MinSans-Regular.ttf ... [MinSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [79/150] MinSansVF.ttf ... [MinSansVF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [80/150] MiraeroNormal.ttf ... [MiraeroNormal] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [81/150] Moneygraphy-Rounded.ttf ... [MoneygraphyRounded] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [82/150] Mungyeong-Gamhong-Apple.ttf ... [MungyeongGamhongApple] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [83/150] NanumBarunGothic-YetHangul.ttf ... [NanumBarunGothicYetHangul] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [84/150] NanumBarunGothic.ttf ... [NanumBarunGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [85/150] NanumBarunpenR.ttf ... [NanumBarunpenR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [86/150] NanumGothic.ttf ... [NanumGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [87/150] NanumHumanRegular.ttf ... [NanumHumanRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [88/150] NanumMyeongjo-YetHangul.ttf ... [NanumMyeongjoYetHangul] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [89/150] NanumMyeongjo.ttf ... [NanumMyeongjo] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [90/150] NanumSquareR.ttf ... [NanumSquareR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [91/150] netmarbleM.ttf ... [netmarbleM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [92/150] NEXON Kart Gothic Kor Medium.ttf ... [NEXONKartGothicKorMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [93/150] NEXONLv1GothicRegular.ttf ... [NEXONLv1GothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [94/150] NotoSansKR-Regular.ttf ... [NotoSansKRRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [95/150] NotoSerifKR-Regular.ttf ... [NotoSerifKRRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [96/150] ONE Mobile Regular.ttf ... [ONEMobileRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [97/150] Paperlogy-4Regular.ttf ... [Paperlogy4Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [98/150] PyeojinGothic-Light.ttf ... [PyeojinGothicLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [99/150] PyeojinGothic-Regular.ttf ... [PyeojinGothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [100/150] PyeongChang-Regular.ttf ... [PyeongChangRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [101/150] RiaSans-Regular.ttf ... [RiaSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [102/150] SB ì–´ê·¸ë¡œ M.ttf ... [SBì–´ê·¸ë¡œM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [103/150] SejongGeulggot.ttf ... [SejongGeulggot] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [104/150] SeoulAlrimTTF-Medium.ttf ... [SeoulAlrimTTFMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [105/150] SeoulNamsanB.ttf ... [SeoulNamsanB] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [106/150] Spoqa Han Sans Regular.ttf ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103736 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SpoqaHanSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [107/150] SpoqaHanSansNeo-Regular.ttf ... [SpoqaHanSansNeoRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [108/150] STUNNING.ttf ... [STUNNING] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [109/150] SUIT-Variable.ttf ... [SUITVariable] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [110/150] The Jamsil 3 Regular.ttf ... [TheJamsil3Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [111/150] THEFACESHOP+INKLIPQUID(ìœˆë„ìš°ìš©).ttf ... [THEFACESHOPINKLIPQUIDìœˆë„ìš°ìš©] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [112/150] Tlabì‹ ì˜ë³µì²´.ttf ... [Tlabì‹ ì˜ë³µì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [113/150] UhBee Se_hyun.ttf ... [UhBeeSehyun] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [114/150] WantedSans-Regular.ttf ... [WantedSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [115/150] WantedSansVariable.ttf ... [WantedSansVariable] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [116/150] YES24GothicR.ttf ... [YES24GothicR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [117/150] YES24MyoungjoR.ttf ... [YES24MyoungjoR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [118/150] YoonChildfundkoreaMinGuk.ttf ... [YoonChildfundkoreaMinGuk] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [119/150] ê°•ì›êµìœ¡ëª¨ë‘ Light.ttf ... [ê°•ì›êµìœ¡ëª¨ë‘Light] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [120/150] ê°•ì›êµìœ¡ìƒˆìŒ.ttf ... [ê°•ì›êµìœ¡ìƒˆìŒ] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [121/150] ê°•ì›êµìœ¡í˜„ì˜¥ìƒ˜.ttf ... [ê°•ì›êµìœ¡í˜„ì˜¥ìƒ˜] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [122/150] ê²½ê¸°ì²œë…„ë°”íƒ•_Regular.ttf ... [ê²½ê¸°ì²œë…„ë°”íƒ•Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [123/150] ê²½ê¸°ì²œë…„ì œëª©V_Bold.ttf ... [ê²½ê¸°ì²œë…„ì œëª©VBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [124/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ê³°ì‹ ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ê³°ì‹ ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [125/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ë§›ìˆëŠ”ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ë§›ìˆëŠ”ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [126/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ìƒí•´ì°¬ë¯¸ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ìƒí•´ì°¬ë¯¸ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [127/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì„±ì‹¤ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì„±ì‹¤ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [128/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì†Œë°©ê´€ì˜ ê¸°ë„.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì†Œë°©ê´€ì˜ê¸°ë„] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [129/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì•„ì¸ë§˜ ì†ê¸€ì”¨.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì•„ì¸ë§˜ì†ê¸€ì”¨] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [130/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì—„ë§ˆì‚¬ë‘.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì—„ë§ˆì‚¬ë‘] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [131/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ˆìœ ë¯¼ê²½ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ˆìœë¯¼ê²½ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [132/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ë¯¸ìˆëŠ” í•œê¸€.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ë¯¸ìˆëŠ”í•œê¸€] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [133/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì² í•„ê¸€ì”¨.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì² í•„ê¸€ì”¨] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [134/150] ëŒ€êµ¬ë¶ì„±ë¡œ Light.ttf ... [ëŒ€êµ¬ë¶ì„±ë¡œLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [135/150] ë•…ìŠ¤ë¶€ëŒ€ì°Œê°œ Light.ttf ... [ë•…ìŠ¤ë¶€ëŒ€ì°Œê°œLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [136/150] ì‚¼ìœ¡ëŒ€ì²´ Regular.ttf ... [ì‚¼ìœ¡ëŒ€ì²´Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [137/150] ì„œìš¸í•œê°• ì¥ì²´B.ttf ... [ì„œìš¸í•œê°•ì¥ì²´B] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [138/150] ì„œìš¸í•œê°• ì¥ì²´M.ttf ... [ì„œìš¸í•œê°•ì¥ì²´M] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [139/150] ì˜¨ê¸€ì ê³µë¶€ì˜í•˜ìë‚˜.ttf ... [ì˜¨ê¸€ìê³µë¶€ì˜í•˜ìë‚˜] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [140/150] ì˜¨ê¸€ì ê¹€ì½©í•´.ttf ... [ì˜¨ê¸€ìê¹€ì½©í•´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [141/150] ì˜¨ê¸€ì ë°”ë‹·ë°”ëŒ.ttf ... [ì˜¨ê¸€ìë°”ë‹·ë°”ëŒ] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [142/150] ì˜¨ê¸€ì ìœ„ì”¨ë¦¬ìŠ¤íŠ¸.ttf ... [ì˜¨ê¸€ììœ„ì”¨ë¦¬ìŠ¤íŠ¸] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [143/150] ì˜¨ê¸€ì ì½˜ì½˜ì²´.ttf ... [ì˜¨ê¸€ìì½˜ì½˜ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [144/150] ìœ ì•¤í”¼í”Œ ê³ ë”• KS.ttf ... [ìœ ì•¤í”¼í”Œê³ ë”•KS] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [145/150] ìœ ì•¤í”¼í”Œ ê³ ë”• UNI.ttf ... [ìœ ì•¤í”¼í”Œê³ ë”•UNI] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [146/150] ì´ì„œìœ¤ì²´.ttf ... [ì´ì„œìœ¤ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [147/150] ì •ì„ ë™ê°•ì²´(Regular)TTF.ttf ... [ì •ì„ ë™ê°•ì²´RegularTTF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [148/150] ì •ì„ ì•„ë¦¬ë‘ë¿Œë¦¬ì²´TTF.ttf ... [ì •ì„ ì•„ë¦¬ë‘ë¿Œë¦¬ì²´TTF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [149/150] ì¤‘ë‚˜ì¢‹ì²´ Medium.ttf ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12292 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¤‘ë‚˜ì¢‹ì²´Medium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [150/150] í´ë¦½ì•„íŠ¸ì½”ë¦¬ì•„_Regular.ttf ... [í´ë¦½ì•„íŠ¸ì½”ë¦¬ì•„Regular] Saved: 200, Skipped: 0\n",
      "\n",
      "âœ… All Done.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ê°€ìƒ í™”ì¥í’ˆ ë’·ë©´ì— ë“¤ì–´ê°ˆ í°íŠ¸ ì´ë¯¸ì§€ ìƒì„±í•˜ê¸°",
   "id": "517e9296f9282f88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T12:58:08.129032100Z",
     "start_time": "2025-12-20T12:27:11.250716500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import textwrap  # ì¤„ë°”ê¿ˆ ì²˜ë¦¬ë¥¼ ìœ„í•œ ëª¨ë“ˆ\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageChops\n",
    "from fontTools.ttLib import TTFont\n",
    "\n",
    "# =========================\n",
    "# âœ… 1. ì„¤ì • ë° ê²½ë¡œ\n",
    "# =========================\n",
    "FONTS_DIR  = Path(r\"C:\\Users\\nam\\Desktop\\tst\\ref_fonts_ttf\")\n",
    "OUT_ROOT   = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\BackPage\")\n",
    "CSV_PATH   = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\back_labels_200_fixed_21lines_max34.csv\")\n",
    "\n",
    "# ë Œë”ë§ ì˜µì…˜ (ë’·ë©´ ë¼ë²¨ìš©)\n",
    "RENDER_FONT_SIZE = 42           # ì‘ì€ ê¸€ì”¨\n",
    "LINE_SPACING = 10               # ì¤„ ê°„ê²© (í”½ì…€)\n",
    "IMAGE_WIDTH = 1024              # ì´ë¯¸ì§€ ê°€ë¡œ í¬ê¸°\n",
    "IMAGE_HEIGHT = 1024             # ì´ë¯¸ì§€ ì„¸ë¡œ í¬ê¸°\n",
    "PADDING_X = 50                  # ì¢Œìš° ì—¬ë°±\n",
    "PADDING_Y = 50                  # ìƒí•˜ ì—¬ë°±\n",
    "MAX_CHARS_PER_LINE = 35         # í•œ ì¤„ë‹¹ ìµœëŒ€ ê¸€ì ìˆ˜ (í°íŠ¸ í¬ê¸°ì— ë”°ë¼ ì¡°ì ˆ í•„ìš”)\n",
    "\n",
    "SKIP_MISSING_GLYPHS = True\n",
    "\n",
    "# =========================\n",
    "# âœ… 2. ë°ì´í„° ë¡œë“œ (CSV)\n",
    "# =========================\n",
    "# CSV íŒŒì¼ì„ ì½ì–´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "try:\n",
    "    # ì œê³µëœ íŒŒì¼ëª…ê³¼ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì½ê¸° (í—¤ë”ê°€ ì—†ê±°ë‚˜ 'text' ì»¬ëŸ¼ì´ ìˆë‹¤ê³  ê°€ì •)\n",
    "    # ì‹¤ì œ íŒŒì¼ì— í—¤ë”ê°€ ì—†ë‹¤ë©´ names=['text'], header=None ì‚¬ìš©\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    # í…ìŠ¤íŠ¸ ì»¬ëŸ¼ì´ 'text'ë¼ê³  ê°€ì •, ì—†ë‹¤ë©´ ì²« ë²ˆì§¸ ì»¬ëŸ¼ ì‚¬ìš©\n",
    "    col_name = 'text' if 'text' in df.columns else df.columns[0]\n",
    "    back_label_texts = df[col_name].dropna().astype(str).tolist()\n",
    "\n",
    "    print(f\"Loaded {len(back_label_texts)} back label records.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ CSV Load Error: {e}\")\n",
    "    # í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„° (íŒŒì¼ ì—†ì„ ë•Œ ì‹¤í–‰ìš©)\n",
    "    back_label_texts = [\n",
    "        \"ì‚¬ìš©ë°©ë²•\\nì ë‹¹ëŸ‰ì„ ëœì–´ ì–¼êµ´ì— í´ ë°”ë¥´ì„¸ìš”.\\n\\nì „ì„±ë¶„\\nì •ì œìˆ˜, ê¸€ë¦¬ì„¸ë¦°, ë¶€í‹¸ë Œê¸€ë¼ì´ì½œ\",\n",
    "        \"ì£¼ì˜ì‚¬í•­\\n1. ë¶‰ì€ ë°˜ì  ë“±ì´ ë‚˜íƒ€ë‚˜ë©´ ì‚¬ìš© ì¤‘ë‹¨.\\n2. ìƒì²˜ ë¶€ìœ„ ì‚¬ìš© ê¸ˆì§€.\"\n",
    "    ] * 100\n",
    "\n",
    "# ë°ì´í„° ê°œìˆ˜ ë§ì¶”ê¸° (200ê°œ)\n",
    "back_label_texts = back_label_texts[:200]\n",
    "\n",
    "# =========================\n",
    "# Utils\n",
    "# =========================\n",
    "def get_clean_font_name(font_path: Path) -> str:\n",
    "    stem = font_path.stem\n",
    "    clean_name = re.sub(r\"[^a-zA-Z0-9ê°€-í£]\", \"\", stem)\n",
    "    return clean_name\n",
    "\n",
    "def best_cmap(font_path: Path) -> dict:\n",
    "    try:\n",
    "        tt = TTFont(str(font_path), lazy=True)\n",
    "        cmap = tt[\"cmap\"].getBestCmap() or {}\n",
    "        try: tt.close()\n",
    "        except: pass\n",
    "        return cmap\n",
    "    except: return {}\n",
    "\n",
    "def missing_chars(cmap: dict, text: str):\n",
    "    miss = []\n",
    "    for ch in set(text):\n",
    "        if ch.isspace(): continue\n",
    "        if ord(ch) not in cmap: miss.append(ch)\n",
    "    return sorted(miss)\n",
    "\n",
    "# =========================\n",
    "# â­ [í•µì‹¬] ë’·ë©´ ë¼ë²¨ ë Œë”ë§ (ì¤„ë°”ê¿ˆ + ì¢Œì¸¡ ì •ë ¬)\n",
    "# =========================\n",
    "def render_back_label(full_text, font_path: Path) -> tuple[Image.Image, list]:\n",
    "    font = ImageFont.truetype(str(font_path), RENDER_FONT_SIZE)\n",
    "\n",
    "    # 1. í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (Text Wrapping)\n",
    "    # ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ì—”í„°(\\n)ëŠ” ìœ ì§€í•˜ë˜, ë„ˆë¬´ ê¸´ ì¤„ì€ ìë¦…ë‹ˆë‹¤.\n",
    "    wrapped_lines = []\n",
    "\n",
    "    # ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì¤„ë°”ê¿ˆ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ”\n",
    "    paragraphs = full_text.split('\\n')\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        if not paragraph.strip():\n",
    "            wrapped_lines.append(\"\") # ë¹ˆ ì¤„ ìœ ì§€\n",
    "            continue\n",
    "        # ê¸´ ë¬¸ì¥ì„ ì„¤ì •ëœ ë„ˆë¹„ë¡œ ìë¦„\n",
    "        wrapped = textwrap.wrap(paragraph, width=MAX_CHARS_PER_LINE)\n",
    "        wrapped_lines.extend(wrapped)\n",
    "\n",
    "    # 2. ìº”ë²„ìŠ¤ ë†’ì´ ê³„ì‚°\n",
    "    # (ê¸€ì ë†’ì´ + ì¤„ê°„ê²©) * ì¤„ ìˆ˜\n",
    "    # ì •í™•í•œ ë†’ì´ ê³„ì‚°ì„ ìœ„í•´ bbox ì‚¬ìš©\n",
    "    dummy_draw = ImageDraw.Draw(Image.new(\"RGB\", (1, 1)))\n",
    "    line_heights = []\n",
    "    max_line_w = 0\n",
    "\n",
    "    for line in wrapped_lines:\n",
    "        if not line:\n",
    "            # ë¹ˆ ì¤„ì€ í°íŠ¸ í¬ê¸°ì˜ 50% ì •ë„ ë†’ì´ë¡œ ì„¤ì •\n",
    "            line_heights.append(int(RENDER_FONT_SIZE * 0.5))\n",
    "            continue\n",
    "\n",
    "        if hasattr(dummy_draw, \"textbbox\"):\n",
    "            bbox = dummy_draw.textbbox((0, 0), line, font=font)\n",
    "            w = bbox[2] - bbox[0]\n",
    "            h = bbox[3] - bbox[1]\n",
    "        else:\n",
    "            w, h = dummy_draw.textsize(line, font=font)\n",
    "\n",
    "        line_heights.append(h)\n",
    "        max_line_w = max(max_line_w, w)\n",
    "\n",
    "    # ì „ì²´ í…ìŠ¤íŠ¸ ë†’ì´\n",
    "    total_text_h = sum(line_heights) + (len(wrapped_lines) - 1) * LINE_SPACING\n",
    "\n",
    "    # ìº”ë²„ìŠ¤ ìƒì„± (1024x1024 ê³ ì • or ë‚´ìš©ì— ë§ê²Œ? -> ì—¬ê¸°ì„  1024 Fitì„ ìœ„í•´ ë„‰ë„‰íˆ ìƒì„± í›„ ë¦¬ì‚¬ì´ì¦ˆ)\n",
    "    # ì¼ë‹¨ ë‚´ìš©ì— ë”± ë§ëŠ” ìº”ë²„ìŠ¤ ìƒì„± í›„ ë‚˜ì¤‘ì— Fit\n",
    "    canvas_w = max_line_w + (PADDING_X * 2)\n",
    "    canvas_h = total_text_h + (PADDING_Y * 2)\n",
    "\n",
    "    img = Image.new(\"RGB\", (canvas_w, canvas_h), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # 3. ê·¸ë¦¬ê¸°\n",
    "    current_y = PADDING_Y\n",
    "    for i, line in enumerate(wrapped_lines):\n",
    "        h = line_heights[i]\n",
    "        if line:\n",
    "            draw.text((PADDING_X, current_y), line, font=font, fill=(0, 0, 0))\n",
    "        current_y += h + LINE_SPACING\n",
    "\n",
    "    return img, wrapped_lines\n",
    "\n",
    "def fit_into_square(img: Image.Image, size: int) -> tuple[Image.Image, float, tuple[int,int]]:\n",
    "    # ì´ë¯¸ì§€ë¥¼ 1024x1024 ì•ˆì— ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë„£ê¸°\n",
    "    w, h = img.size\n",
    "    scale = min(size / w, size / h, 1.0) # í™•ëŒ€ëŠ” ì•ˆ í•¨ (1.0 cap)\n",
    "\n",
    "    nw = int(w * scale)\n",
    "    nh = int(h * scale)\n",
    "\n",
    "    img_resized = img.resize((nw, nh), resample=Image.Resampling.LANCZOS)\n",
    "\n",
    "    canvas = Image.new(\"RGB\", (size, size), (255, 255, 255))\n",
    "    # ì¤‘ì•™ ì •ë ¬\n",
    "    ox = (size - nw) // 2\n",
    "    oy = (size - nh) // 2\n",
    "    canvas.paste(img_resized, (ox, oy))\n",
    "\n",
    "    return canvas, scale, (ox, oy)\n",
    "\n",
    "# =========================\n",
    "# ë©”ì¸ í”„ë¡œì„¸ìŠ¤\n",
    "# =========================\n",
    "def process_single_font_back(font_path, text_list):\n",
    "    clean_font_name = get_clean_font_name(font_path) or \"UnknownFont\"\n",
    "    out_dir = OUT_ROOT / clean_font_name\n",
    "\n",
    "    ann_path  = out_dir / \"annotations.jsonl\"\n",
    "    if ann_path.exists():\n",
    "        print(f\"â© Skipping {clean_font_name} (Already done)\", flush=True)\n",
    "        return\n",
    "\n",
    "    cmap = best_cmap(font_path)\n",
    "    if not cmap:\n",
    "        print(f\"âš ï¸ Bad font: {clean_font_name}\", flush=True)\n",
    "        return\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    miss_path = out_dir / \"missing_glyphs.jsonl\"\n",
    "    saved, skipped = 0, 0\n",
    "\n",
    "    with ann_path.open(\"w\", encoding=\"utf-8\") as ann_f, miss_path.open(\"w\", encoding=\"utf-8\") as miss_f:\n",
    "        for idx, text in enumerate(text_list):\n",
    "            rid = f\"{idx+1:05d}\" # ID: 00001 ~ 00200\n",
    "\n",
    "            # ê¸€ì ëˆ„ë½ í™•ì¸\n",
    "            miss = missing_chars(cmap, text)\n",
    "            if miss:\n",
    "                miss_f.write(json.dumps({\"id\": rid, \"font\": str(font_path), \"missing_chars\": miss}, ensure_ascii=False) + \"\\n\")\n",
    "                if SKIP_MISSING_GLYPHS:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                # ë Œë”ë§\n",
    "                img, processed_lines = render_back_label(text, font_path)\n",
    "\n",
    "                # 1024x1024 ì¤‘ì•™ ë°°ì¹˜\n",
    "                final_img, scale, (ox, oy) = fit_into_square(img, IMAGE_HEIGHT)\n",
    "\n",
    "                # ì €ì¥\n",
    "                filename = f\"{clean_font_name}_back_{rid}.png\"\n",
    "                final_img.save(out_dir / filename, \"PNG\")\n",
    "\n",
    "                # ë©”íƒ€ë°ì´í„°\n",
    "                meta = {\n",
    "                    \"id\": rid,\n",
    "                    \"file_name\": filename,\n",
    "                    \"image_path\": f\"{clean_font_name}/{filename}\",\n",
    "                    \"font_name\": clean_font_name,\n",
    "                    \"type\": \"back_label\",\n",
    "                    \"original_text\": text,\n",
    "                    \"processed_lines\": processed_lines, # ì¤„ë°”ê¿ˆëœ ìµœì¢… í…ìŠ¤íŠ¸\n",
    "                    \"fit_scale\": float(scale),\n",
    "                    \"paste_offset\": [ox, oy]\n",
    "                }\n",
    "                ann_f.write(json.dumps(meta, ensure_ascii=False) + \"\\n\")\n",
    "                saved += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                # print(f\"Error on {rid}: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"[{clean_font_name}] Saved: {saved}, Skipped: {skipped}\", flush=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ttf_paths = sorted([p for p in FONTS_DIR.rglob(\"*.ttf\") if p.is_file()])\n",
    "\n",
    "    print(f\"Back Labels: {len(back_label_texts)}, Fonts: {len(ttf_paths)}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    for i, font_path in enumerate(ttf_paths):\n",
    "        print(f\"ğŸ‘‰ [{i+1}/{len(ttf_paths)}] {font_path.name} ... \", end=\"\", flush=True)\n",
    "        try: process_single_font_back(font_path, back_label_texts)\n",
    "        except KeyboardInterrupt: break\n",
    "        except Exception as e: print(f\"\\nâŒ Error: {e}\", flush=True)\n",
    "\n",
    "    print(\"\\nâœ… All Done.\")"
   ],
   "id": "45429338ab8f80f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 back label records.\n",
      "Back Labels: 200, Fonts: 150\n",
      "--------------------------------------------------\n",
      "ğŸ‘‰ [1/150] AritaBuriKR-Medium.ttf ... [AritaBuriKRMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [2/150] AstaSans-Regular.ttf ... [AstaSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [3/150] Binggrae.ttf ... [Binggrae] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [4/150] BinggraeII.ttf ... [BinggraeII] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [5/150] BinggraeMelona.ttf ... [BinggraeMelona] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [6/150] BinggraeSamanco.ttf ... [BinggraeSamanco] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [7/150] BinggraeTaom.ttf ... [BinggraeTaom] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [8/150] BMHANNA_11yrs_ttf.ttf ... [BMHANNA11yrsttf] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [9/150] BookkGothic_Light.ttf ... [BookkGothicLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [10/150] BookkMyungjo_Light.ttf ... [BookkMyungjoLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [11/150] Cafe24Simplehae-v2.0.ttf ... [Cafe24Simplehaev20] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [12/150] Cafe24SsurroundAir-v1.1.ttf ... [Cafe24SsurroundAirv11] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [13/150] Cafe24Syongsyong-v2.0.ttf ... [Cafe24Syongsyongv20] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [14/150] ChosunGs.TTF ... [ChosunGs] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [15/150] ChosunGu.TTF ... [ChosunGu] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [16/150] ChosunKg.TTF ... [ChosunKg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [17/150] ChosunKm.TTF ... [ChosunKm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [18/150] ChosunNm.ttf ... [ChosunNm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [19/150] ChosunSg.TTF ... [ChosunSg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [20/150] ChosunSm.TTF ... [ChosunSm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [21/150] D2Coding-Ver1.3.2-20180524.ttf ... [D2CodingVer13220180524] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [22/150] Dongle-Light.ttf ... [DongleLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [23/150] EliceDigitalBaeum_Regular.ttf ... [EliceDigitalBaeumRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [24/150] EliceDigitalCodingverH_Bold.ttf ... [EliceDigitalCodingverHBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [25/150] EliceDXNeolli-Medium.ttf ... [EliceDXNeolliMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [26/150] esamanru Medium.ttf ... [esamanruMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [27/150] Eulyoo1945-Regular.ttf ... [Eulyoo1945Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [28/150] Freesentation-4Regular.ttf ... [Freesentation4Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [29/150] FreesentationVF.ttf ... [FreesentationVF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [30/150] GapyeongHanseokbongR.ttf ... [GapyeongHanseokbongR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [31/150] GmarketSansTTFMedium.ttf ... [GmarketSansTTFMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [32/150] goorm-sans-regular.ttf ... [goormsansregular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [33/150] goorm_Sans_Code_400.ttf ... [goormSansCode400] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [34/150] GowunDodum-Regular.ttf ... [GowunDodumRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [35/150] Gumi Dotum.ttf ... [GumiDotum] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [36/150] Hahmlet-Black.ttf ... [HahmletBlack] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [37/150] Hahmlet-Thin.ttf ... [HahmletThin] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [38/150] Hakgyoansim Allimjang TTF R.ttf ... [HakgyoansimAllimjangTTFR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [39/150] Hakgyoansim Badasseugi TTF L.ttf ... [HakgyoansimBadasseugiTTFL] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [40/150] Hakgyoansim Geurimilgi TTF R.ttf ... [HakgyoansimGeurimilgiTTFR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [41/150] Hakgyoansim Nadeuri TTF B.ttf ... [HakgyoansimNadeuriTTFB] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [42/150] Hakgyoansim_BoardmarkerR.ttf ... [HakgyoansimBoardmarkerR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [43/150] Hakgyoansim_JayusiganR.ttf ... [HakgyoansimJayusiganR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [44/150] Hakgyoansim_OcarinaR.ttf ... [HakgyoansimOcarinaR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [45/150] Hakgyoansim_SangjangR.ttf ... [HakgyoansimSangjangR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [46/150] Hakgyoansim_SiganpyoR.ttf ... [HakgyoansimSiganpyoR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [47/150] HakgyoansimBareonbatangR.ttf ... [HakgyoansimBareonbatangR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [48/150] HakgyoansimBareondotumR.ttf ... [HakgyoansimBareondotumR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [49/150] HakgyoansimSantteutdotumM.ttf ... [HakgyoansimSantteutdotumM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [50/150] HakgyoansimTtwimteulR.ttf ... [HakgyoansimTtwimteulR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [51/150] HakgyoansimUndongjangL.ttf ... [HakgyoansimUndongjangL] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [52/150] HancomSans-SemiBold_0.ttf ... [HancomSansSemiBold0] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [53/150] HSJandari-Regular.ttf ... [HSJandariRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [54/150] HSê²¨ìš¸ëˆˆê½ƒì²´.ttf ... [HSê²¨ìš¸ëˆˆê½ƒì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [55/150] Interop-Regular.ttf ... [InteropRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [56/150] JejuGothic.ttf ... [JejuGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [57/150] JejuHallasan.ttf ... [JejuHallasan] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [58/150] JejuMyeongjo.ttf ... [JejuMyeongjo] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [59/150] KakaoBigSans-Regular.ttf ... [KakaoBigSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [60/150] KakaoSmallSans-Regular.ttf ... [KakaoSmallSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [61/150] KBO Dia Gothic_medium.ttf ... [KBODiaGothicmedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [62/150] KCCChassam.ttf ... [KCCChassam] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [63/150] KCCImkwontaek.ttf ... [KCCImkwontaek] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [64/150] KCCì€ì˜ì²´.ttf ... [KCCì€ì˜ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [65/150] KimjungchulGothic-Regular.ttf ... [KimjungchulGothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [66/150] KimjungchulMyungjo-Regular.ttf ... [KimjungchulMyungjoRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [67/150] KimjungchulScript-Bold.ttf ... [KimjungchulScriptBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [68/150] KOHINanum_Light.ttf ... [KOHINanumLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [69/150] KoPubWorld Batang Medium.ttf ... [KoPubWorldBatangMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [70/150] KoPubWorld Dotum Medium.ttf ... [KoPubWorldDotumMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [71/150] KOTRA_GOTHIC.ttf ... [KOTRAGOTHIC] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [72/150] KOTRA_SONGEULSSI.ttf ... [KOTRASONGEULSSI] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [73/150] KyoboHandwriting2024psw.ttf ... [KyoboHandwriting2024psw] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [74/150] LINESeedKR-Rg.ttf ... [LINESeedKRRg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [75/150] MapoHongdaeFreedom.ttf ... [MapoHongdaeFreedom] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [76/150] MBC 1961êµ´ë¦¼ M.ttf ... [MBC1961êµ´ë¦¼M] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [77/150] MinSans-Light.ttf ... [MinSansLight] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [78/150] MinSans-Regular.ttf ... [MinSansRegular] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [79/150] MinSansVF.ttf ... [MinSansVF] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [80/150] MiraeroNormal.ttf ... [MiraeroNormal] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [81/150] Moneygraphy-Rounded.ttf ... [MoneygraphyRounded] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [82/150] Mungyeong-Gamhong-Apple.ttf ... [MungyeongGamhongApple] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [83/150] NanumBarunGothic-YetHangul.ttf ... [NanumBarunGothicYetHangul] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [84/150] NanumBarunGothic.ttf ... [NanumBarunGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [85/150] NanumBarunpenR.ttf ... [NanumBarunpenR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [86/150] NanumGothic.ttf ... [NanumGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [87/150] NanumHumanRegular.ttf ... [NanumHumanRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [88/150] NanumMyeongjo-YetHangul.ttf ... [NanumMyeongjoYetHangul] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [89/150] NanumMyeongjo.ttf ... [NanumMyeongjo] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [90/150] NanumSquareR.ttf ... [NanumSquareR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [91/150] netmarbleM.ttf ... [netmarbleM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [92/150] NEXON Kart Gothic Kor Medium.ttf ... [NEXONKartGothicKorMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [93/150] NEXONLv1GothicRegular.ttf ... [NEXONLv1GothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [94/150] NotoSansKR-Regular.ttf ... [NotoSansKRRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [95/150] NotoSerifKR-Regular.ttf ... [NotoSerifKRRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [96/150] ONE Mobile Regular.ttf ... [ONEMobileRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [97/150] Paperlogy-4Regular.ttf ... [Paperlogy4Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [98/150] PyeojinGothic-Light.ttf ... [PyeojinGothicLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [99/150] PyeojinGothic-Regular.ttf ... [PyeojinGothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [100/150] PyeongChang-Regular.ttf ... [PyeongChangRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [101/150] RiaSans-Regular.ttf ... [RiaSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [102/150] SB ì–´ê·¸ë¡œ M.ttf ... [SBì–´ê·¸ë¡œM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [103/150] SejongGeulggot.ttf ... [SejongGeulggot] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [104/150] SeoulAlrimTTF-Medium.ttf ... [SeoulAlrimTTFMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [105/150] SeoulNamsanB.ttf ... [SeoulNamsanB] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [106/150] Spoqa Han Sans Regular.ttf ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103736 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SpoqaHanSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [107/150] SpoqaHanSansNeo-Regular.ttf ... [SpoqaHanSansNeoRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [108/150] STUNNING.ttf ... [STUNNING] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [109/150] SUIT-Variable.ttf ... [SUITVariable] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [110/150] The Jamsil 3 Regular.ttf ... [TheJamsil3Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [111/150] THEFACESHOP+INKLIPQUID(ìœˆë„ìš°ìš©).ttf ... [THEFACESHOPINKLIPQUIDìœˆë„ìš°ìš©] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [112/150] Tlabì‹ ì˜ë³µì²´.ttf ... [Tlabì‹ ì˜ë³µì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [113/150] UhBee Se_hyun.ttf ... [UhBeeSehyun] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [114/150] WantedSans-Regular.ttf ... [WantedSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [115/150] WantedSansVariable.ttf ... [WantedSansVariable] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [116/150] YES24GothicR.ttf ... [YES24GothicR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [117/150] YES24MyoungjoR.ttf ... [YES24MyoungjoR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [118/150] YoonChildfundkoreaMinGuk.ttf ... [YoonChildfundkoreaMinGuk] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [119/150] ê°•ì›êµìœ¡ëª¨ë‘ Light.ttf ... [ê°•ì›êµìœ¡ëª¨ë‘Light] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [120/150] ê°•ì›êµìœ¡ìƒˆìŒ.ttf ... [ê°•ì›êµìœ¡ìƒˆìŒ] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [121/150] ê°•ì›êµìœ¡í˜„ì˜¥ìƒ˜.ttf ... [ê°•ì›êµìœ¡í˜„ì˜¥ìƒ˜] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [122/150] ê²½ê¸°ì²œë…„ë°”íƒ•_Regular.ttf ... [ê²½ê¸°ì²œë…„ë°”íƒ•Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [123/150] ê²½ê¸°ì²œë…„ì œëª©V_Bold.ttf ... [ê²½ê¸°ì²œë…„ì œëª©VBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [124/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ê³°ì‹ ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ê³°ì‹ ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [125/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ë§›ìˆëŠ”ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ë§›ìˆëŠ”ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [126/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ìƒí•´ì°¬ë¯¸ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ìƒí•´ì°¬ë¯¸ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [127/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì„±ì‹¤ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì„±ì‹¤ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [128/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì†Œë°©ê´€ì˜ ê¸°ë„.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì†Œë°©ê´€ì˜ê¸°ë„] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [129/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì•„ì¸ë§˜ ì†ê¸€ì”¨.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì•„ì¸ë§˜ì†ê¸€ì”¨] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [130/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì—„ë§ˆì‚¬ë‘.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì—„ë§ˆì‚¬ë‘] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [131/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ˆìœ ë¯¼ê²½ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ˆìœë¯¼ê²½ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [132/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ë¯¸ìˆëŠ” í•œê¸€.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ë¯¸ìˆëŠ”í•œê¸€] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [133/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì² í•„ê¸€ì”¨.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì² í•„ê¸€ì”¨] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [134/150] ëŒ€êµ¬ë¶ì„±ë¡œ Light.ttf ... [ëŒ€êµ¬ë¶ì„±ë¡œLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [135/150] ë•…ìŠ¤ë¶€ëŒ€ì°Œê°œ Light.ttf ... [ë•…ìŠ¤ë¶€ëŒ€ì°Œê°œLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [136/150] ì‚¼ìœ¡ëŒ€ì²´ Regular.ttf ... [ì‚¼ìœ¡ëŒ€ì²´Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [137/150] ì„œìš¸í•œê°• ì¥ì²´B.ttf ... [ì„œìš¸í•œê°•ì¥ì²´B] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [138/150] ì„œìš¸í•œê°• ì¥ì²´M.ttf ... [ì„œìš¸í•œê°•ì¥ì²´M] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [139/150] ì˜¨ê¸€ì ê³µë¶€ì˜í•˜ìë‚˜.ttf ... [ì˜¨ê¸€ìê³µë¶€ì˜í•˜ìë‚˜] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [140/150] ì˜¨ê¸€ì ê¹€ì½©í•´.ttf ... [ì˜¨ê¸€ìê¹€ì½©í•´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [141/150] ì˜¨ê¸€ì ë°”ë‹·ë°”ëŒ.ttf ... [ì˜¨ê¸€ìë°”ë‹·ë°”ëŒ] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [142/150] ì˜¨ê¸€ì ìœ„ì”¨ë¦¬ìŠ¤íŠ¸.ttf ... [ì˜¨ê¸€ììœ„ì”¨ë¦¬ìŠ¤íŠ¸] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [143/150] ì˜¨ê¸€ì ì½˜ì½˜ì²´.ttf ... [ì˜¨ê¸€ìì½˜ì½˜ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [144/150] ìœ ì•¤í”¼í”Œ ê³ ë”• KS.ttf ... [ìœ ì•¤í”¼í”Œê³ ë”•KS] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [145/150] ìœ ì•¤í”¼í”Œ ê³ ë”• UNI.ttf ... [ìœ ì•¤í”¼í”Œê³ ë”•UNI] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [146/150] ì´ì„œìœ¤ì²´.ttf ... [ì´ì„œìœ¤ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [147/150] ì •ì„ ë™ê°•ì²´(Regular)TTF.ttf ... [ì •ì„ ë™ê°•ì²´RegularTTF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [148/150] ì •ì„ ì•„ë¦¬ë‘ë¿Œë¦¬ì²´TTF.ttf ... [ì •ì„ ì•„ë¦¬ë‘ë¿Œë¦¬ì²´TTF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [149/150] ì¤‘ë‚˜ì¢‹ì²´ Medium.ttf ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12292 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¤‘ë‚˜ì¢‹ì²´Medium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [150/150] í´ë¦½ì•„íŠ¸ì½”ë¦¬ì•„_Regular.ttf ... [í´ë¦½ì•„íŠ¸ì½”ë¦¬ì•„Regular] Saved: 200, Skipped: 0\n",
      "\n",
      "âœ… All Done.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ìƒ‰ìƒì„ ë‹¤ì–‘í•˜ê²Œ ìƒì„±",
   "id": "79b85ccb3b3748d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T13:56:21.439369Z",
     "start_time": "2025-12-20T13:25:47.220657600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from fontTools.ttLib import TTFont\n",
    "\n",
    "# =========================\n",
    "# âœ… 1. ì„¤ì • ë° ê²½ë¡œ\n",
    "# =========================\n",
    "# ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ê²½ë¡œë¥¼ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "FONTS_DIR  = Path(r\"C:\\Users\\nam\\Desktop\\tst\\ref_fonts_ttf\")\n",
    "OUT_ROOT   = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\back_color_aug\") # ì»¬ëŸ¬ ë²„ì „ í´ë”\n",
    "CSV_PATH   = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\back_labels_200_fixed_21lines_max34.csv\") # ì—…ë¡œë“œëœ íŒŒì¼ëª… ì‚¬ìš©\n",
    "\n",
    "# ë Œë”ë§ ì˜µì…˜\n",
    "RENDER_FONT_SIZE = 42\n",
    "LINE_SPACING = 10\n",
    "IMAGE_WIDTH = 1024\n",
    "IMAGE_HEIGHT = 1024\n",
    "PADDING_X = 50\n",
    "PADDING_Y = 50\n",
    "MAX_CHARS_PER_LINE = 35\n",
    "\n",
    "SKIP_MISSING_GLYPHS = True\n",
    "\n",
    "# =========================\n",
    "# âœ… 2. [ìˆ˜ì •ë¨] Front Label ë°©ì‹ì˜ ëœë¤ ìƒ‰ìƒ ìƒì„± í•¨ìˆ˜\n",
    "# =========================\n",
    "def get_random_dark_color():\n",
    "    \"\"\"\n",
    "    [ë³€ê²½ë¨] Front Label ì½”ë“œì™€ ë™ì¼í•œ ë¡œì§.\n",
    "    ë¬´ì¡°ê±´ ê²€ì •/íšŒìƒ‰ë§Œ ë‚˜ì˜¤ëŠ” ê²ƒì„ ë°©ì§€í•˜ê³ ,\n",
    "    ê°€ë…ì„±ì´ ìˆìœ¼ë©´ì„œë„ ë‹¤ì–‘í•œ ìœ ì±„ìƒ‰(íŒŒë‘, ë¹¨ê°•, ì´ˆë¡, ë³´ë¼ ë“± ì–´ë‘ìš´ í†¤)ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # 1. ê¸°ë³¸ ë² ì´ìŠ¤ ìƒ‰ìƒì„ ì•½ê°„ ë°ê²Œ ì¡ìŠµë‹ˆë‹¤ (50~150)\n",
    "    base_r = random.randint(50, 150)\n",
    "    base_g = random.randint(50, 150)\n",
    "    base_b = random.randint(50, 150)\n",
    "\n",
    "    # 2. í° ë°°ê²½ ê°€ë…ì„±ì„ ìœ„í•´ RGB ì¤‘ í•˜ë‚˜ë¥¼ ê°•ì œë¡œ ì–´ë‘¡ê²Œ ë§Œë“­ë‹ˆë‹¤ (0~50)\n",
    "    #    ì´ë ‡ê²Œ í•˜ë©´ 'ì§„í•œ íŒŒë‘', 'ì§„í•œ ì´ˆë¡', 'ì§„í•œ ì™€ì¸ìƒ‰' ë“±ì´ ì˜ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "    darken = random.choice(['r', 'g', 'b'])\n",
    "\n",
    "    if darken == 'r':\n",
    "        base_r = random.randint(0, 50)\n",
    "    elif darken == 'g':\n",
    "        base_g = random.randint(0, 50)\n",
    "    else:\n",
    "        base_b = random.randint(0, 50)\n",
    "\n",
    "    return (base_r, base_g, base_b)\n",
    "\n",
    "# =========================\n",
    "# 3. ë°ì´í„° ë¡œë“œ ë° ìœ í‹¸ë¦¬í‹°\n",
    "# =========================\n",
    "try:\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    col_name = 'text' if 'text' in df.columns else df.columns[0]\n",
    "    back_label_texts = df[col_name].dropna().astype(str).tolist()\n",
    "    # 200ê°œë§Œ ì‚¬ìš©\n",
    "    back_label_texts = back_label_texts[:200]\n",
    "    print(f\"Loaded {len(back_label_texts)} records.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ CSV Load Error: {e}\")\n",
    "    back_label_texts = []\n",
    "\n",
    "def get_clean_font_name(font_path: Path) -> str:\n",
    "    return re.sub(r\"[^a-zA-Z0-9ê°€-í£]\", \"\", font_path.stem)\n",
    "\n",
    "def best_cmap(font_path: Path) -> dict:\n",
    "    try:\n",
    "        tt = TTFont(str(font_path), lazy=True)\n",
    "        cmap = tt[\"cmap\"].getBestCmap() or {}\n",
    "        try: tt.close()\n",
    "        except: pass\n",
    "        return cmap\n",
    "    except: return {}\n",
    "\n",
    "def missing_chars(cmap: dict, text: str):\n",
    "    miss = []\n",
    "    for ch in set(text):\n",
    "        if ch.isspace(): continue\n",
    "        if ord(ch) not in cmap: miss.append(ch)\n",
    "    return sorted(miss)\n",
    "\n",
    "# =========================\n",
    "# 4. ë Œë”ë§ í•¨ìˆ˜ (ëœë¤ ìƒ‰ìƒ ì ìš©)\n",
    "# =========================\n",
    "def render_back_label_color(full_text, font_path: Path) -> tuple[Image.Image, list, tuple]:\n",
    "    font = ImageFont.truetype(str(font_path), RENDER_FONT_SIZE)\n",
    "\n",
    "    # â­ (1) í…ìŠ¤íŠ¸ ìƒ‰ìƒ ê²°ì • (ìˆ˜ì •ëœ í•¨ìˆ˜ ì‚¬ìš©)\n",
    "    text_color = get_random_dark_color()\n",
    "\n",
    "    # (2) ì¤„ë°”ê¿ˆ ì²˜ë¦¬\n",
    "    wrapped_lines = []\n",
    "    paragraphs = full_text.split('\\n')\n",
    "    for paragraph in paragraphs:\n",
    "        if not paragraph.strip():\n",
    "            wrapped_lines.append(\"\")\n",
    "            continue\n",
    "        wrapped = textwrap.wrap(paragraph, width=MAX_CHARS_PER_LINE)\n",
    "        wrapped_lines.extend(wrapped)\n",
    "\n",
    "    # (3) ë†’ì´ ê³„ì‚°\n",
    "    dummy_draw = ImageDraw.Draw(Image.new(\"RGB\", (1, 1)))\n",
    "    line_heights = []\n",
    "    max_line_w = 0\n",
    "\n",
    "    for line in wrapped_lines:\n",
    "        if not line:\n",
    "            line_heights.append(int(RENDER_FONT_SIZE * 0.5))\n",
    "            continue\n",
    "        if hasattr(dummy_draw, \"textbbox\"):\n",
    "            bbox = dummy_draw.textbbox((0, 0), line, font=font)\n",
    "            w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
    "        else:\n",
    "            w, h = dummy_draw.textsize(line, font=font)\n",
    "        line_heights.append(h)\n",
    "        max_line_w = max(max_line_w, w)\n",
    "\n",
    "    total_text_h = sum(line_heights) + (len(wrapped_lines) - 1) * LINE_SPACING\n",
    "\n",
    "    canvas_w = max_line_w + (PADDING_X * 2)\n",
    "    canvas_h = total_text_h + (PADDING_Y * 2)\n",
    "\n",
    "    img = Image.new(\"RGB\", (canvas_w, canvas_h), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # (4) ê·¸ë¦¬ê¸° (ê²°ì •ëœ ìƒ‰ìƒ ì‚¬ìš©)\n",
    "    current_y = PADDING_Y\n",
    "    for i, line in enumerate(wrapped_lines):\n",
    "        h = line_heights[i]\n",
    "        if line:\n",
    "            # â­ text_color ì ìš©\n",
    "            draw.text((PADDING_X, current_y), line, font=font, fill=text_color)\n",
    "        current_y += h + LINE_SPACING\n",
    "\n",
    "    return img, wrapped_lines, text_color\n",
    "\n",
    "def fit_into_square(img: Image.Image, size: int) -> tuple[Image.Image, float, tuple[int,int]]:\n",
    "    w, h = img.size\n",
    "    scale = min(size / w, size / h, 1.0)\n",
    "    nw, nh = int(w * scale), int(h * scale)\n",
    "    img_resized = img.resize((nw, nh), resample=Image.Resampling.LANCZOS)\n",
    "    canvas = Image.new(\"RGB\", (size, size), (255, 255, 255))\n",
    "    ox, oy = (size - nw) // 2, (size - nh) // 2\n",
    "    canvas.paste(img_resized, (ox, oy))\n",
    "    return canvas, scale, (ox, oy)\n",
    "\n",
    "# =========================\n",
    "# 5. ë©”ì¸ ì‹¤í–‰ ë¡œì§\n",
    "# =========================\n",
    "def process_single_font_color(font_path, text_list):\n",
    "    clean_font_name = get_clean_font_name(font_path) or \"UnknownFont\"\n",
    "    out_dir = OUT_ROOT / clean_font_name\n",
    "\n",
    "    ann_path  = out_dir / \"annotations.jsonl\"\n",
    "    if ann_path.exists():\n",
    "        print(f\"â© Skipping {clean_font_name} (Already done)\", flush=True)\n",
    "        return\n",
    "\n",
    "    cmap = best_cmap(font_path)\n",
    "    if not cmap:\n",
    "        print(f\"âš ï¸ Bad font: {clean_font_name}\", flush=True)\n",
    "        return\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    miss_path = out_dir / \"missing_glyphs.jsonl\"\n",
    "    saved, skipped = 0, 0\n",
    "\n",
    "    with ann_path.open(\"w\", encoding=\"utf-8\") as ann_f, miss_path.open(\"w\", encoding=\"utf-8\") as miss_f:\n",
    "        for idx, text in enumerate(text_list):\n",
    "            rid = f\"{idx+1:05d}\"\n",
    "\n",
    "            miss = missing_chars(cmap, text)\n",
    "            if miss:\n",
    "                miss_f.write(json.dumps({\"id\": rid, \"font\": str(font_path), \"missing_chars\": miss}, ensure_ascii=False) + \"\\n\")\n",
    "                if SKIP_MISSING_GLYPHS:\n",
    "                    skipped += 1\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                # ë Œë”ë§ í˜¸ì¶œ (ìƒ‰ìƒ ì •ë³´ë„ ë°˜í™˜ë°›ìŒ)\n",
    "                img, processed_lines, used_color = render_back_label_color(text, font_path)\n",
    "\n",
    "                final_img, scale, (ox, oy) = fit_into_square(img, IMAGE_HEIGHT)\n",
    "\n",
    "                filename = f\"{clean_font_name}_back_{rid}.png\"\n",
    "                final_img.save(out_dir / filename, \"PNG\")\n",
    "\n",
    "                meta = {\n",
    "                    \"id\": rid,\n",
    "                    \"file_name\": filename,\n",
    "                    \"image_path\": f\"{clean_font_name}/{filename}\",\n",
    "                    \"font_name\": clean_font_name,\n",
    "                    \"type\": \"back_label\",\n",
    "                    \"original_text\": text,\n",
    "                    \"processed_lines\": processed_lines,\n",
    "                    \"text_color_rgb\": used_color, # ì‚¬ìš©ëœ ìƒ‰ìƒ ì •ë³´ ì €ì¥\n",
    "                    \"fit_scale\": float(scale),\n",
    "                    \"paste_offset\": [ox, oy]\n",
    "                }\n",
    "                ann_f.write(json.dumps(meta, ensure_ascii=False) + \"\\n\")\n",
    "                saved += 1\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    print(f\"[{clean_font_name}] Saved: {saved}, Skipped: {skipped}\", flush=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ê²½ë¡œ ìƒì„±\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # í°íŠ¸ ì°¾ê¸°\n",
    "    ttf_paths = sorted([p for p in FONTS_DIR.rglob(\"*.ttf\") if p.is_file()])\n",
    "\n",
    "    print(f\"Data Records: {len(back_label_texts)}\")\n",
    "    print(f\"Fonts Found: {len(ttf_paths)}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"ğŸ¨ [Diverse Color Mode] Generating Back Labels with Random Colors...\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    for i, font_path in enumerate(ttf_paths):\n",
    "        print(f\"ğŸ‘‰ [{i+1}/{len(ttf_paths)}] {font_path.name} ... \", end=\"\", flush=True)\n",
    "        try:\n",
    "            process_single_font_color(font_path, back_label_texts)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nğŸ›‘ Stopped by user.\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Error: {e}\", flush=True)\n",
    "\n",
    "    print(\"\\nâœ… All Done.\")"
   ],
   "id": "76efc022a58fa8c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 records.\n",
      "Data Records: 200\n",
      "Fonts Found: 150\n",
      "--------------------------------------------------\n",
      "ğŸ¨ [Diverse Color Mode] Generating Back Labels with Random Colors...\n",
      "--------------------------------------------------\n",
      "ğŸ‘‰ [1/150] AritaBuriKR-Medium.ttf ... [AritaBuriKRMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [2/150] AstaSans-Regular.ttf ... [AstaSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [3/150] Binggrae.ttf ... [Binggrae] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [4/150] BinggraeII.ttf ... [BinggraeII] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [5/150] BinggraeMelona.ttf ... [BinggraeMelona] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [6/150] BinggraeSamanco.ttf ... [BinggraeSamanco] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [7/150] BinggraeTaom.ttf ... [BinggraeTaom] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [8/150] BMHANNA_11yrs_ttf.ttf ... [BMHANNA11yrsttf] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [9/150] BookkGothic_Light.ttf ... [BookkGothicLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [10/150] BookkMyungjo_Light.ttf ... [BookkMyungjoLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [11/150] Cafe24Simplehae-v2.0.ttf ... [Cafe24Simplehaev20] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [12/150] Cafe24SsurroundAir-v1.1.ttf ... [Cafe24SsurroundAirv11] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [13/150] Cafe24Syongsyong-v2.0.ttf ... [Cafe24Syongsyongv20] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [14/150] ChosunGs.TTF ... [ChosunGs] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [15/150] ChosunGu.TTF ... [ChosunGu] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [16/150] ChosunKg.TTF ... [ChosunKg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [17/150] ChosunKm.TTF ... [ChosunKm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [18/150] ChosunNm.ttf ... [ChosunNm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [19/150] ChosunSg.TTF ... [ChosunSg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [20/150] ChosunSm.TTF ... [ChosunSm] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [21/150] D2Coding-Ver1.3.2-20180524.ttf ... [D2CodingVer13220180524] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [22/150] Dongle-Light.ttf ... [DongleLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [23/150] EliceDigitalBaeum_Regular.ttf ... [EliceDigitalBaeumRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [24/150] EliceDigitalCodingverH_Bold.ttf ... [EliceDigitalCodingverHBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [25/150] EliceDXNeolli-Medium.ttf ... [EliceDXNeolliMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [26/150] esamanru Medium.ttf ... [esamanruMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [27/150] Eulyoo1945-Regular.ttf ... [Eulyoo1945Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [28/150] Freesentation-4Regular.ttf ... [Freesentation4Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [29/150] FreesentationVF.ttf ... [FreesentationVF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [30/150] GapyeongHanseokbongR.ttf ... [GapyeongHanseokbongR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [31/150] GmarketSansTTFMedium.ttf ... [GmarketSansTTFMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [32/150] goorm-sans-regular.ttf ... [goormsansregular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [33/150] goorm_Sans_Code_400.ttf ... [goormSansCode400] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [34/150] GowunDodum-Regular.ttf ... [GowunDodumRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [35/150] Gumi Dotum.ttf ... [GumiDotum] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [36/150] Hahmlet-Black.ttf ... [HahmletBlack] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [37/150] Hahmlet-Thin.ttf ... [HahmletThin] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [38/150] Hakgyoansim Allimjang TTF R.ttf ... [HakgyoansimAllimjangTTFR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [39/150] Hakgyoansim Badasseugi TTF L.ttf ... [HakgyoansimBadasseugiTTFL] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [40/150] Hakgyoansim Geurimilgi TTF R.ttf ... [HakgyoansimGeurimilgiTTFR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [41/150] Hakgyoansim Nadeuri TTF B.ttf ... [HakgyoansimNadeuriTTFB] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [42/150] Hakgyoansim_BoardmarkerR.ttf ... [HakgyoansimBoardmarkerR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [43/150] Hakgyoansim_JayusiganR.ttf ... [HakgyoansimJayusiganR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [44/150] Hakgyoansim_OcarinaR.ttf ... [HakgyoansimOcarinaR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [45/150] Hakgyoansim_SangjangR.ttf ... [HakgyoansimSangjangR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [46/150] Hakgyoansim_SiganpyoR.ttf ... [HakgyoansimSiganpyoR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [47/150] HakgyoansimBareonbatangR.ttf ... [HakgyoansimBareonbatangR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [48/150] HakgyoansimBareondotumR.ttf ... [HakgyoansimBareondotumR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [49/150] HakgyoansimSantteutdotumM.ttf ... [HakgyoansimSantteutdotumM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [50/150] HakgyoansimTtwimteulR.ttf ... [HakgyoansimTtwimteulR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [51/150] HakgyoansimUndongjangL.ttf ... [HakgyoansimUndongjangL] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [52/150] HancomSans-SemiBold_0.ttf ... [HancomSansSemiBold0] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [53/150] HSJandari-Regular.ttf ... [HSJandariRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [54/150] HSê²¨ìš¸ëˆˆê½ƒì²´.ttf ... [HSê²¨ìš¸ëˆˆê½ƒì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [55/150] Interop-Regular.ttf ... [InteropRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [56/150] JejuGothic.ttf ... [JejuGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [57/150] JejuHallasan.ttf ... [JejuHallasan] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [58/150] JejuMyeongjo.ttf ... [JejuMyeongjo] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [59/150] KakaoBigSans-Regular.ttf ... [KakaoBigSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [60/150] KakaoSmallSans-Regular.ttf ... [KakaoSmallSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [61/150] KBO Dia Gothic_medium.ttf ... [KBODiaGothicmedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [62/150] KCCChassam.ttf ... [KCCChassam] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [63/150] KCCImkwontaek.ttf ... [KCCImkwontaek] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [64/150] KCCì€ì˜ì²´.ttf ... [KCCì€ì˜ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [65/150] KimjungchulGothic-Regular.ttf ... [KimjungchulGothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [66/150] KimjungchulMyungjo-Regular.ttf ... [KimjungchulMyungjoRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [67/150] KimjungchulScript-Bold.ttf ... [KimjungchulScriptBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [68/150] KOHINanum_Light.ttf ... [KOHINanumLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [69/150] KoPubWorld Batang Medium.ttf ... [KoPubWorldBatangMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [70/150] KoPubWorld Dotum Medium.ttf ... [KoPubWorldDotumMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [71/150] KOTRA_GOTHIC.ttf ... [KOTRAGOTHIC] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [72/150] KOTRA_SONGEULSSI.ttf ... [KOTRASONGEULSSI] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [73/150] KyoboHandwriting2024psw.ttf ... [KyoboHandwriting2024psw] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [74/150] LINESeedKR-Rg.ttf ... [LINESeedKRRg] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [75/150] MapoHongdaeFreedom.ttf ... [MapoHongdaeFreedom] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [76/150] MBC 1961êµ´ë¦¼ M.ttf ... [MBC1961êµ´ë¦¼M] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [77/150] MinSans-Light.ttf ... [MinSansLight] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [78/150] MinSans-Regular.ttf ... [MinSansRegular] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [79/150] MinSansVF.ttf ... [MinSansVF] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [80/150] MiraeroNormal.ttf ... [MiraeroNormal] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [81/150] Moneygraphy-Rounded.ttf ... [MoneygraphyRounded] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [82/150] Mungyeong-Gamhong-Apple.ttf ... [MungyeongGamhongApple] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [83/150] NanumBarunGothic-YetHangul.ttf ... [NanumBarunGothicYetHangul] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [84/150] NanumBarunGothic.ttf ... [NanumBarunGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [85/150] NanumBarunpenR.ttf ... [NanumBarunpenR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [86/150] NanumGothic.ttf ... [NanumGothic] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [87/150] NanumHumanRegular.ttf ... [NanumHumanRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [88/150] NanumMyeongjo-YetHangul.ttf ... [NanumMyeongjoYetHangul] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [89/150] NanumMyeongjo.ttf ... [NanumMyeongjo] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [90/150] NanumSquareR.ttf ... [NanumSquareR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [91/150] netmarbleM.ttf ... [netmarbleM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [92/150] NEXON Kart Gothic Kor Medium.ttf ... [NEXONKartGothicKorMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [93/150] NEXONLv1GothicRegular.ttf ... [NEXONLv1GothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [94/150] NotoSansKR-Regular.ttf ... [NotoSansKRRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [95/150] NotoSerifKR-Regular.ttf ... [NotoSerifKRRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [96/150] ONE Mobile Regular.ttf ... [ONEMobileRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [97/150] Paperlogy-4Regular.ttf ... [Paperlogy4Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [98/150] PyeojinGothic-Light.ttf ... [PyeojinGothicLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [99/150] PyeojinGothic-Regular.ttf ... [PyeojinGothicRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [100/150] PyeongChang-Regular.ttf ... [PyeongChangRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [101/150] RiaSans-Regular.ttf ... [RiaSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [102/150] SB ì–´ê·¸ë¡œ M.ttf ... [SBì–´ê·¸ë¡œM] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [103/150] SejongGeulggot.ttf ... [SejongGeulggot] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [104/150] SeoulAlrimTTF-Medium.ttf ... [SeoulAlrimTTFMedium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [105/150] SeoulNamsanB.ttf ... [SeoulNamsanB] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [106/150] Spoqa Han Sans Regular.ttf ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103736 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SpoqaHanSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [107/150] SpoqaHanSansNeo-Regular.ttf ... [SpoqaHanSansNeoRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [108/150] STUNNING.ttf ... [STUNNING] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [109/150] SUIT-Variable.ttf ... [SUITVariable] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [110/150] The Jamsil 3 Regular.ttf ... [TheJamsil3Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [111/150] THEFACESHOP+INKLIPQUID(ìœˆë„ìš°ìš©).ttf ... [THEFACESHOPINKLIPQUIDìœˆë„ìš°ìš©] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [112/150] Tlabì‹ ì˜ë³µì²´.ttf ... [Tlabì‹ ì˜ë³µì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [113/150] UhBee Se_hyun.ttf ... [UhBeeSehyun] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [114/150] WantedSans-Regular.ttf ... [WantedSansRegular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [115/150] WantedSansVariable.ttf ... [WantedSansVariable] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [116/150] YES24GothicR.ttf ... [YES24GothicR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [117/150] YES24MyoungjoR.ttf ... [YES24MyoungjoR] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [118/150] YoonChildfundkoreaMinGuk.ttf ... [YoonChildfundkoreaMinGuk] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [119/150] ê°•ì›êµìœ¡ëª¨ë‘ Light.ttf ... [ê°•ì›êµìœ¡ëª¨ë‘Light] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [120/150] ê°•ì›êµìœ¡ìƒˆìŒ.ttf ... [ê°•ì›êµìœ¡ìƒˆìŒ] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [121/150] ê°•ì›êµìœ¡í˜„ì˜¥ìƒ˜.ttf ... [ê°•ì›êµìœ¡í˜„ì˜¥ìƒ˜] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [122/150] ê²½ê¸°ì²œë…„ë°”íƒ•_Regular.ttf ... [ê²½ê¸°ì²œë…„ë°”íƒ•Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [123/150] ê²½ê¸°ì²œë…„ì œëª©V_Bold.ttf ... [ê²½ê¸°ì²œë…„ì œëª©VBold] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [124/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ê³°ì‹ ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ê³°ì‹ ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [125/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ë§›ìˆëŠ”ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ë§›ìˆëŠ”ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [126/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ìƒí•´ì°¬ë¯¸ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ìƒí•´ì°¬ë¯¸ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [127/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì„±ì‹¤ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì„±ì‹¤ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [128/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì†Œë°©ê´€ì˜ ê¸°ë„.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì†Œë°©ê´€ì˜ê¸°ë„] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [129/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì•„ì¸ë§˜ ì†ê¸€ì”¨.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì•„ì¸ë§˜ì†ê¸€ì”¨] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [130/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì—„ë§ˆì‚¬ë‘.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì—„ë§ˆì‚¬ë‘] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [131/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ˆìœ ë¯¼ê²½ì²´.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ˆìœë¯¼ê²½ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [132/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ë¯¸ìˆëŠ” í•œê¸€.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ë¯¸ìˆëŠ”í•œê¸€] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [133/150] ë‚˜ëˆ”ì†ê¸€ì”¨ ì² í•„ê¸€ì”¨.ttf ... [ë‚˜ëˆ”ì†ê¸€ì”¨ì² í•„ê¸€ì”¨] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [134/150] ëŒ€êµ¬ë¶ì„±ë¡œ Light.ttf ... [ëŒ€êµ¬ë¶ì„±ë¡œLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [135/150] ë•…ìŠ¤ë¶€ëŒ€ì°Œê°œ Light.ttf ... [ë•…ìŠ¤ë¶€ëŒ€ì°Œê°œLight] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [136/150] ì‚¼ìœ¡ëŒ€ì²´ Regular.ttf ... [ì‚¼ìœ¡ëŒ€ì²´Regular] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [137/150] ì„œìš¸í•œê°• ì¥ì²´B.ttf ... [ì„œìš¸í•œê°•ì¥ì²´B] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [138/150] ì„œìš¸í•œê°• ì¥ì²´M.ttf ... [ì„œìš¸í•œê°•ì¥ì²´M] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [139/150] ì˜¨ê¸€ì ê³µë¶€ì˜í•˜ìë‚˜.ttf ... [ì˜¨ê¸€ìê³µë¶€ì˜í•˜ìë‚˜] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [140/150] ì˜¨ê¸€ì ê¹€ì½©í•´.ttf ... [ì˜¨ê¸€ìê¹€ì½©í•´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [141/150] ì˜¨ê¸€ì ë°”ë‹·ë°”ëŒ.ttf ... [ì˜¨ê¸€ìë°”ë‹·ë°”ëŒ] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [142/150] ì˜¨ê¸€ì ìœ„ì”¨ë¦¬ìŠ¤íŠ¸.ttf ... [ì˜¨ê¸€ììœ„ì”¨ë¦¬ìŠ¤íŠ¸] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [143/150] ì˜¨ê¸€ì ì½˜ì½˜ì²´.ttf ... [ì˜¨ê¸€ìì½˜ì½˜ì²´] Saved: 0, Skipped: 200\n",
      "ğŸ‘‰ [144/150] ìœ ì•¤í”¼í”Œ ê³ ë”• KS.ttf ... [ìœ ì•¤í”¼í”Œê³ ë”•KS] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [145/150] ìœ ì•¤í”¼í”Œ ê³ ë”• UNI.ttf ... [ìœ ì•¤í”¼í”Œê³ ë”•UNI] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [146/150] ì´ì„œìœ¤ì²´.ttf ... [ì´ì„œìœ¤ì²´] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [147/150] ì •ì„ ë™ê°•ì²´(Regular)TTF.ttf ... [ì •ì„ ë™ê°•ì²´RegularTTF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [148/150] ì •ì„ ì•„ë¦¬ë‘ë¿Œë¦¬ì²´TTF.ttf ... [ì •ì„ ì•„ë¦¬ë‘ë¿Œë¦¬ì²´TTF] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [149/150] ì¤‘ë‚˜ì¢‹ì²´ Medium.ttf ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12292 extra bytes in post.stringData array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì¤‘ë‚˜ì¢‹ì²´Medium] Saved: 200, Skipped: 0\n",
      "ğŸ‘‰ [150/150] í´ë¦½ì•„íŠ¸ì½”ë¦¬ì•„_Regular.ttf ... [í´ë¦½ì•„íŠ¸ì½”ë¦¬ì•„Regular] Saved: 200, Skipped: 0\n",
      "\n",
      "âœ… All Done.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# âŒ Skipped í°íŠ¸ ëª©ë¡ (ì´ 24ê°œ)\n",
    "#\n",
    "# 1. ë‚˜ëˆ”ì†ê¸€ì”¨ ì‹œë¦¬ì¦ˆ (8ê°œ) ì†ê¸€ì”¨ í°íŠ¸ê°€ ëŒ€ê±° ìŠ¤í‚µë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "#\n",
    "#     [124] ë‚˜ëˆ”ì†ê¸€ì”¨ ê³°ì‹ ì²´.ttf\n",
    "#\n",
    "#     [125] ë‚˜ëˆ”ì†ê¸€ì”¨ ë§›ìˆëŠ”ì²´.ttf\n",
    "#\n",
    "#     [126] ë‚˜ëˆ”ì†ê¸€ì”¨ ìƒí•´ì°¬ë¯¸ì²´.ttf\n",
    "#\n",
    "#     [127] ë‚˜ëˆ”ì†ê¸€ì”¨ ì„±ì‹¤ì²´.ttf\n",
    "#\n",
    "#     [128] ë‚˜ëˆ”ì†ê¸€ì”¨ ì†Œë°©ê´€ì˜ ê¸°ë„.ttf\n",
    "#\n",
    "#     [129] ë‚˜ëˆ”ì†ê¸€ì”¨ ì•„ì¸ë§˜ ì†ê¸€ì”¨.ttf\n",
    "#\n",
    "#     [130] ë‚˜ëˆ”ì†ê¸€ì”¨ ì—„ë§ˆì‚¬ë‘.ttf\n",
    "#\n",
    "#     [131] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ˆìœ ë¯¼ê²½ì²´.ttf\n",
    "#\n",
    "#     [132] ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ë¯¸ìˆëŠ” í•œê¸€.ttf\n",
    "#\n",
    "#     [133] ë‚˜ëˆ”ì†ê¸€ì”¨ ì² í•„ê¸€ì”¨.ttf\n",
    "#\n",
    "# 2. ì˜¨ê¸€ì ì‹œë¦¬ì¦ˆ (5ê°œ) ë§ˆì°¬ê°€ì§€ë¡œ ì†ê¸€ì”¨ ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤.\n",
    "#\n",
    "#     [139] ì˜¨ê¸€ì ê³µë¶€ì˜í•˜ìë‚˜.ttf\n",
    "#\n",
    "#     [140] ì˜¨ê¸€ì ê¹€ì½©í•´.ttf\n",
    "#\n",
    "#     [141] ì˜¨ê¸€ì ë°”ë‹·ë°”ëŒ.ttf\n",
    "#\n",
    "#     [142] ì˜¨ê¸€ì ìœ„ì”¨ë¦¬ìŠ¤íŠ¸.ttf\n",
    "#\n",
    "#     [143] ì˜¨ê¸€ì ì½˜ì½˜ì²´.ttf\n",
    "#\n",
    "# 3. MinSans ì‹œë¦¬ì¦ˆ (3ê°œ)\n",
    "#\n",
    "#     [77] MinSans-Light.ttf\n",
    "#\n",
    "#     [78] MinSans-Regular.ttf\n",
    "#\n",
    "#     [79] MinSansVF.ttf (ê°€ë³€ í°íŠ¸)\n",
    "#\n",
    "# 4. Cafe24 ì‹œë¦¬ì¦ˆ (2ê°œ)\n",
    "#\n",
    "#     [11] Cafe24Simplehae-v2.0.ttf\n",
    "#\n",
    "#     [12] Cafe24SsurroundAir-v1.1.ttf\n",
    "#\n",
    "# 5. Hahmlet (í•¨ë ›) ì‹œë¦¬ì¦ˆ (2ê°œ)\n",
    "#\n",
    "#     [36] Hahmlet-Black.ttf\n",
    "#\n",
    "#     [37] Hahmlet-Thin.ttf\n",
    "#\n",
    "# 6. ê¸°íƒ€ (4ê°œ)\n",
    "#\n",
    "#     [75] MapoHongdaeFreedom.ttf (ë§ˆí¬í™ëŒ€í”„ë¦¬ë¤)\n",
    "#\n",
    "#     [113] UhBee Se_hyun.ttf (ì–´ë¹„ ì„¸í˜„ - ì†ê¸€ì”¨)"
   ],
   "id": "3d0a72145815a22b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 24ê°œ í°íŠ¸ (íŠ¹íˆ ì†ê¸€ì”¨ ê´€ë ¨ í°íŠ¸ê°€ ë’·ë©´ ë°ì´í„°ì…‹ ìƒì„±ì— ì‹¤íŒ¨)\n",
    "## >> 126ê°œë¡œ ì§„í–‰"
   ],
   "id": "d96846120992105a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T14:10:59.516902200Z",
     "start_time": "2025-12-20T14:10:59.357402500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# âœ… 1. ì„¤ì • ë° ê²½ë¡œ\n",
    "# =========================\n",
    "DATASET_ROOT = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\")\n",
    "FAILED_DATASET_ROOT = Path(r\"C:\\Users\\nam\\Desktop\\_Failed_\")\n",
    "TARGET_SUBFOLDERS = [\"back_bw\", \"back_color_aug\", \"front_bw\", \"front_color_aug\"]\n",
    "\n",
    "# ğŸ“ ë¡œê·¸ì—ì„œ ì¶”ì¶œí•œ ì‹¤íŒ¨ í°íŠ¸ ëª©ë¡ (24ê°œ)\n",
    "FAILED_FONT_FILENAMES = [\n",
    "    # 1. ë‚˜ëˆ”ì†ê¸€ì”¨\n",
    "    \"ë‚˜ëˆ”ì†ê¸€ì”¨ ê³°ì‹ ì²´.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ë§›ìˆëŠ”ì²´.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ìƒí•´ì°¬ë¯¸ì²´.ttf\",\n",
    "    \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì„±ì‹¤ì²´.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì†Œë°©ê´€ì˜ ê¸°ë„.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì•„ì¸ë§˜ ì†ê¸€ì”¨.ttf\",\n",
    "    \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì—„ë§ˆì‚¬ë‘.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ˆìœ ë¯¼ê²½ì²´.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ë¯¸ìˆëŠ” í•œê¸€.ttf\",\n",
    "    \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì² í•„ê¸€ì”¨.ttf\",\n",
    "    # 2. ì˜¨ê¸€ì\n",
    "    \"ì˜¨ê¸€ì ê³µë¶€ì˜í•˜ìë‚˜.ttf\", \"ì˜¨ê¸€ì ê¹€ì½©í•´.ttf\", \"ì˜¨ê¸€ì ë°”ë‹·ë°”ëŒ.ttf\",\n",
    "    \"ì˜¨ê¸€ì ìœ„ì”¨ë¦¬ìŠ¤íŠ¸.ttf\", \"ì˜¨ê¸€ì ì½˜ì½˜ì²´.ttf\",\n",
    "    # 3. MinSans\n",
    "    \"MinSans-Light.ttf\", \"MinSans-Regular.ttf\", \"MinSansVF.ttf\",\n",
    "    # 4. Cafe24\n",
    "    \"Cafe24Simplehae-v2.0.ttf\", \"Cafe24SsurroundAir-v1.1.ttf\",\n",
    "    # 5. Hahmlet\n",
    "    \"Hahmlet-Black.ttf\", \"Hahmlet-Thin.ttf\",\n",
    "    # 6. ê¸°íƒ€\n",
    "    \"MapoHongdaeFreedom.ttf\", \"UhBee Se_hyun.ttf\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "# =========================\n",
    "def get_clean_folder_name(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    íŒŒì¼ëª…(í™•ì¥ì ì œì™¸)ì—ì„œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ì—¬ í´ë”ëª…ìœ¼ë¡œ ë³€í™˜\n",
    "    ì˜ˆ: \"Cafe24Simplehae-v2.0.ttf\" -> \"Cafe24Simplehaev20\"\n",
    "    \"\"\"\n",
    "    stem = Path(filename).stem\n",
    "    return re.sub(r\"[^a-zA-Z0-9ê°€-í£]\", \"\", stem)\n",
    "\n",
    "# =========================\n",
    "# 3. ë©”ì¸ ì‹¤í–‰\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"ğŸ“‹ Processing list of {len(FAILED_FONT_FILENAMES)} failed fonts...\")\n",
    "    print(f\"ğŸ“‚ Source: {DATASET_ROOT}\")\n",
    "    print(f\"ğŸ“‚ Target: {FAILED_DATASET_ROOT}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    moved_count = 0\n",
    "\n",
    "    for font_file in FAILED_FONT_FILENAMES:\n",
    "        # íŒŒì¼ëª… -> í´ë”ëª… ë³€í™˜\n",
    "        folder_name = get_clean_folder_name(font_file)\n",
    "\n",
    "        # 4ê°œì˜ í•˜ìœ„ í´ë”(back_bw ë“±) í™•ì¸\n",
    "        for sub in TARGET_SUBFOLDERS:\n",
    "            src_path = DATASET_ROOT / sub / folder_name\n",
    "            dest_path = FAILED_DATASET_ROOT / sub / folder_name\n",
    "\n",
    "            # ì›ë³¸ ë°ì´í„°ì…‹ì— í•´ë‹¹ í´ë”ê°€ ì¡´ì¬í•˜ë©´ ì´ë™\n",
    "            if src_path.exists() and src_path.is_dir():\n",
    "                try:\n",
    "                    # ëª©ì ì§€ ê²½ë¡œ ìƒì„±\n",
    "                    dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                    if dest_path.exists():\n",
    "                        print(f\"âš ï¸ [Skip] Already exists: {sub}/{folder_name}\")\n",
    "                        # ë®ì–´ì“°ë ¤ë©´: shutil.rmtree(dest_path) í›„ ì´ë™\n",
    "                    else:\n",
    "                        shutil.move(str(src_path), str(dest_path))\n",
    "                        print(f\"moved ğŸ“¦: {sub}/{folder_name}\")\n",
    "                        moved_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Error moving {sub}/{folder_name}: {e}\")\n",
    "            else:\n",
    "                # í´ë”ê°€ ì—†ìœ¼ë©´ ì´ë¯¸ ì´ë™í–ˆê±°ë‚˜ ìƒì„±ì´ ì•ˆ ëœ ê²ƒì„\n",
    "                pass\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"ğŸ‰ Done. Moved {moved_count} folders based on the log list.\")"
   ],
   "id": "b3f02a12edf8c52c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Processing list of 24 failed fonts...\n",
      "ğŸ“‚ Source: C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\n",
      "ğŸ“‚ Target: C:\\Users\\nam\\Desktop\\_Failed_\n",
      "------------------------------------------------------------\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ê³°ì‹ ì²´\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ê³°ì‹ ì²´\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ê³°ì‹ ì²´\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ê³°ì‹ ì²´\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ë§›ìˆëŠ”ì²´\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ë§›ìˆëŠ”ì²´\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ë§›ìˆëŠ”ì²´\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ë§›ìˆëŠ”ì²´\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ìƒí•´ì°¬ë¯¸ì²´\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ìƒí•´ì°¬ë¯¸ì²´\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ìƒí•´ì°¬ë¯¸ì²´\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ìƒí•´ì°¬ë¯¸ì²´\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì„±ì‹¤ì²´\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì„±ì‹¤ì²´\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì„±ì‹¤ì²´\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì„±ì‹¤ì²´\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì†Œë°©ê´€ì˜ê¸°ë„\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì†Œë°©ê´€ì˜ê¸°ë„\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì†Œë°©ê´€ì˜ê¸°ë„\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì†Œë°©ê´€ì˜ê¸°ë„\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì•„ì¸ë§˜ì†ê¸€ì”¨\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì•„ì¸ë§˜ì†ê¸€ì”¨\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì•„ì¸ë§˜ì†ê¸€ì”¨\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì•„ì¸ë§˜ì†ê¸€ì”¨\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì—„ë§ˆì‚¬ë‘\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì—„ë§ˆì‚¬ë‘\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì—„ë§ˆì‚¬ë‘\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì—„ë§ˆì‚¬ë‘\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ˆìœë¯¼ê²½ì²´\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ˆìœë¯¼ê²½ì²´\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ˆìœë¯¼ê²½ì²´\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ˆìœë¯¼ê²½ì²´\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ë¯¸ìˆëŠ”í•œê¸€\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ë¯¸ìˆëŠ”í•œê¸€\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ë¯¸ìˆëŠ”í•œê¸€\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì˜ë¯¸ìˆëŠ”í•œê¸€\n",
      "moved ğŸ“¦: back_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì² í•„ê¸€ì”¨\n",
      "moved ğŸ“¦: back_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì² í•„ê¸€ì”¨\n",
      "moved ğŸ“¦: front_bw/ë‚˜ëˆ”ì†ê¸€ì”¨ì² í•„ê¸€ì”¨\n",
      "moved ğŸ“¦: front_color_aug/ë‚˜ëˆ”ì†ê¸€ì”¨ì² í•„ê¸€ì”¨\n",
      "moved ğŸ“¦: back_bw/ì˜¨ê¸€ìê³µë¶€ì˜í•˜ìë‚˜\n",
      "moved ğŸ“¦: back_color_aug/ì˜¨ê¸€ìê³µë¶€ì˜í•˜ìë‚˜\n",
      "moved ğŸ“¦: front_bw/ì˜¨ê¸€ìê³µë¶€ì˜í•˜ìë‚˜\n",
      "moved ğŸ“¦: front_color_aug/ì˜¨ê¸€ìê³µë¶€ì˜í•˜ìë‚˜\n",
      "moved ğŸ“¦: back_bw/ì˜¨ê¸€ìê¹€ì½©í•´\n",
      "moved ğŸ“¦: back_color_aug/ì˜¨ê¸€ìê¹€ì½©í•´\n",
      "moved ğŸ“¦: front_bw/ì˜¨ê¸€ìê¹€ì½©í•´\n",
      "moved ğŸ“¦: front_color_aug/ì˜¨ê¸€ìê¹€ì½©í•´\n",
      "moved ğŸ“¦: back_bw/ì˜¨ê¸€ìë°”ë‹·ë°”ëŒ\n",
      "moved ğŸ“¦: back_color_aug/ì˜¨ê¸€ìë°”ë‹·ë°”ëŒ\n",
      "moved ğŸ“¦: front_bw/ì˜¨ê¸€ìë°”ë‹·ë°”ëŒ\n",
      "moved ğŸ“¦: front_color_aug/ì˜¨ê¸€ìë°”ë‹·ë°”ëŒ\n",
      "moved ğŸ“¦: back_bw/ì˜¨ê¸€ììœ„ì”¨ë¦¬ìŠ¤íŠ¸\n",
      "moved ğŸ“¦: back_color_aug/ì˜¨ê¸€ììœ„ì”¨ë¦¬ìŠ¤íŠ¸\n",
      "moved ğŸ“¦: front_bw/ì˜¨ê¸€ììœ„ì”¨ë¦¬ìŠ¤íŠ¸\n",
      "moved ğŸ“¦: front_color_aug/ì˜¨ê¸€ììœ„ì”¨ë¦¬ìŠ¤íŠ¸\n",
      "moved ğŸ“¦: back_bw/ì˜¨ê¸€ìì½˜ì½˜ì²´\n",
      "moved ğŸ“¦: back_color_aug/ì˜¨ê¸€ìì½˜ì½˜ì²´\n",
      "moved ğŸ“¦: front_bw/ì˜¨ê¸€ìì½˜ì½˜ì²´\n",
      "moved ğŸ“¦: front_color_aug/ì˜¨ê¸€ìì½˜ì½˜ì²´\n",
      "moved ğŸ“¦: back_bw/MinSansLight\n",
      "moved ğŸ“¦: back_color_aug/MinSansLight\n",
      "moved ğŸ“¦: front_bw/MinSansLight\n",
      "moved ğŸ“¦: front_color_aug/MinSansLight\n",
      "moved ğŸ“¦: back_bw/MinSansRegular\n",
      "moved ğŸ“¦: back_color_aug/MinSansRegular\n",
      "moved ğŸ“¦: front_bw/MinSansRegular\n",
      "moved ğŸ“¦: front_color_aug/MinSansRegular\n",
      "moved ğŸ“¦: back_bw/MinSansVF\n",
      "moved ğŸ“¦: back_color_aug/MinSansVF\n",
      "moved ğŸ“¦: front_bw/MinSansVF\n",
      "moved ğŸ“¦: front_color_aug/MinSansVF\n",
      "moved ğŸ“¦: back_bw/Cafe24Simplehaev20\n",
      "moved ğŸ“¦: back_color_aug/Cafe24Simplehaev20\n",
      "moved ğŸ“¦: front_bw/Cafe24Simplehaev20\n",
      "moved ğŸ“¦: front_color_aug/Cafe24Simplehaev20\n",
      "moved ğŸ“¦: back_bw/Cafe24SsurroundAirv11\n",
      "moved ğŸ“¦: back_color_aug/Cafe24SsurroundAirv11\n",
      "moved ğŸ“¦: front_bw/Cafe24SsurroundAirv11\n",
      "moved ğŸ“¦: front_color_aug/Cafe24SsurroundAirv11\n",
      "moved ğŸ“¦: back_bw/HahmletBlack\n",
      "moved ğŸ“¦: back_color_aug/HahmletBlack\n",
      "moved ğŸ“¦: front_bw/HahmletBlack\n",
      "moved ğŸ“¦: front_color_aug/HahmletBlack\n",
      "moved ğŸ“¦: back_bw/HahmletThin\n",
      "moved ğŸ“¦: back_color_aug/HahmletThin\n",
      "moved ğŸ“¦: front_bw/HahmletThin\n",
      "moved ğŸ“¦: front_color_aug/HahmletThin\n",
      "moved ğŸ“¦: back_bw/MapoHongdaeFreedom\n",
      "moved ğŸ“¦: back_color_aug/MapoHongdaeFreedom\n",
      "moved ğŸ“¦: front_bw/MapoHongdaeFreedom\n",
      "moved ğŸ“¦: front_color_aug/MapoHongdaeFreedom\n",
      "moved ğŸ“¦: back_bw/UhBeeSehyun\n",
      "moved ğŸ“¦: back_color_aug/UhBeeSehyun\n",
      "moved ğŸ“¦: front_bw/UhBeeSehyun\n",
      "moved ğŸ“¦: front_color_aug/UhBeeSehyun\n",
      "------------------------------------------------------------\n",
      "ğŸ‰ Done. Moved 96 folders based on the log list.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T14:17:35.746252200Z",
     "start_time": "2025-12-20T14:17:35.662421800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# âœ… 1. ì„¤ì • ë° ê²½ë¡œ\n",
    "# =========================\n",
    "\n",
    "# (1) ë°ì´í„°ì…‹ ê²½ë¡œ\n",
    "DATASET_ROOT = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\")\n",
    "FAILED_DATASET_ROOT = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\_Failed_\")\n",
    "TARGET_SUBFOLDERS = [\"back_bw\", \"back_color_aug\", \"front_bw\", \"front_color_aug\"]\n",
    "\n",
    "# (2) í°íŠ¸ ì›ë³¸ ê²½ë¡œ (ì¶”ê°€ë¨)\n",
    "FONTS_DIR = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\ref_fonts_ttf\")\n",
    "FAILED_FONTS_DIR = Path(r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\_Failed_\\ref_fonts_ttf\")\n",
    "\n",
    "# ğŸ“ ë¡œê·¸ì—ì„œ ì¶”ì¶œí•œ ì‹¤íŒ¨ í°íŠ¸ ëª©ë¡ (24ê°œ)\n",
    "FAILED_FONT_FILENAMES = [\n",
    "    # 1. ë‚˜ëˆ”ì†ê¸€ì”¨\n",
    "    \"ë‚˜ëˆ”ì†ê¸€ì”¨ ê³°ì‹ ì²´.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ë§›ìˆëŠ”ì²´.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ìƒí•´ì°¬ë¯¸ì²´.ttf\",\n",
    "    \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì„±ì‹¤ì²´.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì†Œë°©ê´€ì˜ ê¸°ë„.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì•„ì¸ë§˜ ì†ê¸€ì”¨.ttf\",\n",
    "    \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì—„ë§ˆì‚¬ë‘.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ˆìœ ë¯¼ê²½ì²´.ttf\", \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ë¯¸ìˆëŠ” í•œê¸€.ttf\",\n",
    "    \"ë‚˜ëˆ”ì†ê¸€ì”¨ ì² í•„ê¸€ì”¨.ttf\",\n",
    "    # 2. ì˜¨ê¸€ì\n",
    "    \"ì˜¨ê¸€ì ê³µë¶€ì˜í•˜ìë‚˜.ttf\", \"ì˜¨ê¸€ì ê¹€ì½©í•´.ttf\", \"ì˜¨ê¸€ì ë°”ë‹·ë°”ëŒ.ttf\",\n",
    "    \"ì˜¨ê¸€ì ìœ„ì”¨ë¦¬ìŠ¤íŠ¸.ttf\", \"ì˜¨ê¸€ì ì½˜ì½˜ì²´.ttf\",\n",
    "    # 3. MinSans\n",
    "    \"MinSans-Light.ttf\", \"MinSans-Regular.ttf\", \"MinSansVF.ttf\",\n",
    "    # 4. Cafe24\n",
    "    \"Cafe24Simplehae-v2.0.ttf\", \"Cafe24SsurroundAir-v1.1.ttf\",\n",
    "    # 5. Hahmlet\n",
    "    \"Hahmlet-Black.ttf\", \"Hahmlet-Thin.ttf\",\n",
    "    # 6. ê¸°íƒ€\n",
    "    \"MapoHongdaeFreedom.ttf\", \"UhBee Se_hyun.ttf\"\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "# =========================\n",
    "def get_clean_folder_name(filename: str) -> str:\n",
    "    \"\"\"íŒŒì¼ëª…ì—ì„œ í™•ì¥ìë¥¼ ë–¼ê³  íŠ¹ìˆ˜ë¬¸ìë¥¼ ì œê±°í•˜ì—¬ í´ë”ëª…ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    stem = Path(filename).stem\n",
    "    return re.sub(r\"[^a-zA-Z0-9ê°€-í£]\", \"\", stem)\n",
    "\n",
    "# =========================\n",
    "# 3. ë©”ì¸ ì‹¤í–‰\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"ğŸ“‹ Processing list of {len(FAILED_FONT_FILENAMES)} failed fonts...\")\n",
    "\n",
    "    # í´ë” ìƒì„±\n",
    "    FAILED_DATASET_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "    FAILED_FONTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    moved_font_count = 0\n",
    "    moved_folder_count = 0\n",
    "\n",
    "    for font_filename in FAILED_FONT_FILENAMES:\n",
    "        print(f\"\\nğŸ” Checking: {font_filename}\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # [Step 1] ì›ë³¸ .ttf íŒŒì¼ ì´ë™\n",
    "        # ---------------------------------------------------------\n",
    "        src_font_path = FONTS_DIR / font_filename\n",
    "        dest_font_path = FAILED_FONTS_DIR / font_filename\n",
    "\n",
    "        if src_font_path.exists():\n",
    "            try:\n",
    "                # ì¤‘ë³µ ì²´í¬\n",
    "                if dest_font_path.exists():\n",
    "                    print(f\"   âš ï¸  [Font] Already exists in failed folder: {font_filename}\")\n",
    "                else:\n",
    "                    shutil.move(str(src_font_path), str(dest_font_path))\n",
    "                    print(f\"   âœ… [Font] Moved to failed folder.\")\n",
    "                    moved_font_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"   âŒ [Font] Error moving file: {e}\")\n",
    "        else:\n",
    "            print(f\"   â„¹ï¸  [Font] File not found in source (already moved?): {font_filename}\")\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # [Step 2] ë°ì´í„°ì…‹ í´ë” ì´ë™ (ê¸°ì¡´ ë¡œì§)\n",
    "        # ---------------------------------------------------------\n",
    "        folder_name = get_clean_folder_name(font_filename)\n",
    "\n",
    "        for sub in TARGET_SUBFOLDERS:\n",
    "            src_dataset_path = DATASET_ROOT / sub / folder_name\n",
    "            dest_dataset_path = FAILED_DATASET_ROOT / sub / folder_name\n",
    "\n",
    "            if src_dataset_path.exists() and src_dataset_path.is_dir():\n",
    "                try:\n",
    "                    dest_dataset_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                    if dest_dataset_path.exists():\n",
    "                        print(f\"   âš ï¸  [Data] Folder already exists: {sub}/{folder_name}\")\n",
    "                    else:\n",
    "                        shutil.move(str(src_dataset_path), str(dest_dataset_path))\n",
    "                        print(f\"   ğŸ“¦ [Data] Moved folder: {sub}/{folder_name}\")\n",
    "                        moved_folder_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"   âŒ [Data] Error moving folder: {e}\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"ğŸ‰ Summary:\")\n",
    "    print(f\"   - Moved Font Files (.ttf): {moved_font_count}\")\n",
    "    print(f\"   - Moved Dataset Folders  : {moved_folder_count}\")\n",
    "    print(\"Done.\")"
   ],
   "id": "9e8f4487393910b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Processing list of 24 failed fonts...\n",
      "------------------------------------------------------------\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ê³°ì‹ ì²´.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ë§›ìˆëŠ”ì²´.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ìƒí•´ì°¬ë¯¸ì²´.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ì„±ì‹¤ì²´.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ì†Œë°©ê´€ì˜ ê¸°ë„.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ì•„ì¸ë§˜ ì†ê¸€ì”¨.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ì—„ë§ˆì‚¬ë‘.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ˆìœ ë¯¼ê²½ì²´.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ì˜ë¯¸ìˆëŠ” í•œê¸€.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ë‚˜ëˆ”ì†ê¸€ì”¨ ì² í•„ê¸€ì”¨.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ì˜¨ê¸€ì ê³µë¶€ì˜í•˜ìë‚˜.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ì˜¨ê¸€ì ê¹€ì½©í•´.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ì˜¨ê¸€ì ë°”ë‹·ë°”ëŒ.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ì˜¨ê¸€ì ìœ„ì”¨ë¦¬ìŠ¤íŠ¸.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: ì˜¨ê¸€ì ì½˜ì½˜ì²´.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: MinSans-Light.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: MinSans-Regular.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: MinSansVF.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: Cafe24Simplehae-v2.0.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: Cafe24SsurroundAir-v1.1.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: Hahmlet-Black.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: Hahmlet-Thin.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: MapoHongdaeFreedom.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "\n",
      "ğŸ” Checking: UhBee Se_hyun.ttf\n",
      "   âœ… [Font] Moved to failed folder.\n",
      "------------------------------------------------------------\n",
      "ğŸ‰ Summary:\n",
      "   - Moved Font Files (.ttf): 24\n",
      "   - Moved Dataset Folders  : 0\n",
      "Done.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T14:22:38.572123500Z",
     "start_time": "2025-12-20T14:22:38.519986300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "target_path = r\"C:\\Users\\nam\\Desktop\\ìµœì¢… í°íŠ¸ ë°ì´í„°ì…‹\\ref_fonts_ttf\"\n",
    "\n",
    "# 1. í•´ë‹¹ ê²½ë¡œì—ì„œ .ttf íŒŒì¼ë§Œ ê³¨ë¼ë‚´ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)\n",
    "ttf_files = [f for f in os.listdir(target_path)\n",
    "             if os.path.isfile(os.path.join(target_path, f)) and f.lower().endswith('.ttf')]\n",
    "\n",
    "# 2. ë°ì´í„°í”„ë ˆì„ ìƒì„± ë° csv ì €ì¥\n",
    "df = pd.DataFrame(ttf_files, columns=['Font Filename'])\n",
    "\n",
    "# ì €ì¥í•  íŒŒì¼ëª… ì„¤ì •\n",
    "output_csv = \"font_list.csv\"\n",
    "df.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"âœ… ì´ {len(ttf_files)}ê°œì˜ í°íŠ¸ íŒŒì¼ëª…ì„ '{output_csv}'ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\")"
   ],
   "id": "a05c8178a17dd59b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ 126ê°œì˜ í°íŠ¸ íŒŒì¼ëª…ì„ 'font_list.csv'ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
