import os
import csv
import json
import random
import traceback
import multiprocessing
import gc
import time
import numpy as np
import torch
import cv2
from PIL import Image, ImageOps, ImageFile
from torchvision.transforms import v2
import torchvision.transforms.v2.functional as F
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor, as_completed

# [ì•ˆì „ì¥ì¹˜] ì˜ë¦° ì´ë¯¸ì§€ ë¡œë“œ ë°©ì§€
ImageFile.LOAD_TRUNCATED_IMAGES = False

# =======================================================
# [1. ì„¤ì • ë° ìƒìˆ˜]
# =======================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

CONFIG = {
    "IS_TEST_MODE": False,
    "TEST_COUNT": 5,  # í…ŒìŠ¤íŠ¸ ì‹œ 5ì¥ë§Œ ìˆ˜í–‰
    "NUM_WORKERS": 30,  # CPU/RAM ì‚¬ì–‘ì— ë”°ë¼ ì¡°ì ˆ (ì•ˆì •ì„± ê¶Œì¥: 10~15)
    "MAX_RAM_CACHE": 30,

    "INPUT_ROOT": BASE_DIR,
    "OUTPUT_ROOT": os.path.join(BASE_DIR, "final_output"),

    "TARGET_CSV": "Seg_filtered.csv",
    "OUTPUT_CSV": "augmentation_log.csv",
    "CHECKPOINT_FILE": "completed_tasks.txt"
}

# [ìˆ˜ì •ë¨] ìš”ì²­í•˜ì‹  OK/NG ë¡œì§ ë° ì œì™¸ í•­ëª© ë°˜ì˜
AUG_STEPS = [
    # Step 1: Pair ì ìš© (OK ê¸°í•˜í•™)
    (1, 'pair', ['shear_M', 'rot_M']),

    # Step 2: Target Only ì ìš© (NG ê¸°í•˜í•™ - ë¯¸ì„¸í•œ ë¹„í‹€ë¦¼ì´ NGë¡œ ê°„ì£¼ë  ê²½ìš°)
    (2, 'tgt_only', ['shear_L', 'rot_L']),

    # Step 3: Pair ì ìš© (OK ìƒ‰ìƒ)
    (3, 'pair', ['hue_L', 'gray_L']),

    # Step 4: Target Only ì ìš© (NG ì™œê³¡ + OK í™”ì§ˆì €í•˜)
    (4, 'tgt_only', ['elastic_L', 'elastic_H', 'bright_M', 'contrast_L', 'eq_H', 'noise_L'])
]

# [ìˆ˜ì •ë¨] ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” íŒŒë¼ë¯¸í„° ì œê±° ë° ì •ë¦¬
PARAM_MAP = {
    # --- OK Group ---
    "shear_M": {"method": "shear", "range": (20, 30)},
    "rot_M": {"method": "rotate", "range": (20, 30)},
    "hue_L": {"method": "hue", "range": (0.01, 0.05)},
    "gray_L": {"method": "grayscale", "range": (0.1, 0.3)},
    "bright_M": {"method": "brightness", "range": (0.1, 0.2)},  # Low~Mid ì»¤ë²„
    "contrast_L": {"method": "contrast", "range": (0.53, 0.80)},
    "eq_H": {"method": "equalize", "range": (0.7, 0.9)},
    "noise_L": {"method": "noise", "range": (0.01, 0.03)},

    # --- NG Group ---
    "shear_L": {"method": "shear", "range": (5, 15)},
    "rot_L": {"method": "rotate", "range": (5, 15)},
    "elastic_L": {"method": "elastic", "alpha": (15.0, 30.0), "sigma": (4.0, 5.0)},
    "elastic_H": {"method": "elastic", "alpha": (120.0, 200.0), "sigma": (8.0, 10.0)}
}

# [ìˆ˜ì •ë¨] NG ë¼ë²¨(1)ì„ ìœ ë°œí•˜ëŠ” íŠ¸ë¦¬ê±° ë¦¬ìŠ¤íŠ¸
FONT_NG_TRIGGERS = {"shear_L", "rot_L", "elastic_L", "elastic_H"}


# =======================================================
# [2. ë°ì´í„° ë¡œë”]
# =======================================================
class DataLoader:
    def __init__(self, config):
        self.config = config

    def get_absolute_path(self, relative_path_from_csv):
        if not relative_path_from_csv: return None
        clean_rel = relative_path_from_csv.strip().replace('\\', '/')
        if clean_rel.startswith('./'):
            clean_rel = clean_rel[2:]
        elif clean_rel.startswith('/'):
            clean_rel = clean_rel[1:]
        abs_path = os.path.join(self.config["INPUT_ROOT"], clean_rel)
        if os.path.exists(abs_path): return abs_path
        return None

    def create_tasks(self):
        csv_path = os.path.join(self.config["INPUT_ROOT"], self.config["TARGET_CSV"])
        if not os.path.exists(csv_path):
            csv_path = os.path.join(self.config["INPUT_ROOT"], "image_metadata", self.config["TARGET_CSV"])

        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"Target CSV not found: {self.config['TARGET_CSV']}")

        tasks = []
        print(f"ğŸ“„ Reading target list from: {csv_path}")

        with open(csv_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            if reader.fieldnames: reader.fieldnames = [x.strip() for x in reader.fieldnames]

            for row in reader:
                real_ref = self.get_absolute_path(row.get('ref_path', ''))
                real_tar = self.get_absolute_path(row.get('tar_path', ''))

                if real_ref and real_tar:
                    task_meta = {
                        'font': row.get('font', ''),
                        'logo': row.get('logo', ''),
                        'label_s': int(row.get('label_s', 0)),
                        'label_c': int(row.get('label_c', 0))
                    }
                    tasks.append({
                        'real_ref_path': real_ref,
                        'real_tar_path': real_tar,
                        'ref_filename': os.path.basename(real_ref),
                        'tar_filename': os.path.basename(real_tar),
                        'meta': task_meta
                    })

                if self.config["IS_TEST_MODE"] and len(tasks) >= self.config["TEST_COUNT"]:
                    break
        return tasks


# =======================================================
# [3. í—¬í¼ í•¨ìˆ˜]
# =======================================================
def save_image_immediate(img, folder_path, filename):
    os.makedirs(folder_path, exist_ok=True)
    save_path = os.path.join(folder_path, filename)
    img.save(save_path, compress_level=1)
    return save_path

def is_black_image(pil_img, threshold=5.0):
    """
    ì´ë¯¸ì§€ê°€ ê²€ì€ìƒ‰(ë˜ëŠ” ê±°ì˜ ê²€ì€ìƒ‰)ì¸ì§€ íŒë³„í•©ë‹ˆë‹¤.
    threshold: í‰ê·  í”½ì…€ê°’ ê¸°ì¤€ (0~255 ì¤‘ 5 ë¯¸ë§Œì´ë©´ ê²€ì€ìƒ‰ìœ¼ë¡œ ê°„ì£¼)
    """
    if pil_img is None: return True
    try:
        # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        img_arr = np.array(pil_img)
        # í‰ê·  í”½ì…€ ê°’ì´ thresholdë³´ë‹¤ ë‚®ìœ¼ë©´ ê²€ì€ìƒ‰ ì´ë¯¸ì§€ë¡œ íŒë‹¨
        return np.mean(img_arr) < threshold
    except Exception:
        return True

def load_image_with_retry(path, retries=3, delay=0.2):
    for i in range(retries):
        try:
            if not os.path.exists(path):
                raise FileNotFoundError(f"File not found: {path}")
            with Image.open(path) as f:
                img = f.convert("RGB")
                img.load()
                return img
        except Exception as e:
            if i == retries - 1:
                return None
            time.sleep(delay)
    return None


# =======================================================
# [4. ì´ë¯¸ì§€ ì¦ê°• ì—”ì§„]
# =======================================================
class ImageAugmentor:
    @staticmethod
    def apply_noise(img, severity_factor):
        img_tensor = v2.ToImage()(img)
        img_tensor = v2.ToDtype(torch.float32, scale=True)(img_tensor)
        noise = torch.randn_like(img_tensor) * severity_factor
        noisy_img = torch.clamp(img_tensor + noise, 0., 1.)
        return v2.ToPILImage()(noisy_img), {"severity": round(severity_factor, 4)}

    # [ìˆ˜ì •ë¨] Stain, Perspective ê´€ë ¨ í•¨ìˆ˜ ë° ë¶„ê¸° ì œê±°
    @classmethod
    def apply_op(cls, img, tag, manual_param=None):
        if tag not in PARAM_MAP: return img, {}
        config = PARAM_MAP[tag]
        method = config["method"]
        processed = img.copy()
        params_log = {}

        if method == "shear":
            min_v, max_v = config["range"]
            if manual_param is not None:
                val, axis = manual_param
            else:
                val = random.uniform(min_v, max_v) * random.choice([-1, 1])
                axis = random.choice(['x', 'y'])
            processed = F.affine(processed, angle=0, translate=[0, 0], scale=1.0,
                                 shear=[val, 0.0] if axis == 'x' else [0.0, val],
                                 interpolation=v2.InterpolationMode.BILINEAR, fill=255)
            params_log = {"axis": axis, "val": round(val, 2)}

        elif method == "rotate":
            min_v, max_v = config["range"]
            if manual_param is not None:
                val = manual_param
            else:
                val = random.uniform(min_v, max_v) * random.choice([-1, 1])
            processed = F.rotate(processed, angle=val, interpolation=v2.InterpolationMode.BILINEAR, fill=255)
            params_log = {"angle": round(val, 2)}

        elif method == "elastic":
            alpha = random.uniform(*config["alpha"])
            sigma = random.uniform(*config["sigma"])
            processed = v2.ElasticTransform(alpha=alpha, sigma=sigma)(processed)
            params_log = {"alpha": round(alpha, 1), "sigma": round(sigma, 1)}

        elif method == "hue":
            min_v, max_v = config["range"]
            if manual_param is not None:
                val = manual_param
            else:
                val = max(-0.5, min(random.uniform(min_v, max_v) * random.choice([-1, 1]), 0.5))
            processed = F.adjust_hue(processed, val)
            params_log = {"hue_factor": round(val, 3)}

        elif method == "grayscale":
            if manual_param is not None:
                alpha = manual_param
            else:
                alpha = random.uniform(*config["range"])
            if processed.mode != 'RGB': processed = processed.convert('RGB')
            processed = Image.blend(processed, ImageOps.grayscale(processed).convert("RGB"), alpha)
            params_log = {"gray_alpha": round(alpha, 2)}

        elif method == "brightness":
            min_v, max_v = config["range"]
            factor = max(0.0, 1.0 + (random.uniform(min_v, max_v) * random.choice([-1, 1])))
            processed = F.adjust_brightness(processed, factor)
            params_log = {"bright_factor": round(factor, 2)}

        elif method == "contrast":
            val = random.uniform(*config["range"])
            processed = F.adjust_contrast(processed, val)
            params_log = {"contrast_factor": round(val, 2)}

        elif method == "equalize":
            alpha = random.uniform(*config["range"])
            if processed.mode != 'RGB': processed = processed.convert('RGB')
            processed = Image.blend(processed, ImageOps.equalize(processed), alpha)
            params_log = {"eq_alpha": round(alpha, 2)}

        elif method == "noise":
            val = random.uniform(*config["range"])
            processed, p_log = cls.apply_noise(processed, val)
            params_log = p_log

        return processed, params_log

    @staticmethod
    def generate_seed_param(tag):
        if tag not in PARAM_MAP: return None
        config = PARAM_MAP[tag]
        method = config["method"]
        if method == "shear":
            min_v, max_v = config["range"]
            return (random.uniform(min_v, max_v) * random.choice([-1, 1]), random.choice(['x', 'y']))
        elif method == "rotate":
            min_v, max_v = config["range"]
            return random.uniform(min_v, max_v) * random.choice([-1, 1])
        elif method == "hue":
            min_v, max_v = config["range"]
            return max(-0.5, min(random.uniform(min_v, max_v) * random.choice([-1, 1]), 0.5))
        elif method == "grayscale":
            return random.uniform(*config["range"])
        return None


# =======================================================
# [5. ë°ì´í„° ê°ì²´]
# =======================================================
class AugData:
    def __init__(self, ref_path, tgt_path, ref_name, tgt_name, meta,
                 aug_method=None, aug_params=None,
                 img_ref_obj=None, img_tgt_obj=None):
        self.ref_path = ref_path
        self.tgt_path = tgt_path
        self.ref_name = ref_name
        self.tgt_name = tgt_name
        self.meta = meta
        self.aug_method = aug_method if aug_method else ""
        self.aug_params = aug_params if aug_params else ""
        self.img_ref_obj = img_ref_obj
        self.img_tgt_obj = img_tgt_obj

    def get_images(self):
        if self.img_ref_obj is None:
            self.img_ref_obj = load_image_with_retry(self.ref_path)
        if self.img_tgt_obj is None:
            self.img_tgt_obj = load_image_with_retry(self.tgt_path)
        return self.img_ref_obj, self.img_tgt_obj

    def release_memory(self):
        self.img_ref_obj = None
        self.img_tgt_obj = None

    def update_label(self, method_tag):
        if self.meta['label_s'] == 0 and (method_tag in FONT_NG_TRIGGERS):
            self.meta['label_s'] = 1

    def get_target_subfolder(self):
        s = self.meta['label_s']
        c = self.meta['label_c']
        if s == 1 and c == 1: return "font_diff_letter_diff"
        if s == 1 and c == 0: return "font_diff_letter_same"
        if s == 0 and c == 1: return "font_same_letter_diff"
        return "font_same_letter_same"

    def get_csv_row(self):
        def to_relative(path):
            try:
                if path is None: return ""
                rel = os.path.relpath(path, CONFIG["OUTPUT_ROOT"])
                rel = rel.replace(os.sep, '/')
                if not rel.startswith('./'): rel = './' + rel
                return rel
            except:
                return path

        return {
            'tar_path': to_relative(self.tgt_path),
            'ref_path': to_relative(self.ref_path),
            'font': self.meta.get('font', ''),
            'logo': self.meta.get('logo', ''),
            'label_s': self.meta.get('label_s', 0),
            'label_c': self.meta.get('label_c', 0),
            'aug_method': self.aug_method,
            'aug_param': self.aug_params,
            'label_stain': 0  # Stain ê¸°ëŠ¥ ì œê±°ë¡œ í•­ìƒ 0
        }


# =======================================================
# [6. ì›Œì»¤ í”„ë¡œì„¸ìŠ¤]
# =======================================================
def worker_process(task_data):
    try:
        real_ref_path = task_data['real_ref_path']
        real_tgt_path = task_data['real_tar_path']
        ref_filename = task_data['ref_filename']
        tar_filename = task_data['tar_filename']
        meta = task_data['meta']

        base = os.path.basename(ref_filename)
        base_ref_name = base[:-8] if base.lower().endswith('.png.jpg') else os.path.splitext(base)[0]

        stem = os.path.basename(tar_filename)
        stem = stem[:-8] if stem.lower().endswith('.png.jpg') else os.path.splitext(stem)[0]
        base_tgt_name = stem.split("@seg")[0] + "@seg" if "@seg" in stem else stem

        origin_ref_img = load_image_with_retry(real_ref_path)
        origin_tgt_img = load_image_with_retry(real_tgt_path)

        if origin_ref_img is None or origin_tgt_img is None:
            return []

        pool = [AugData(real_ref_path, real_tgt_path, base_ref_name, base_tgt_name, meta,
                        img_ref_obj=origin_ref_img, img_tgt_obj=origin_tgt_img)]

        result_rows = []

        for step_idx, scope, methods in AUG_STEPS:
            new_items = []

            if len(pool) > CONFIG["MAX_RAM_CACHE"]:
                for old_item in pool[:-CONFIG["MAX_RAM_CACHE"]]:
                    old_item.release_memory()
                gc.collect()

            for data in pool:
                src_ref_img, src_tgt_img = data.get_images()
                if src_ref_img is None or src_tgt_img is None: continue

                for tag in methods:
                    # [ìˆ˜ì •] ì¬ì‹œë„ ë¡œì§ ì¶”ê°€ (ìµœëŒ€ 3íšŒ)
                    retry_count = 0
                    max_retries = 3

                    res_ref_img = None
                    res_tgt_img = None
                    params_r = {}
                    params_t = {}
                    aug_info = ""
                    success = False

                    while retry_count < max_retries:
                        # 1. íŒŒë¼ë¯¸í„° ìƒì„± ë° ì ìš©
                        if scope == 'pair':
                            seed_param = ImageAugmentor.generate_seed_param(tag)
                            res_ref_img, params_r = ImageAugmentor.apply_op(src_ref_img, tag, manual_param=seed_param)
                            res_tgt_img, params_t = ImageAugmentor.apply_op(src_tgt_img, tag, manual_param=seed_param)
                            name_r = f"{data.ref_name}@{tag}"
                            name_t = f"{data.tgt_name}@{tag}"
                            aug_info = json.dumps({"ref": params_r, "tgt": params_t}, ensure_ascii=False)
                        else:
                            res_ref_img = src_ref_img
                            res_tgt_img, params_t = ImageAugmentor.apply_op(src_tgt_img, tag)
                            name_r = data.ref_name
                            name_t = f"{data.tgt_name}@{tag}"
                            aug_info = json.dumps({"ref": None, "tgt": params_t}, ensure_ascii=False)

                        # 2. [ê²€ì¦] ê²€ì€ ì´ë¯¸ì§€ ì²´í¬
                        if is_black_image(res_ref_img) or is_black_image(res_tgt_img):
                            retry_count += 1
                            # print(f"âš ï¸ Black image detected ({tag}). Retrying {retry_count}/{max_retries}...")
                            continue  # ë‹¤ì‹œ whileë¬¸ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ì„œ ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„°ë¡œ ì‹œë„
                        else:
                            success = True
                            break  # ì •ìƒ ì´ë¯¸ì§€ë©´ while íƒˆì¶œ

                    # 3íšŒ ì‹œë„ í›„ì—ë„ ê²€ì€ìƒ‰ì´ë©´ ê±´ë„ˆëœ€ (ë°ì´í„° ì˜¤ì—¼ ë°©ì§€)
                    if not success:
                        # print(f"âŒ Skipping {tag} due to persistent black image error.")
                        continue

                    # --- ì´í•˜ ì €ì¥ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼ ---
                    next_meta = data.meta.copy()

                    # ë¼ë²¨ ì—…ë°ì´íŠ¸ (NG ì¡°ê±´ ë°œìƒ ì‹œ label_s = 1)
                    if next_meta['label_s'] == 0 and (tag in FONT_NG_TRIGGERS):
                        next_meta['label_s'] = 1

                    temp_item = AugData(None, None, name_r, name_t, next_meta, aug_method=tag, aug_params=aug_info)
                    target_subfolder = temp_item.get_target_subfolder()

                    # (ì´í•˜ ì €ì¥ ì½”ë“œ ë™ì¼...)
                    save_dir_ref = os.path.join(CONFIG["OUTPUT_ROOT"], "ref_img")
                    save_dir_tgt = os.path.join(CONFIG["OUTPUT_ROOT"], "tar_img", target_subfolder)

                    filename_ref = f"{name_r}.png"
                    filename_tgt = f"{name_t}.png"

                    saved_ref_path = save_image_immediate(res_ref_img, save_dir_ref, filename_ref)
                    saved_tgt_path = save_image_immediate(res_tgt_img, save_dir_tgt, filename_tgt)

                    next_item = AugData(saved_ref_path, saved_tgt_path, name_r, name_t, next_meta,
                                        aug_method=tag, aug_params=aug_info,
                                        img_ref_obj=res_ref_img, img_tgt_obj=res_tgt_img)

                    result_rows.append(next_item.get_csv_row())
                    new_items.append(next_item)

            pool.extend(new_items)

        del pool
        gc.collect()
        return result_rows

    except Exception:
        print(f"\n[Critical Error processing {task_data.get('tar_filename')}]")
        traceback.print_exc()
        return []


# =======================================================
# [7. ë©”ì¸ ì‹¤í–‰]
# =======================================================
def main():
    multiprocessing.freeze_support()

    os.makedirs(CONFIG["OUTPUT_ROOT"], exist_ok=True)
    checkpoint_path = os.path.join(CONFIG["OUTPUT_ROOT"], CONFIG["CHECKPOINT_FILE"])
    output_csv = os.path.join(CONFIG["OUTPUT_ROOT"], CONFIG["OUTPUT_CSV"])

    completed_tasks = set()
    if os.path.exists(checkpoint_path):
        with open(checkpoint_path, 'r', encoding='utf-8') as f:
            completed_tasks = set(line.strip() for line in f)
        print(f"ğŸ”„ Resuming... Found {len(completed_tasks)} completed tasks.")
    else:
        print(f"ğŸ†• Starting fresh.")

    print(f"ğŸš€ Augmentation Start (Workers: {CONFIG['NUM_WORKERS']})")

    loader = DataLoader(CONFIG)
    try:
        all_tasks = loader.create_tasks()
    except Exception as e:
        print(f"âŒ Error creating tasks: {e}")
        return

    task_list = [t for t in all_tasks if t['tar_filename'] not in completed_tasks]

    if not task_list:
        print("âœ… All tasks are already completed!")
        return

    print(f"ğŸ“‹ Remaining tasks: {len(task_list)} / {len(all_tasks)}")

    headers = ['tar_path', 'ref_path', 'font', 'logo', 'label_s', 'label_c',
               'aug_method', 'aug_param', 'label_stain']

    file_mode = 'a' if (completed_tasks and os.path.exists(output_csv)) else 'w'

    print("â³ Processing...")

    with open(output_csv, file_mode, newline='', encoding='utf-8-sig') as out_f, \
            open(checkpoint_path, 'a', encoding='utf-8') as cp_f:

        writer = csv.DictWriter(out_f, fieldnames=headers)
        if file_mode == 'w':
            writer.writeheader()

        with ProcessPoolExecutor(max_workers=CONFIG["NUM_WORKERS"]) as executor:
            future_to_id = {
                executor.submit(worker_process, task): task['tar_filename']
                for task in task_list
            }

            for future in tqdm(as_completed(future_to_id), total=len(task_list), desc="Augmenting"):
                task_id = future_to_id[future]
                try:
                    results = future.result()
                    if results:
                        writer.writerows(results)
                        out_f.flush()
                        cp_f.write(task_id + '\n')
                        cp_f.flush()
                except Exception as e:
                    print(f"âŒ Error in task {task_id}: {e}")

    print(f"âœ… Finished. Saved to: {CONFIG['OUTPUT_ROOT']}")


if __name__ == "__main__":
    main()